{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f315a60150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "import FLAlgorithms\n",
    "import utils\n",
    "\n",
    "#for jupyter notebook reload modules\n",
    "import imp\n",
    "imp.reload(FLAlgorithms) \n",
    "imp.reload(utils) \n",
    "from FLAlgorithms.servers.serveravg import FedAvg\n",
    "from FLAlgorithms.servers.serverpFedMe import pFedMe\n",
    "from FLAlgorithms.servers.serverperavg import PerAvg\n",
    "from FLAlgorithms.trainmodel.models import *\n",
    "from FLAlgorithms.servers.servertrans import pFedTrans\n",
    "\n",
    "from utils.plot_utils import *\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Running time:------------\n",
      "Number of users / total users: 5  /  20\n",
      "Finished creating pFedMe server.\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "\n",
    "print(\"---------------Running time:------------\",)\n",
    "# Generate model\n",
    "model = 'mclr'\n",
    "dataset = 'Mnist'\n",
    "\n",
    "model = Mclr_Logistic().to(device), model\n",
    "algorithm = \"pFedMe\"\n",
    "# select algorithm\n",
    "batch_size = 20\n",
    "learning_rate = 0.01\n",
    "personal_learning_rate = 0.01\n",
    "beta = 2\n",
    "lamda = 15\n",
    "num_glob_iters = 800\n",
    "local_epochs = 20\n",
    "optimizer = \"SGD\"\n",
    "numusers = 5\n",
    "K = 5\n",
    "server = pFedTrans(device, dataset, algorithm, model, batch_size, learning_rate,beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, K, personal_learning_rate, 5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.emb_layer.to(device)\n",
    "for user in server.users:\n",
    "    user.train(10)\n",
    "    user.net_values = [*user.model.state_dict().values()]\n",
    "    user.per_values = user.net_values[-2:]\n",
    "    value_vec = nn.utils.parameters_to_vector(user.per_values).clone()\n",
    "    user.emb_vec = server.emb_layer(value_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from kmeans_pytorch import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Global Accurancy:  0.9306155507559395\n",
      "Average Global Trainning Accurancy:  0.9400505597688696\n",
      "Average Global Trainning Loss:  0.6547107414116107\n"
     ]
    }
   ],
   "source": [
    "server.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in server.users:\n",
    "    user.train(server.local_epochs)\n",
    "    user.emb(server.emb_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data\n",
    "data_size, dims, num_clusters = 1000, 100, 10\n",
    "\n",
    "client_emb_list = [user.emb_vec.data.clone().reshape(1, -1) for user in server.users]\n",
    "print(len(client_emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client_emb_list = torch.cat(client_emb_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0026, -0.0084,  0.0218,  ...,  0.0389, -0.0186,  0.0014],\n",
      "        [ 0.0058, -0.0061,  0.0197,  ...,  0.0393, -0.0129,  0.0027],\n",
      "        [ 0.0064, -0.0094,  0.0134,  ...,  0.0399, -0.0117,  0.0021],\n",
      "        ...,\n",
      "        [ 0.0069, -0.0079,  0.0153,  ...,  0.0413, -0.0013,  0.0014],\n",
      "        [ 0.0073, -0.0062,  0.0212,  ...,  0.0393, -0.0086,  0.0040],\n",
      "        [ 0.0044, -0.0089,  0.0136,  ...,  0.0398, -0.0111,  0.0026]])\n"
     ]
    }
   ],
   "source": [
    "print(client_emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cpu..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 2it [00:00, 333.25it/s, center_shift=0.000000, iteration=2, tol=0.000100]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_clusters = 10\n",
    "# kmeans\n",
    "cluster_res, cluster_centers = kmeans(\n",
    "    X=client_emb_list, num_clusters=num_clusters, distance='euclidean', device=device\n",
    ")\n",
    "#cluster_res, cluster_centers = kmeans(\n",
    "#    X=client_emb_list, num_clusters=num_clusters, distance='euclidean', device=torch.device('cuda:0')\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for client_id, cluster_id in enumerate(cluster_res):\n",
    "    server.users[client_id].cluster_id = cluster_res[client_id] \n",
    "    server.clusters[cluster_id].users.append(server.users[client_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2780/2775804118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_update_base_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\fang\\Documents\\gitspace\\pFedMe-trans\\FLAlgorithms\\users\\userpFedTrans.py\u001b[0m in \u001b[0;36mavg_update_base_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres_values\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                     \u001b[0mres_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "for cluster in server.clusters:\n",
    "    cluster.avg_update_base_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cluster in server.clusters:\n",
    "    cluster.update_model(server.emb_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reformer_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((10, 1, 10)).to(device)\n",
    "y = torch.randn((10, 1, 10)).to(device)\n",
    "z = torch.randn((10, 1, 10)).to(device)\n",
    "\n",
    "embed_dim = 10\n",
    "num_heads = 5\n",
    "attn = nn.MultiheadAttention(embed_dim, num_heads).to(device)\n",
    "opt, weight = attn(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "attn = nn.MultiheadAttention(embed_dim, num_heads).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intra_cluster_attn weigh        \n",
    "emb_dim = attn_dim = 128\n",
    "# position embedding :weight of total samples in cluster\n",
    "cluster_emb_list = [cluster.emb_vec.data.clone().reshape(1, -1) for cluster in server.clusters]\n",
    "x = torch.cat(cluster_emb_list, dim=0).unsqueeze(1)\n",
    "ln1 = torch.nn.LayerNorm(x.size()).to(device)\n",
    "x = ln1(x)\n",
    "print(x.size())\n",
    "l1 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "l2 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "a = l1(x)\n",
    "b = l2(x)\n",
    "c = torch.zeros_like(a)\n",
    "output, weight = attn(a, b, c)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_add(models, weights):\n",
    "    res = copy.deepcopy(models[0])\n",
    "    for param in res.parameters():\n",
    "        param.data = torch.zeros_like(param.data)\n",
    "        param.grad = torch.zeros_like(param.data)\n",
    "        print(param)\n",
    "    for model, weight in zip(models, weights):\n",
    "        for res_param, model_param in zip(res.parameters(), model.parameters()):\n",
    "            res_param.data += model_param.data.clone() * weight\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "models = [nn.Linear(10, 10).to(device) for _ in range(5)]\n",
    "weights = [1,0, 0, 0, 0]\n",
    "model_a = model_add(models, weights)\n",
    "print(models[0].state_dict())\n",
    "print(model_a.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "weight = weight.squeeze(0)\n",
    "cluster_models = [cluster.model.clone() for cluster in server.clusters]\n",
    "for cluster in server.clusters:\n",
    "    cluster.model = \n",
    "print(weight.size())\n",
    "print(weight[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_values = [*model.state_dict().values()]\n",
    "base_values = net_values[:-2]\n",
    "per_values = net_values[-2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratio = 0.5\n",
    "base_values = \n",
    "for v in base_values\n",
    "v = base_values * ratio\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = server.clusters[0].model\n",
    "model_list = []\n",
    "for param in model.parameters():\n",
    "    param.grad = param.data\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128\n",
    "cluster_model_list = [cluster.model.data.clone().reshape(1, -1) for cluster in server.clusters]\n",
    "attn_dim = 128\n",
    "x = torch.randn((10, 1, 128)).to(device)\n",
    "print(x.size())\n",
    "l1 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "l2 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "\n",
    "a = l1(x)\n",
    "b = l2(x)\n",
    "c = torch.ones_like(a)\n",
    "output, weight = attn(a, b, c)\n",
    "\n",
    "print(weight)\n",
    "torch.einsum('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_query = inter_query_weight(inter_attn_input)\n",
    "inter_key = inter_key_weight(inter_attn_input)\n",
    "inter_value = torch.ones_like(inter_query).to(device)\n",
    "#inter_key = inter_key_weight(inter_attn_input)\n",
    "#inter_value = inter_value_weight(inter_query)\n",
    "attn_output, attn_weight = attn(inter_query, inter_key, inter_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.ones((10, 1, 128)).to(device)\n",
    "output, weight = attn(x, y, z)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.ones((10, 1, 128)).to(device)\n",
    "attn_output, attn_weight = attn(x, y, z)\n",
    "print(attn_output)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"---------------Running time:------------\",i)\n",
    "    # Generate model\n",
    "    model = 'mclr'\n",
    "    dataset = 'Mnist'\n",
    "\n",
    "    model = Mclr_Logistic().to(device), model\n",
    "    algorithm = \"pFedMe\"\n",
    "    # select algorithm\n",
    "    batch_size = 20\n",
    "    learning_rate = 0.01\n",
    "    personal_learning_rate = 0.01\n",
    "    beta = 2\n",
    "    lamda = 15\n",
    "    num_glob_iters = 800\n",
    "    local_epochs = 20\n",
    "    optimizer = \"SGD\"\n",
    "    numusers = 5\n",
    "    K = 5\n",
    "    if(algorithm == \"FedAvg\"):\n",
    "        server = FedAvg(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, i)\n",
    "        \n",
    "    if(algorithm == \"pFedMe\"):\n",
    "        server = pFedMe(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, K, personal_learning_rate, i)\n",
    "\n",
    "    if(algorithm == \"PerAvg\"):\n",
    "        server = PerAvg(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, i)\n",
    "\n",
    "    server.train()\n",
    "    server.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from kmeans_pytorch import kmeans\n",
    "\n",
    "# data\n",
    "data_size, dims, num_clusters = 1000, 100, 3\n",
    "x = np.random.randn(data_size, dims) / 6\n",
    "x = torch.from_numpy(x)\n",
    "\n",
    "# kmeans\n",
    "cluster_ids_x, cluster_centers = kmeans(\n",
    "    X=x, num_clusters=num_clusters, distance='euclidean', device=torch.device('cuda:0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(cluster_ids_x, cluster_centers.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 5\n",
    "\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=\"pFedMe_p\", batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=algorithm, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user = server.users[0]\n",
    "model = user.model\n",
    "net_values = [*model.state_dict().values()]\n",
    "print(net_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(server.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x, y in server.users[0].testloaderfull:\n",
    "    x = x.to(user.device)\n",
    "    print(x.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Average data \n",
    "if(algorithm == \"PerAvg\"):\n",
    "    algorithm == \"PerAvg_p\"\n",
    "if(algorithm == \"pFedMe\"):\n",
    "    average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=\"pFedMe_p\", batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=algorithm, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1ccd20b5258b628543699ad079c0d4ef32c5d2797833541d65624ed3b1ba210"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('phd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
