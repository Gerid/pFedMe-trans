{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1df70de8210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "import FLAlgorithms\n",
    "import utils\n",
    "\n",
    "#for jupyter notebook reload modules\n",
    "import imp\n",
    "imp.reload(FLAlgorithms) \n",
    "imp.reload(utils) \n",
    "from FLAlgorithms.servers.serveravg import FedAvg\n",
    "from FLAlgorithms.servers.serverpFedMe import pFedMe\n",
    "from FLAlgorithms.servers.serverperavg import PerAvg\n",
    "from FLAlgorithms.trainmodel.models import *\n",
    "from FLAlgorithms.servers.servertrans import pFedTrans\n",
    "\n",
    "from utils.plot_utils import *\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Running time:------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'pFedTrans' object has no attribute 'get_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34832/1831412560.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mnumusers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mserver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpFedTrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_glob_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumusers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpersonal_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Projects\\pFedMe-trans\\FLAlgorithms\\servers\\servertrans.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, num_users, K, personal_learning_rate, times, num_cluster)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Initialize data for all  users\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0memb_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mattn_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mnum_heads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'pFedTrans' object has no attribute 'get_parameters'"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "\n",
    "print(\"---------------Running time:------------\",)\n",
    "# Generate model\n",
    "model = 'mclr'\n",
    "dataset = 'Mnist'\n",
    "\n",
    "model = Mclr_Logistic().to(device), model\n",
    "algorithm = \"pFedMe\"\n",
    "# select algorithm\n",
    "batch_size = 20\n",
    "learning_rate = 0.01\n",
    "personal_learning_rate = 0.01\n",
    "beta = 2\n",
    "lamda = 15\n",
    "num_glob_iters = 800\n",
    "local_epochs = 20\n",
    "optimizer = \"SGD\"\n",
    "numusers = 5\n",
    "K = 5\n",
    "server = pFedTrans(device, dataset, algorithm, model, batch_size, learning_rate,beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, K, personal_learning_rate, 5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.emb_layer.to(device)\n",
    "for user in server.users:\n",
    "    user.train(10)\n",
    "    user.net_values = [*user.model.state_dict().values()]\n",
    "    user.per_values = user.net_values[-2:]\n",
    "    value_vec = nn.utils.parameters_to_vector(user.per_values).clone()\n",
    "    user.emb_vec = server.emb_layer(value_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from kmeans_pytorch import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Global Accurancy:  0.9306155507559395\n",
      "Average Global Trainning Accurancy:  0.9400505597688696\n",
      "Average Global Trainning Loss:  0.6547072587266387\n"
     ]
    }
   ],
   "source": [
    "server.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in server.users:\n",
    "    user.train(server.local_epochs)\n",
    "    user.emb(server.emb_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23848/488306689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "model1 = model.copy()\n",
    "print(id(model1),id(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda:0..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 2it [00:00, 222.03it/s, center_shift=0.000000, iteration=2, tol=0.000100]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23848/3403436826.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mform_cluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Projects\\pFedMe-trans\\FLAlgorithms\\servers\\servertrans.py\u001b[0m in \u001b[0;36mform_cluster\u001b[1;34m(self, reform)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclient_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;31m#cluster.per_layer is the centroid per_model for clients within cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "server.num_cluster = 10\n",
    "server.form_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data\n",
    "data_size, dims, num_clusters = 1000, 100, 10\n",
    "\n",
    "client_emb_list = [user.emb_vec.data.clone().reshape(1, -1) for user in server.users]\n",
    "print(len(client_emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client_emb_list = torch.cat(client_emb_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client_emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_clusters = 10\n",
    "# kmeans\n",
    "cluster_res, cluster_centers = kmeans(\n",
    "    X=client_emb_list, num_clusters=num_clusters, distance='euclidean', device=torch.device('cuda:0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for client_id, cluster_id in enumerate(cluster_res):\n",
    "    server.users[client_id].cluster_id = cluster_res[client_id] \n",
    "    server.clusters[cluster_id].users.append(server.users[client_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cluster in server.clusters:\n",
    "    cluster.update_model(server.emb_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reformer_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((10, 1, 10)).to(device)\n",
    "y = torch.randn((10, 1, 10)).to(device)\n",
    "z = torch.randn((10, 1, 10)).to(device)\n",
    "\n",
    "embed_dim = 10\n",
    "num_heads = 5\n",
    "attn = nn.MultiheadAttention(embed_dim, num_heads).to(device)\n",
    "opt, weight = attn(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "attn = nn.MultiheadAttention(embed_dim, num_heads).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intra_cluster_attn weigh        \n",
    "emb_dim = attn_dim = 128\n",
    "# position embedding :weight of total samples in cluster\n",
    "cluster_emb_list = [cluster.emb_vec.data.clone().reshape(1, -1) for cluster in server.clusters]\n",
    "x = torch.cat(cluster_emb_list, dim=0).unsqueeze(1)\n",
    "ln1 = torch.nn.LayerNorm(x.size()).to(device)\n",
    "x = ln1(x)\n",
    "print(x.size())\n",
    "l1 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "l2 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "a = l1(x)\n",
    "b = l2(x)\n",
    "c = torch.zeros_like(a)\n",
    "output, weight = attn(a, b, c)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_add(models, weights):\n",
    "    res = copy.deepcopy(models[0])\n",
    "    for param in res.parameters():\n",
    "        param.data = torch.zeros_like(param.data)\n",
    "        param.grad = torch.zeros_like(param.data)\n",
    "        print(param)\n",
    "    for model, weight in zip(models, weights):\n",
    "        for res_param, model_param in zip(res.parameters(), model.parameters()):\n",
    "            res_param.data += model_param.data.clone() * weight\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "models = [nn.Linear(10, 10).to(device) for _ in range(5)]\n",
    "weights = [1,0, 0, 0, 0]\n",
    "model_a = model_add(models, weights)\n",
    "print(models[0].state_dict())\n",
    "print(model_a.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "weight = weight.squeeze(0)\n",
    "cluster_models = [cluster.model.clone() for cluster in server.clusters]\n",
    "for cluster in server.clusters:\n",
    "    cluster.model = \n",
    "print(weight.size())\n",
    "print(weight[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_values = [*model.state_dict().values()]\n",
    "base_values = net_values[:-2]\n",
    "per_values = net_values[-2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratio = 0.5\n",
    "base_values = \n",
    "for v in base_values\n",
    "v = base_values * ratio\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = server.clusters[0].model\n",
    "model_list = []\n",
    "for param in model.parameters():\n",
    "    param.grad = param.data\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128\n",
    "cluster_model_list = [cluster.model.data.clone().reshape(1, -1) for cluster in server.clusters]\n",
    "attn_dim = 128\n",
    "x = torch.randn((10, 1, 128)).to(device)\n",
    "print(x.size())\n",
    "l1 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "l2 = nn.Linear(emb_dim, attn_dim).to(device)\n",
    "\n",
    "a = l1(x)\n",
    "b = l2(x)\n",
    "c = torch.ones_like(a)\n",
    "output, weight = attn(a, b, c)\n",
    "\n",
    "print(weight)\n",
    "torch.einsum('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_query = inter_query_weight(inter_attn_input)\n",
    "inter_key = inter_key_weight(inter_attn_input)\n",
    "inter_value = torch.ones_like(inter_query).to(device)\n",
    "#inter_key = inter_key_weight(inter_attn_input)\n",
    "#inter_value = inter_value_weight(inter_query)\n",
    "attn_output, attn_weight = attn(inter_query, inter_key, inter_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.ones((10, 1, 128)).to(device)\n",
    "output, weight = attn(x, y, z)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.ones((10, 1, 128)).to(device)\n",
    "attn_output, attn_weight = attn(x, y, z)\n",
    "print(attn_output)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"---------------Running time:------------\",i)\n",
    "    # Generate model\n",
    "    model = 'mclr'\n",
    "    dataset = 'Mnist'\n",
    "\n",
    "    model = Mclr_Logistic().to(device), model\n",
    "    algorithm = \"pFedMe\"\n",
    "    # select algorithm\n",
    "    batch_size = 20\n",
    "    learning_rate = 0.01\n",
    "    personal_learning_rate = 0.01\n",
    "    beta = 2\n",
    "    lamda = 15\n",
    "    num_glob_iters = 800\n",
    "    local_epochs = 20\n",
    "    optimizer = \"SGD\"\n",
    "    numusers = 5\n",
    "    K = 5\n",
    "    if(algorithm == \"FedAvg\"):\n",
    "        server = FedAvg(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, i)\n",
    "        \n",
    "    if(algorithm == \"pFedMe\"):\n",
    "        server = pFedMe(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, K, personal_learning_rate, i)\n",
    "\n",
    "    if(algorithm == \"PerAvg\"):\n",
    "        server = PerAvg(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, i)\n",
    "\n",
    "    server.train()\n",
    "    server.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from kmeans_pytorch import kmeans\n",
    "\n",
    "# data\n",
    "data_size, dims, num_clusters = 1000, 100, 3\n",
    "x = np.random.randn(data_size, dims) / 6\n",
    "x = torch.from_numpy(x)\n",
    "\n",
    "# kmeans\n",
    "cluster_ids_x, cluster_centers = kmeans(\n",
    "    X=x, num_clusters=num_clusters, distance='euclidean', device=torch.device('cuda:0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(cluster_ids_x, cluster_centers.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 5\n",
    "\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=\"pFedMe_p\", batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=algorithm, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user = server.users[0]\n",
    "model = user.model\n",
    "net_values = [*model.state_dict().values()]\n",
    "print(net_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(server.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x, y in server.users[0].testloaderfull:\n",
    "    x = x.to(user.device)\n",
    "    print(x.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Average data \n",
    "if(algorithm == \"PerAvg\"):\n",
    "    algorithm == \"PerAvg_p\"\n",
    "if(algorithm == \"pFedMe\"):\n",
    "    average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=\"pFedMe_p\", batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=algorithm, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "293539041be06dcdbc1dd82d46367ecf96c14410c0014bf8043197a4a2571a26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
