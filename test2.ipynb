{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1783682cdf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from kmeans_pytorch import kmeans\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "import FLAlgorithms\n",
    "import utils\n",
    "\n",
    "#for jupyter notebook reload modules\n",
    "import imp\n",
    "imp.reload(FLAlgorithms) \n",
    "imp.reload(utils) \n",
    "from FLAlgorithms.servers.serveravg import FedAvg\n",
    "from FLAlgorithms.servers.serverpFedMe import pFedMe\n",
    "from FLAlgorithms.servers.serverperavg import PerAvg\n",
    "from FLAlgorithms.trainmodel.models import *\n",
    "from FLAlgorithms.servers.servertrans import pFedTrans, Cluster\n",
    "\n",
    "from utils.plot_utils import *\n",
    "from kmeans_pytorch import kmeans\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def props(cls):   \n",
    "  return [i for i in cls.__dict__.keys() if i[:1] != '_']\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpu = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "model = DNN(60, 20, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 60])\n",
      "torch.Size([20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for value in model.state_dict().values():\n",
    "    print(value.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Running time:------------\n",
      "Number of users / total users: 100  /  20\n",
      "Finished creating pFedMe server.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "gpu = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "\n",
    "print(\"---------------Running time:------------\",)\n",
    "# Generate model\n",
    "model = 'mclr'\n",
    "dataset = 'Mnist'\n",
    "\n",
    "model = Mclr_Logistic().to(device), model\n",
    "algorithm = \"pFedTrans\"\n",
    "# select algorithm\n",
    "batch_size = 20\n",
    "learning_rate = 0.01\n",
    "personal_learning_rate = 0.01\n",
    "beta = 2\n",
    "lamda = 15\n",
    "num_glob_iters = 800\n",
    "local_epochs = 20\n",
    "optimizer = \"SGD\"\n",
    "numusers = 100 \n",
    "K = 5\n",
    "time1 = time.time()\n",
    "server = pFedTrans(device, dataset, algorithm, model, batch_size, learning_rate,beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, K, personal_learning_rate, 5)\n",
    "time2 = time.time()\n",
    "cost_time = time2-time1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Global Accurancy:  0.08342332613390929\n",
      "Average Global Trainning Accurancy:  0.08360418923799205\n",
      "Average Global Trainning Loss:  2.418263764276363\n",
      "odict_values([tensor([[-0.0202, -0.0072,  0.0322,  ...,  0.0074,  0.0303, -0.0296],\n",
      "        [-0.0186,  0.0064, -0.0356,  ...,  0.0092, -0.0141,  0.0014],\n",
      "        [ 0.0140, -0.0160, -0.0340,  ..., -0.0065,  0.0020,  0.0101],\n",
      "        ...,\n",
      "        [ 0.0123, -0.0354,  0.0271,  ..., -0.0067,  0.0086, -0.0130],\n",
      "        [ 0.0090,  0.0256,  0.0047,  ..., -0.0015,  0.0345,  0.0252],\n",
      "        [ 0.0072, -0.0231, -0.0263,  ...,  0.0135, -0.0356,  0.0076]]), tensor([-0.0043,  0.0244, -0.0186,  0.0201, -0.0008,  0.0112, -0.0338, -0.0048,\n",
      "        -0.0224,  0.0197])])\n",
      "odict_values([tensor([[-0.0202, -0.0072,  0.0322,  ...,  0.0074,  0.0303, -0.0296],\n",
      "        [-0.0186,  0.0064, -0.0356,  ...,  0.0092, -0.0141,  0.0014],\n",
      "        [ 0.0140, -0.0160, -0.0340,  ..., -0.0065,  0.0020,  0.0100],\n",
      "        ...,\n",
      "        [ 0.0123, -0.0354,  0.0271,  ..., -0.0067,  0.0086, -0.0130],\n",
      "        [ 0.0090,  0.0256,  0.0047,  ..., -0.0015,  0.0345,  0.0252],\n",
      "        [ 0.0072, -0.0231, -0.0263,  ...,  0.0135, -0.0356,  0.0076]]), tensor([ 0.0209,  0.0499, -0.0247,  0.0135, -0.0073,  0.0046, -0.0396, -0.0109,\n",
      "        -0.0285,  0.0129])])\n",
      "Average Global Accurancy:  0.933585313174946\n",
      "Average Global Trainning Accurancy:  0.9420368364030336\n",
      "Average Global Trainning Loss:  0.633952087424386\n"
     ]
    }
   ],
   "source": [
    "server.evaluate()\n",
    "server.prev_per_values = []\n",
    "            \n",
    "server.attn_optimizer.zero_grad()\n",
    "\n",
    "print(server.users[0].model.state_dict().values())\n",
    "for i, user in enumerate(server.users):\n",
    "    if glob_iter != 0:\n",
    "        user.prev_per_values = [0]*len(user.per_values)\n",
    "        server.copy_value(user.per_values, user.prev_per_values, if_grad=True)\n",
    "    user.train(server.local_epochs)\n",
    "    #get user embedding vec\n",
    "    user.emb(server.emb_layer)\n",
    "\n",
    "print(server.users[0].model.state_dict().values())\n",
    "server.evaluate()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cpu..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 3it [00:00, 503.03it/s, center_shift=0.000000, iteration=3, tol=0.000100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "cluster users:\n",
      "f_00006\n",
      "f_00007\n",
      "f_00016\n",
      "===================================\n",
      "cluster users:\n",
      "f_00005\n",
      "f_00015\n",
      "===================================\n",
      "cluster users:\n",
      "f_00008\n",
      "f_00009\n",
      "f_00018\n",
      "f_00019\n",
      "===================================\n",
      "cluster users:\n",
      "f_00003\n",
      "f_00013\n",
      "===================================\n",
      "cluster users:\n",
      "f_00011\n",
      "===================================\n",
      "cluster users:\n",
      "f_00001\n",
      "===================================\n",
      "cluster users:\n",
      "f_00002\n",
      "f_00012\n",
      "===================================\n",
      "cluster users:\n",
      "f_00017\n",
      "===================================\n",
      "cluster users:\n",
      "f_00004\n",
      "f_00014\n",
      "===================================\n",
      "cluster users:\n",
      "f_00000\n",
      "f_00010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "server.form_cluster()\n",
    "for cluster in server.clusters:\n",
    "    print(\"===================================\")\n",
    "    print(\"cluster users:\")\n",
    "    for user in cluster.users:\n",
    "        print(user.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[-0.0003,  0.0191, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0237,  0.0103, -0.0219,  ...,  0.0088, -0.0009,  0.0009],\n",
      "        [ 0.0144, -0.0336, -0.0346,  ..., -0.0222, -0.0025, -0.0138],\n",
      "        [-0.0195, -0.0118,  0.0230,  ..., -0.0202,  0.0172,  0.0355]],\n",
      "       device='cuda:0')), ('fc1.bias', tensor([ 0.0421,  0.0745, -0.0228, -0.0464, -0.0416, -0.0250,  0.0211,  0.0023,\n",
      "         0.0199,  0.0073], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(server.users[0].model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spfe\n"
     ]
    }
   ],
   "source": [
    "model_path = \"ne\"\n",
    "i = 10\n",
    "\n",
    "alg = \"pfe\"\n",
    "local_ep1 = 10\n",
    "print(\"s{}\".format(alg,local_ep1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "from utils.plot_utils import *\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "flag = 1\n",
    "if(flag==0): # plot for MNIST convex \n",
    "    numusers = 5\n",
    "    num_glob_iters = 800\n",
    "    dataset = \"Mnist\"\n",
    "    local_ep = [20,20,20,20]\n",
    "    lamda = [15,15,15,15]\n",
    "    learning_rate = [0.005, 0.005, 0.005, 0.005]\n",
    "    beta =  [1.0, 1.0, 0.001, 1.0]\n",
    "    batch_size = [20,20,20,20]\n",
    "    K = [5,5,5,5,5,5]\n",
    "    personal_learning_rate = [0.1,0.1,0.1,0.1]\n",
    "    algorithms = [ \"pFedMe_p\",\"pFedMe\",\"PerAvg_p\",\"FedAvg\"]\n",
    "    plot_summary_one_figure_mnist_Compare(num_users=numusers, loc_ep1=local_ep, Numb_Glob_Iters=num_glob_iters, lamb=lamda,\n",
    "                               learning_rate=learning_rate, beta = beta, algorithms_list=algorithms, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate)\n",
    "\n",
    "if(flag==1): # plot for Synthetic covex\n",
    "    numusers = 10\n",
    "    num_glob_iters = 600\n",
    "    dataset = \"Synthetic\"\n",
    "    local_ep = [20,20,20]\n",
    "    lamda = [30,30,30]\n",
    "    learning_rate = [0.005, 0.005, 0.005]\n",
    "    beta =  [2.0, 2.0, 2.0]\n",
    "    batch_size = [20,20,20]\n",
    "    K = [5,5,5]\n",
    "    personal_learning_rate = [0.01,0.01,0.01] \n",
    "    algorithms = [ \"pFedMe_p\",\"pFedMe\",\"pFedTrans_p\"]\n",
    "    plot_summary_one_figure_synthetic_Compare(num_users=numusers, loc_ep1=local_ep, Numb_Glob_Iters=num_glob_iters, lamb=lamda,\n",
    "                               learning_rate=learning_rate, beta = beta, algorithms_list=algorithms, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_values([tensor([[-0.0003,  0.0191, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0237,  0.0103, -0.0219,  ...,  0.0088, -0.0009,  0.0009],\n",
      "        [ 0.0144, -0.0336, -0.0346,  ..., -0.0222, -0.0025, -0.0138],\n",
      "        [-0.0195, -0.0118,  0.0230,  ..., -0.0202,  0.0172,  0.0355]],\n",
      "       device='cuda:0'), tensor([ 0.0421,  0.0745, -0.0228, -0.0464, -0.0416, -0.0250,  0.0211,  0.0023,\n",
      "         0.0199,  0.0073], device='cuda:0')])\n",
      "odict_values([tensor([[-0.0003,  0.0191, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0237,  0.0103, -0.0219,  ...,  0.0088, -0.0009,  0.0009],\n",
      "        [ 0.0144, -0.0336, -0.0346,  ..., -0.0222, -0.0025, -0.0138],\n",
      "        [-0.0195, -0.0118,  0.0230,  ..., -0.0202,  0.0172,  0.0355]],\n",
      "       device='cuda:0'), tensor([-0.0134,  0.0243, -0.0113, -0.0358, -0.0281,  0.0018,  0.0321,  0.0083,\n",
      "         0.0353,  0.0183], device='cuda:0')])\n",
      "Average Personal Accurancy:  0.70707343412527\n",
      "Average Personal Trainning Accurancy:  0.9689418562657999\n",
      "Average Personal Trainning Loss:  0.25998027301428767\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(server.users[0].model.state_dict().values())\n",
    "for cluster in server.clusters:\n",
    "    for user in cluster.users:\n",
    "        alpha = server.alpha_layer(user.emb_vec)\n",
    "        alpha = torch.sigmoid(alpha)\n",
    "        user.per_values = server.weighted_agg_model([cluster.per_values, user.per_values], [1-alpha,alpha])\n",
    "        user.merge_base_per_model()\n",
    "    cluster.merge_base_per_model()\n",
    "\n",
    "print(server.users[0].model.state_dict().values())\n",
    "server.evaluate_personalized_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, user in enumerate(server.users):\n",
    "    user.prev_per_values = [0]*len(user.per_values)\n",
    "    server.copy_value(user.per_values, user.prev_per_values, if_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.0323,  0.0191,  0.0091,  ..., -0.0150,  0.0041,  0.0090],\n",
      "        [ 0.0253, -0.0168,  0.0191,  ...,  0.0348, -0.0115, -0.0151],\n",
      "        [-0.0091,  0.0183,  0.0120,  ...,  0.0353, -0.0333,  0.0139],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0343, -0.0147,  ..., -0.0248,  0.0140,  0.0297],\n",
      "        [-0.0180,  0.0150,  0.0291,  ...,  0.0168, -0.0131,  0.0281],\n",
      "        [-0.0081, -0.0231, -0.0033,  ...,  0.0317, -0.0223, -0.0356]],\n",
      "       device='cuda:0'), tensor([-0.0037,  0.0056,  0.0282, -0.0248,  0.0320,  0.0182,  0.0168, -0.0324,\n",
      "         0.0074,  0.0250], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(server.users[0].prev_per_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep cost time : {} 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time1 = time.time()\n",
    "time2 = tijkjme.time()\n",
    "cost_time = time2-time1 \n",
    "print(\"ep cost time : {}\", str(cost_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, user in enumerate(server.users):\n",
    "    #if g_iter != 0:\n",
    "        #user.prev_per_values = [0]*len(user.per_values)\n",
    "        #server.copy_value(user.prev_per_values, user.per_values)\n",
    "    user.train(server.local_epochs)\n",
    "    #get user embedding vec\n",
    "    user.emb(server.emb_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.0323,  0.0191,  0.0091,  ..., -0.0150,  0.0041,  0.0090],\n",
      "        [ 0.0253, -0.0168,  0.0191,  ...,  0.0348, -0.0115, -0.0151],\n",
      "        [-0.0091,  0.0183,  0.0120,  ...,  0.0353, -0.0333,  0.0139],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0343, -0.0147,  ..., -0.0248,  0.0140,  0.0297],\n",
      "        [-0.0180,  0.0150,  0.0291,  ...,  0.0168, -0.0131,  0.0281],\n",
      "        [-0.0081, -0.0231, -0.0033,  ...,  0.0317, -0.0223, -0.0356]],\n",
      "       device='cuda:0'), tensor([-0.0037,  0.0056,  0.0282, -0.0248,  0.0320,  0.0182,  0.0168, -0.0324,\n",
      "         0.0074,  0.0250], device='cuda:0')]\n",
      "[tensor([[ 0.0323,  0.0191,  0.0091,  ..., -0.0150,  0.0041,  0.0090],\n",
      "        [ 0.0253, -0.0168,  0.0191,  ...,  0.0348, -0.0115, -0.0151],\n",
      "        [-0.0091,  0.0183,  0.0120,  ...,  0.0353, -0.0333,  0.0139],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0343, -0.0147,  ..., -0.0248,  0.0140,  0.0297],\n",
      "        [-0.0180,  0.0150,  0.0291,  ...,  0.0168, -0.0131,  0.0281],\n",
      "        [-0.0081, -0.0231, -0.0033,  ...,  0.0316, -0.0223, -0.0356]],\n",
      "       device='cuda:0'), tensor([ 0.0205,  0.0334,  0.0209, -0.0309,  0.0258,  0.0128,  0.0096, -0.0392,\n",
      "         0.0011,  0.0181], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "user = server.users[0]\n",
    "print(user.prev_per_values)\n",
    "print(user.per_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7850]) tensor([[ 0.0323,  0.0191,  0.0091,  ..., -0.0392,  0.0011,  0.0181]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35956/425959943.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\MSI\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\MSI\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "criteria = nn.MSELoss()\n",
    "total_train = 0\n",
    "server.attn_optimizer.zero_grad()\n",
    "for user in server.users:\n",
    "    total_train += user.train_samples\n",
    "targets = None \n",
    "preds = None\n",
    "user = server.users[0]\n",
    "if preds == None and targets == None:\n",
    "    preds =  server.copy_value(nn.utils.parameters_to_vector(user.prev_per_values).unsqueeze(0), if_grad=True, if_tensor=True)\n",
    "    targets =  server.copy_value(nn.utils.parameters_to_vector(server.copy_value(user.per_values)).unsqueeze(0), if_tensor=True)\n",
    "else:\n",
    "    preds =  torch.cat((preds, nn.utils.parameters_to_vector(user.prev_per_values).unsqueeze(0)), 0)\n",
    "    targets =  torch.cat((targets, nn.utils.parameters_to_vector(server.copy_value(user.per_values)).unsqueeze(0)), 0)\n",
    "\n",
    "#for i, user in enumerate(server.users):\n",
    "\n",
    "    #ratio = user.train_samples / total_train\n",
    "    #if preds == None and targets == None:\n",
    "        #preds =  nn.utils.parameters_to_vector(user.prev_per_values).unsqueeze(0) \n",
    "        #targets =  nn.utils.parameters_to_vector(server.copy_value(user.per_values)).unsqueeze(0) \n",
    "    #else:\n",
    "        #preds =  torch.cat((preds, nn.utils.parameters_to_vector(user.prev_per_values).unsqueeze(0)), 0)\n",
    "        #targets =  torch.cat((targets, ratio * nn.utils.parameters_to_vector(server.copy_value(user.per_values)).unsqueeze(0)), 0)\n",
    "    #if i >= 5:\n",
    "        #break\n",
    "\n",
    "print(preds.size(), targets)\n",
    "loss = criteria(preds, targets)\n",
    "loss.backward()\n",
    "server.attn_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.attn_optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda:0..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 2it [00:00, 511.16it/s, center_shift=0.000000, iteration=2, tol=0.000100]\n"
     ]
    }
   ],
   "source": [
    "if g_iter % 5 == 0:\n",
    "    server.form_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in server.clusters:\n",
    "    cluster.avg_update_model()\n",
    "    cluster.emb(server.emb_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in server.clusters:\n",
    "    server.intra_cluster_agg(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.inter_cluster_agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0237,  0.0103, -0.0219,  ...,  0.0088, -0.0009,  0.0009],\n",
      "        [ 0.0144, -0.0336, -0.0346,  ..., -0.0222, -0.0025, -0.0138],\n",
      "        [-0.0195, -0.0118,  0.0230,  ..., -0.0202,  0.0172,  0.0355]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([-0.0200,  0.0342,  0.0464, -0.0196, -0.0387, -0.0235,  0.0221,  0.0032,\n",
      "         0.0200,  0.0073], device='cuda:0', grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "user = server.users[1]\n",
    "print(user.per_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in server.clusters:\n",
    "    for user in cluster.users:\n",
    "        alpha = server.alpha_layer(user.emb_vec)\n",
    "        alpha = torch.sigmoid(alpha)\n",
    "        user.per_values = server.weighted_agg_model([cluster.per_values, user.per_values], [1-alpha,alpha], use_grad=True)\n",
    "        user.merge_base_per_model()\n",
    "    cluster.merge_base_per_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Global Accurancy:  0.828023758099352\n",
      "Average Global Trainning Accurancy:  0.8423618634886241\n",
      "Average Global Trainning Loss:  1.2799933238251626\n"
     ]
    }
   ],
   "source": [
    "server.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import torchviz\n",
    "from torchviz import make_dot\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'E:\\工具软件\\graphviz\\\\bin'\n",
    "print(os.environ[\"PATH\"])\n",
    "dot = make_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1ccd20b5258b628543699ad079c0d4ef32c5d2797833541d65624ed3b1ba210"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('phd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
