{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26f16817310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "from FLAlgorithms.servers.serveravg import FedAvg\n",
    "from FLAlgorithms.servers.serverpFedMe import pFedMe\n",
    "from FLAlgorithms.servers.serverperavg import PerAvg\n",
    "from FLAlgorithms.trainmodel.models import *\n",
    "from utils.plot_utils import *\n",
    "import torch\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Running time:------------ 0\n",
      "Number of users / total users: 5  /  20\n",
      "Finished creating pFedMe server.\n",
      "-------------Round number:  0  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.05264578833693304\n",
      "Average Global Trainning Accurancy:  0.05200433369447454\n",
      "Average Global Trainning Loss:  2.5211355774873603\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9404117009750813\n",
      "Average Personal Trainning Loss:  0.6517832581426056\n",
      "-------------Round number:  1  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.44897408207343414\n",
      "Average Global Trainning Accurancy:  0.4528710725893825\n",
      "Average Global Trainning Loss:  1.577712544296226\n",
      "Average Personal Accurancy:  0.916036717062635\n",
      "Average Personal Trainning Accurancy:  0.9214517876489707\n",
      "Average Personal Trainning Loss:  0.5101814311348862\n",
      "-------------Round number:  2  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7103131749460043\n",
      "Average Global Trainning Accurancy:  0.7097327555074034\n",
      "Average Global Trainning Loss:  1.0448212738973908\n",
      "Average Personal Accurancy:  0.9184665226781857\n",
      "Average Personal Trainning Accurancy:  0.9245214879017696\n",
      "Average Personal Trainning Loss:  0.4332420429024467\n",
      "-------------Round number:  3  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7904967602591793\n",
      "Average Global Trainning Accurancy:  0.7864752618273745\n",
      "Average Global Trainning Loss:  0.8412442302049477\n",
      "Average Personal Accurancy:  0.9230561555075594\n",
      "Average Personal Trainning Accurancy:  0.9313831708197905\n",
      "Average Personal Trainning Loss:  0.3887731814565276\n",
      "-------------Round number:  4  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7796976241900648\n",
      "Average Global Trainning Accurancy:  0.7743770314192849\n",
      "Average Global Trainning Loss:  0.7373262448791306\n",
      "Average Personal Accurancy:  0.91792656587473\n",
      "Average Personal Trainning Accurancy:  0.9274106175514626\n",
      "Average Personal Trainning Loss:  0.3613655748846041\n",
      "-------------Round number:  5  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7634989200863931\n",
      "Average Global Trainning Accurancy:  0.7647165041531239\n",
      "Average Global Trainning Loss:  0.7502073740520043\n",
      "Average Personal Accurancy:  0.916036717062635\n",
      "Average Personal Trainning Accurancy:  0.9254243409172986\n",
      "Average Personal Trainning Loss:  0.35575580700247156\n",
      "-------------Round number:  6  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7562095032397408\n",
      "Average Global Trainning Accurancy:  0.7569519682195739\n",
      "Average Global Trainning Loss:  0.7693445957193481\n",
      "Average Personal Accurancy:  0.9109071274298056\n",
      "Average Personal Trainning Accurancy:  0.9169375225713254\n",
      "Average Personal Trainning Loss:  0.3762878880857259\n",
      "-------------Round number:  7  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7302915766738661\n",
      "Average Global Trainning Accurancy:  0.7328457927049477\n",
      "Average Global Trainning Loss:  0.8322894977033677\n",
      "Average Personal Accurancy:  0.8998380129589633\n",
      "Average Personal Trainning Accurancy:  0.906644998194294\n",
      "Average Personal Trainning Loss:  0.38841393588897166\n",
      "-------------Round number:  8  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7213822894168467\n",
      "Average Global Trainning Accurancy:  0.7306789454676779\n",
      "Average Global Trainning Loss:  0.7939320871140303\n",
      "Average Personal Accurancy:  0.8817494600431965\n",
      "Average Personal Trainning Accurancy:  0.8967136150234741\n",
      "Average Personal Trainning Loss:  0.3905887183578232\n",
      "-------------Round number:  9  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8088552915766739\n",
      "Average Global Trainning Accurancy:  0.8198808234019501\n",
      "Average Global Trainning Loss:  0.5989892366518824\n",
      "Average Personal Accurancy:  0.8984881209503239\n",
      "Average Personal Trainning Accurancy:  0.9107981220657277\n",
      "Average Personal Trainning Loss:  0.3508320398905855\n",
      "-------------Round number:  10  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7991360691144709\n",
      "Average Global Trainning Accurancy:  0.8099494402311304\n",
      "Average Global Trainning Loss:  0.6124328855746659\n",
      "Average Personal Accurancy:  0.9017278617710583\n",
      "Average Personal Trainning Accurancy:  0.9116106897797038\n",
      "Average Personal Trainning Loss:  0.3457302811258577\n",
      "-------------Round number:  11  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8696004319654428\n",
      "Average Global Trainning Accurancy:  0.8799205489346335\n",
      "Average Global Trainning Loss:  0.4612406258464247\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9327374503430842\n",
      "Average Personal Trainning Loss:  0.301687188938922\n",
      "-------------Round number:  12  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8793196544276458\n",
      "Average Global Trainning Accurancy:  0.8939147706753341\n",
      "Average Global Trainning Loss:  0.41195794433064736\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.933911159263272\n",
      "Average Personal Trainning Loss:  0.28287861811292436\n",
      "-------------Round number:  13  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8828293736501079\n",
      "Average Global Trainning Accurancy:  0.8922896352473817\n",
      "Average Global Trainning Loss:  0.39315162182026453\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9375225713253882\n",
      "Average Personal Trainning Loss:  0.26680311738217766\n",
      "-------------Round number:  14  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8814794816414687\n",
      "Average Global Trainning Accurancy:  0.8884073672806068\n",
      "Average Global Trainning Loss:  0.39227649803065184\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9370711448176237\n",
      "Average Personal Trainning Loss:  0.26487452547315143\n",
      "-------------Round number:  15  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8814794816414687\n",
      "Average Global Trainning Accurancy:  0.8944564824846515\n",
      "Average Global Trainning Loss:  0.3732548662366829\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9352654387865655\n",
      "Average Personal Trainning Loss:  0.2620346383438854\n",
      "-------------Round number:  16  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8901187904967602\n",
      "Average Global Trainning Accurancy:  0.9016793066088841\n",
      "Average Global Trainning Loss:  0.35969170390935357\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9398699891657638\n",
      "Average Personal Trainning Loss:  0.25448532352468173\n",
      "-------------Round number:  17  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8941684665226782\n",
      "Average Global Trainning Accurancy:  0.9054712892741061\n",
      "Average Global Trainning Loss:  0.3550679326358794\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9420368364030336\n",
      "Average Personal Trainning Loss:  0.2488426905584146\n",
      "-------------Round number:  18  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8914686825053996\n",
      "Average Global Trainning Accurancy:  0.8983387504514265\n",
      "Average Global Trainning Loss:  0.3624119012955941\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9393282773564464\n",
      "Average Personal Trainning Loss:  0.24867146589472733\n",
      "-------------Round number:  19  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.890658747300216\n",
      "Average Global Trainning Accurancy:  0.9018598772119899\n",
      "Average Global Trainning Loss:  0.355411638374921\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9385157096424702\n",
      "Average Personal Trainning Loss:  0.2479554875829496\n",
      "-------------Round number:  20  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.896328293736501\n",
      "Average Global Trainning Accurancy:  0.9044781509570242\n",
      "Average Global Trainning Loss:  0.34986603565705127\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9413145539906104\n",
      "Average Personal Trainning Loss:  0.24266156396008262\n",
      "-------------Round number:  21  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8936285097192225\n",
      "Average Global Trainning Accurancy:  0.9024015890213073\n",
      "Average Global Trainning Loss:  0.3419752854567308\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9403214156735283\n",
      "Average Personal Trainning Loss:  0.23922384530036792\n",
      "-------------Round number:  22  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8855291576673866\n",
      "Average Global Trainning Accurancy:  0.8981581798483207\n",
      "Average Global Trainning Loss:  0.34862399557602025\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.936800288912965\n",
      "Average Personal Trainning Loss:  0.24423419460573537\n",
      "-------------Round number:  23  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8874190064794817\n",
      "Average Global Trainning Accurancy:  0.8968039003250271\n",
      "Average Global Trainning Loss:  0.36706785434159445\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9384254243409172\n",
      "Average Personal Trainning Loss:  0.2547747831389378\n",
      "-------------Round number:  24  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8979481641468683\n",
      "Average Global Trainning Accurancy:  0.90465872156013\n",
      "Average Global Trainning Loss:  0.3513246855179555\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9380642831347057\n",
      "Average Personal Trainning Loss:  0.24927906216848367\n",
      "-------------Round number:  25  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8971382289416847\n",
      "Average Global Trainning Accurancy:  0.9082701336222463\n",
      "Average Global Trainning Loss:  0.34035782075264087\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.942578548212351\n",
      "Average Personal Trainning Loss:  0.23614665066218626\n",
      "-------------Round number:  26  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8936285097192225\n",
      "Average Global Trainning Accurancy:  0.9074575659082701\n",
      "Average Global Trainning Loss:  0.3337313954087103\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9431202600216685\n",
      "Average Personal Trainning Loss:  0.23339153825698583\n",
      "-------------Round number:  27  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8920086393088553\n",
      "Average Global Trainning Accurancy:  0.9034850126399422\n",
      "Average Global Trainning Loss:  0.3386727963685559\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9409534127843987\n",
      "Average Personal Trainning Loss:  0.23421484057590736\n",
      "-------------Round number:  28  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8898488120950324\n",
      "Average Global Trainning Accurancy:  0.9049295774647887\n",
      "Average Global Trainning Loss:  0.33740542967339293\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9434814012278802\n",
      "Average Personal Trainning Loss:  0.22984786221334416\n",
      "-------------Round number:  29  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8744600431965442\n",
      "Average Global Trainning Accurancy:  0.8822679667750091\n",
      "Average Global Trainning Loss:  0.38296410700783223\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9358974358974359\n",
      "Average Personal Trainning Loss:  0.25177729349353334\n",
      "-------------Round number:  30  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.865280777537797\n",
      "Average Global Trainning Accurancy:  0.8755868544600939\n",
      "Average Global Trainning Loss:  0.3928326695952961\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.9328277356446371\n",
      "Average Personal Trainning Loss:  0.25459602000524784\n",
      "-------------Round number:  31  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8868790496760259\n",
      "Average Global Trainning Accurancy:  0.8926507764535934\n",
      "Average Global Trainning Loss:  0.3498586514832182\n",
      "Average Personal Accurancy:  0.9235961123110151\n",
      "Average Personal Trainning Accurancy:  0.9335500180570603\n",
      "Average Personal Trainning Loss:  0.24926671847491197\n",
      "-------------Round number:  32  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8830993520518359\n",
      "Average Global Trainning Accurancy:  0.894005055976887\n",
      "Average Global Trainning Loss:  0.3404070632730679\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9366197183098591\n",
      "Average Personal Trainning Loss:  0.2421566848506907\n",
      "-------------Round number:  33  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8793196544276458\n",
      "Average Global Trainning Accurancy:  0.8863308053448898\n",
      "Average Global Trainning Loss:  0.35558780051603694\n",
      "Average Personal Accurancy:  0.9222462203023758\n",
      "Average Personal Trainning Accurancy:  0.9329180209461899\n",
      "Average Personal Trainning Loss:  0.24969720478822455\n",
      "-------------Round number:  34  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8798596112311015\n",
      "Average Global Trainning Accurancy:  0.8884976525821596\n",
      "Average Global Trainning Loss:  0.3475888887007945\n",
      "Average Personal Accurancy:  0.92170626349892\n",
      "Average Personal Trainning Accurancy:  0.9330083062477429\n",
      "Average Personal Trainning Loss:  0.24648566227090105\n",
      "-------------Round number:  35  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8833693304535637\n",
      "Average Global Trainning Accurancy:  0.8933730588660166\n",
      "Average Global Trainning Loss:  0.35205309569254467\n",
      "Average Personal Accurancy:  0.9235961123110151\n",
      "Average Personal Trainning Accurancy:  0.9345431563741423\n",
      "Average Personal Trainning Loss:  0.2512567423017673\n",
      "-------------Round number:  36  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8790496760259179\n",
      "Average Global Trainning Accurancy:  0.8898519321054532\n",
      "Average Global Trainning Loss:  0.3525694368031103\n",
      "Average Personal Accurancy:  0.9214362850971922\n",
      "Average Personal Trainning Accurancy:  0.9316540267244493\n",
      "Average Personal Trainning Loss:  0.2516775520410121\n",
      "-------------Round number:  37  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8728401727861771\n",
      "Average Global Trainning Accurancy:  0.8847959552184904\n",
      "Average Global Trainning Loss:  0.367320459213615\n",
      "Average Personal Accurancy:  0.9157667386609071\n",
      "Average Personal Trainning Accurancy:  0.9279523293607801\n",
      "Average Personal Trainning Loss:  0.2613381895187229\n",
      "-------------Round number:  38  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8849892008639308\n",
      "Average Global Trainning Accurancy:  0.8981581798483207\n",
      "Average Global Trainning Loss:  0.3386463235543066\n",
      "Average Personal Accurancy:  0.9208963282937365\n",
      "Average Personal Trainning Accurancy:  0.9332791621524016\n",
      "Average Personal Trainning Loss:  0.24460873753639625\n",
      "-------------Round number:  39  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.896598272138229\n",
      "Average Global Trainning Accurancy:  0.9060130010834236\n",
      "Average Global Trainning Loss:  0.32267345181868456\n",
      "Average Personal Accurancy:  0.9230561555075594\n",
      "Average Personal Trainning Accurancy:  0.9367100036114121\n",
      "Average Personal Trainning Loss:  0.23643170181445242\n",
      "-------------Round number:  40  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9079373650107991\n",
      "Average Global Trainning Accurancy:  0.9194655110148068\n",
      "Average Global Trainning Loss:  0.2896215370649377\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9408631274828458\n",
      "Average Personal Trainning Loss:  0.2240949736127099\n",
      "-------------Round number:  41  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9011879049676026\n",
      "Average Global Trainning Accurancy:  0.9155832430480317\n",
      "Average Global Trainning Loss:  0.29511677310457296\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9380642831347057\n",
      "Average Personal Trainning Loss:  0.22830673002860916\n",
      "-------------Round number:  42  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8987580993520519\n",
      "Average Global Trainning Accurancy:  0.9119718309859155\n",
      "Average Global Trainning Loss:  0.3014668540086674\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9395991332611051\n",
      "Average Personal Trainning Loss:  0.22504226392509705\n",
      "-------------Round number:  43  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.892548596112311\n",
      "Average Global Trainning Accurancy:  0.9070964247020585\n",
      "Average Global Trainning Loss:  0.31636846948074665\n",
      "Average Personal Accurancy:  0.9165766738660908\n",
      "Average Personal Trainning Accurancy:  0.9352654387865655\n",
      "Average Personal Trainning Loss:  0.23721956009897527\n",
      "-------------Round number:  44  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9011879049676026\n",
      "Average Global Trainning Accurancy:  0.9142289635247381\n",
      "Average Global Trainning Loss:  0.29379441084608615\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.94068255687974\n",
      "Average Personal Trainning Loss:  0.22311051996574802\n",
      "-------------Round number:  45  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9049676025917927\n",
      "Average Global Trainning Accurancy:  0.9189237992054894\n",
      "Average Global Trainning Loss:  0.28331322633819744\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9430299747201155\n",
      "Average Personal Trainning Loss:  0.21630239986090422\n",
      "-------------Round number:  46  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9009179265658748\n",
      "Average Global Trainning Accurancy:  0.9140483929216323\n",
      "Average Global Trainning Loss:  0.2956558177943865\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.9407728421812929\n",
      "Average Personal Trainning Loss:  0.223203825063764\n",
      "-------------Round number:  47  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.902267818574514\n",
      "Average Global Trainning Accurancy:  0.9161249548573492\n",
      "Average Global Trainning Loss:  0.2941679618727993\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9428494041170098\n",
      "Average Personal Trainning Loss:  0.22068862116005328\n",
      "-------------Round number:  48  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9025377969762419\n",
      "Average Global Trainning Accurancy:  0.9147706753340556\n",
      "Average Global Trainning Loss:  0.3047497915679171\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9422174070061394\n",
      "Average Personal Trainning Loss:  0.2276358061983681\n",
      "-------------Round number:  49  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.9178403755868545\n",
      "Average Global Trainning Loss:  0.2979360065894163\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9418562657999278\n",
      "Average Personal Trainning Loss:  0.22531697723399693\n",
      "-------------Round number:  50  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9014578833693304\n",
      "Average Global Trainning Accurancy:  0.9162152401589021\n",
      "Average Global Trainning Loss:  0.29990786755287335\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9417659804983749\n",
      "Average Personal Trainning Loss:  0.22323880620965375\n",
      "-------------Round number:  51  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8982181425485961\n",
      "Average Global Trainning Accurancy:  0.9128746840014446\n",
      "Average Global Trainning Loss:  0.2983153767859561\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9414048392921632\n",
      "Average Personal Trainning Loss:  0.22043484804560537\n",
      "-------------Round number:  52  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9087473002159827\n",
      "Average Global Trainning Accurancy:  0.9228060671722643\n",
      "Average Global Trainning Loss:  0.2734371914076607\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9447453954496208\n",
      "Average Personal Trainning Loss:  0.2132451094286069\n",
      "-------------Round number:  53  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9247923438064283\n",
      "Average Global Trainning Loss:  0.27200005484126716\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9434814012278802\n",
      "Average Personal Trainning Loss:  0.2130460012428336\n",
      "-------------Round number:  54  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9259660527266161\n",
      "Average Global Trainning Loss:  0.26853756062516926\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9456482484651498\n",
      "Average Personal Trainning Loss:  0.2059286495717091\n",
      "-------------Round number:  55  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9117170626349892\n",
      "Average Global Trainning Accurancy:  0.927049476345251\n",
      "Average Global Trainning Loss:  0.2601618134790312\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9462802455760202\n",
      "Average Personal Trainning Loss:  0.20453777981389942\n",
      "-------------Round number:  56  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9071274298056156\n",
      "Average Global Trainning Accurancy:  0.924070061394005\n",
      "Average Global Trainning Loss:  0.26472585009254246\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9422174070061394\n",
      "Average Personal Trainning Loss:  0.2112998314909489\n",
      "-------------Round number:  57  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906047516198704\n",
      "Average Global Trainning Accurancy:  0.9226254965691585\n",
      "Average Global Trainning Loss:  0.26288558171948356\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9449259660527266\n",
      "Average Personal Trainning Loss:  0.20468012905155292\n",
      "-------------Round number:  58  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.908207343412527\n",
      "Average Global Trainning Accurancy:  0.923167208378476\n",
      "Average Global Trainning Loss:  0.26175168121106446\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9451065366558324\n",
      "Average Personal Trainning Loss:  0.20174539386257448\n",
      "-------------Round number:  59  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9068574514038877\n",
      "Average Global Trainning Accurancy:  0.9237992054893464\n",
      "Average Global Trainning Loss:  0.2640494597694339\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.946460816179126\n",
      "Average Personal Trainning Loss:  0.20334174203373284\n",
      "-------------Round number:  60  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9046976241900648\n",
      "Average Global Trainning Accurancy:  0.9213615023474179\n",
      "Average Global Trainning Loss:  0.26887696811377076\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.946460816179126\n",
      "Average Personal Trainning Loss:  0.20301712493510743\n",
      "-------------Round number:  61  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.9226254965691585\n",
      "Average Global Trainning Loss:  0.2653613298883848\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9438425424340917\n",
      "Average Personal Trainning Loss:  0.2036771157796136\n",
      "-------------Round number:  62  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9017278617710583\n",
      "Average Global Trainning Accurancy:  0.9199169375225713\n",
      "Average Global Trainning Loss:  0.2664894773539071\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9442939689418562\n",
      "Average Personal Trainning Loss:  0.20283900102840602\n",
      "-------------Round number:  63  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9030777537796977\n",
      "Average Global Trainning Accurancy:  0.9177500902853015\n",
      "Average Global Trainning Loss:  0.2698260218109539\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9442939689418562\n",
      "Average Personal Trainning Loss:  0.208551904878792\n",
      "-------------Round number:  64  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9001079913606912\n",
      "Average Global Trainning Accurancy:  0.9174792343806428\n",
      "Average Global Trainning Loss:  0.2710939616061755\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9434814012278802\n",
      "Average Personal Trainning Loss:  0.208127259777616\n",
      "-------------Round number:  65  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9055075593952484\n",
      "Average Global Trainning Accurancy:  0.9224449259660528\n",
      "Average Global Trainning Loss:  0.26041895906690143\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9444745395449621\n",
      "Average Personal Trainning Loss:  0.20403052013503295\n",
      "-------------Round number:  66  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9052375809935205\n",
      "Average Global Trainning Accurancy:  0.9244312026002167\n",
      "Average Global Trainning Loss:  0.2608208344618996\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9459191043698086\n",
      "Average Personal Trainning Loss:  0.20171444645940548\n",
      "-------------Round number:  67  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.908207343412527\n",
      "Average Global Trainning Accurancy:  0.9266883351390394\n",
      "Average Global Trainning Loss:  0.25823216353912737\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9465511014806789\n",
      "Average Personal Trainning Loss:  0.20183442275246027\n",
      "-------------Round number:  68  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9046976241900648\n",
      "Average Global Trainning Accurancy:  0.9241603466955579\n",
      "Average Global Trainning Loss:  0.2608840518068346\n",
      "Average Personal Accurancy:  0.9230561555075594\n",
      "Average Personal Trainning Accurancy:  0.9445648248465149\n",
      "Average Personal Trainning Loss:  0.20398833115378973\n",
      "-------------Round number:  69  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9033477321814255\n",
      "Average Global Trainning Accurancy:  0.9247923438064283\n",
      "Average Global Trainning Loss:  0.2628059648959462\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.945557963163597\n",
      "Average Personal Trainning Loss:  0.20348120372878295\n",
      "-------------Round number:  70  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9014578833693304\n",
      "Average Global Trainning Accurancy:  0.9244312026002167\n",
      "Average Global Trainning Loss:  0.2678078058696732\n",
      "Average Personal Accurancy:  0.9227861771058316\n",
      "Average Personal Trainning Accurancy:  0.9447453954496208\n",
      "Average Personal Trainning Loss:  0.2077658099790651\n",
      "-------------Round number:  71  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9057775377969762\n",
      "Average Global Trainning Accurancy:  0.9230769230769231\n",
      "Average Global Trainning Loss:  0.2742865036523226\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9427591188154568\n",
      "Average Personal Trainning Loss:  0.2134226381929397\n",
      "-------------Round number:  72  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9098272138228942\n",
      "Average Global Trainning Accurancy:  0.9247923438064283\n",
      "Average Global Trainning Loss:  0.26496077703198356\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9442939689418562\n",
      "Average Personal Trainning Loss:  0.20639837119673168\n",
      "-------------Round number:  73  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9071274298056156\n",
      "Average Global Trainning Accurancy:  0.9224449259660528\n",
      "Average Global Trainning Loss:  0.2788752276529772\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9437522571325389\n",
      "Average Personal Trainning Loss:  0.2138832783862631\n",
      "-------------Round number:  74  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9114470842332614\n",
      "Average Global Trainning Accurancy:  0.9214517876489707\n",
      "Average Global Trainning Loss:  0.27439259329010923\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9423076923076923\n",
      "Average Personal Trainning Loss:  0.21733047523925605\n",
      "-------------Round number:  75  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9273203322499097\n",
      "Average Global Trainning Loss:  0.26223998450337443\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9442939689418562\n",
      "Average Personal Trainning Loss:  0.2090790687635428\n",
      "-------------Round number:  76  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9294871794871795\n",
      "Average Global Trainning Loss:  0.2539334502104776\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9469122426868906\n",
      "Average Personal Trainning Loss:  0.201283916061473\n",
      "-------------Round number:  77  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9281328999638859\n",
      "Average Global Trainning Loss:  0.2550059408433776\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9466413867822319\n",
      "Average Personal Trainning Loss:  0.20034727218479145\n",
      "-------------Round number:  78  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.928945467677862\n",
      "Average Global Trainning Loss:  0.25223147529004153\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9452871072589383\n",
      "Average Personal Trainning Loss:  0.20047864435209012\n",
      "-------------Round number:  79  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.24487864562172715\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.19760858130050335\n",
      "-------------Round number:  80  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9303900325027086\n",
      "Average Global Trainning Loss:  0.2558119399489888\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9460996749729144\n",
      "Average Personal Trainning Loss:  0.20470043001901633\n",
      "-------------Round number:  81  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9300288912964969\n",
      "Average Global Trainning Loss:  0.2504520436924431\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9446551101480679\n",
      "Average Personal Trainning Loss:  0.20227343943972328\n",
      "-------------Round number:  82  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9308414590104731\n",
      "Average Global Trainning Loss:  0.2490276696235103\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9460093896713615\n",
      "Average Personal Trainning Loss:  0.20211156071545458\n",
      "-------------Round number:  83  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9329180209461899\n",
      "Average Global Trainning Loss:  0.24129308918918158\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9467316720837847\n",
      "Average Personal Trainning Loss:  0.19747053031328998\n",
      "-------------Round number:  84  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9306608884073673\n",
      "Average Global Trainning Loss:  0.24666702639716503\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9462802455760202\n",
      "Average Personal Trainning Loss:  0.19642790701037152\n",
      "-------------Round number:  85  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9306608884073673\n",
      "Average Global Trainning Loss:  0.24362783270133623\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9460996749729144\n",
      "Average Personal Trainning Loss:  0.19546930899298032\n",
      "-------------Round number:  86  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.933820873961719\n",
      "Average Global Trainning Loss:  0.23387964316850623\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9487179487179487\n",
      "Average Personal Trainning Loss:  0.19080727226943392\n",
      "-------------Round number:  87  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.933820873961719\n",
      "Average Global Trainning Loss:  0.2368287940281916\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.19023225452978287\n",
      "-------------Round number:  88  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9323763091368725\n",
      "Average Global Trainning Loss:  0.23600959157892065\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9480859516070783\n",
      "Average Personal Trainning Loss:  0.19133095346921272\n",
      "-------------Round number:  89  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9304803178042614\n",
      "Average Global Trainning Loss:  0.24301737092728648\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9470025279884435\n",
      "Average Personal Trainning Loss:  0.1968344112904591\n",
      "-------------Round number:  90  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9312026002166848\n",
      "Average Global Trainning Loss:  0.24337339831758983\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9463705308775732\n",
      "Average Personal Trainning Loss:  0.1963191943377009\n",
      "-------------Round number:  91  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9287648970747562\n",
      "Average Global Trainning Loss:  0.24895043336944744\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9465511014806789\n",
      "Average Personal Trainning Loss:  0.19721014450585725\n",
      "-------------Round number:  92  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9098272138228942\n",
      "Average Global Trainning Accurancy:  0.9251534850126399\n",
      "Average Global Trainning Loss:  0.25594355458169693\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9450162513542795\n",
      "Average Personal Trainning Loss:  0.20094501554600036\n",
      "-------------Round number:  93  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.9209100758396533\n",
      "Average Global Trainning Loss:  0.2690639309867619\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9422174070061394\n",
      "Average Personal Trainning Loss:  0.20642947289607033\n",
      "-------------Round number:  94  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9079373650107991\n",
      "Average Global Trainning Accurancy:  0.9256049115204045\n",
      "Average Global Trainning Loss:  0.2552082231217836\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9461899602744673\n",
      "Average Personal Trainning Loss:  0.19987142279760292\n",
      "-------------Round number:  95  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9103671706263499\n",
      "Average Global Trainning Accurancy:  0.9310220296135789\n",
      "Average Global Trainning Loss:  0.24138322019456482\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9478150957024196\n",
      "Average Personal Trainning Loss:  0.19209806994007314\n",
      "-------------Round number:  96  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.23015356701003295\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9497110870350307\n",
      "Average Personal Trainning Loss:  0.18706195317437477\n",
      "-------------Round number:  97  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9374322860238353\n",
      "Average Global Trainning Loss:  0.227734820254661\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.18393623239083942\n",
      "-------------Round number:  98  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9366197183098591\n",
      "Average Global Trainning Loss:  0.2296101138582295\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.18325773702713075\n",
      "-------------Round number:  99  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9351751534850127\n",
      "Average Global Trainning Loss:  0.2369660294499368\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.19117321869921453\n",
      "-------------Round number:  100  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9349042975803539\n",
      "Average Global Trainning Loss:  0.24015012929137325\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9492596605272662\n",
      "Average Personal Trainning Loss:  0.1941169471506523\n",
      "-------------Round number:  101  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.23428938766815638\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.18921559706798483\n",
      "-------------Round number:  102  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9330985915492958\n",
      "Average Global Trainning Loss:  0.23516757533885202\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9481762369086313\n",
      "Average Personal Trainning Loss:  0.19110579127307917\n",
      "-------------Round number:  103  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9373420007222825\n",
      "Average Global Trainning Loss:  0.22544775425892696\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.18295144810922828\n",
      "-------------Round number:  104  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.23012356742619178\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9490790899241603\n",
      "Average Personal Trainning Loss:  0.1864547757045075\n",
      "-------------Round number:  105  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9321054532322138\n",
      "Average Global Trainning Loss:  0.23108359819372967\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9471830985915493\n",
      "Average Personal Trainning Loss:  0.1886113732676508\n",
      "-------------Round number:  106  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9310220296135789\n",
      "Average Global Trainning Loss:  0.23414210095307422\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9465511014806789\n",
      "Average Personal Trainning Loss:  0.18992491860215782\n",
      "-------------Round number:  107  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9114470842332614\n",
      "Average Global Trainning Accurancy:  0.9316540267244493\n",
      "Average Global Trainning Loss:  0.2328437207278124\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9471830985915493\n",
      "Average Personal Trainning Loss:  0.18902151452888002\n",
      "-------------Round number:  108  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9311123149151318\n",
      "Average Global Trainning Loss:  0.23639462664911745\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9463705308775732\n",
      "Average Personal Trainning Loss:  0.19329796512448086\n",
      "-------------Round number:  109  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9330985915492958\n",
      "Average Global Trainning Loss:  0.23018015003583198\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.18684263219037783\n",
      "-------------Round number:  110  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9293066088840737\n",
      "Average Global Trainning Loss:  0.2404200594190141\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.946460816179126\n",
      "Average Personal Trainning Loss:  0.19493877263480724\n",
      "-------------Round number:  111  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9264174792343807\n",
      "Average Global Trainning Loss:  0.24760827711662603\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9449259660527266\n",
      "Average Personal Trainning Loss:  0.19749931757008396\n",
      "-------------Round number:  112  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9117170626349892\n",
      "Average Global Trainning Accurancy:  0.9312026002166848\n",
      "Average Global Trainning Loss:  0.24009597133582747\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9482665222101841\n",
      "Average Personal Trainning Loss:  0.1930108640373894\n",
      "-------------Round number:  113  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9296677500902853\n",
      "Average Global Trainning Loss:  0.24102481223478692\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.19362677026199665\n",
      "-------------Round number:  114  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9349945828819068\n",
      "Average Global Trainning Loss:  0.2323402964108771\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9490790899241603\n",
      "Average Personal Trainning Loss:  0.1874185977493567\n",
      "-------------Round number:  115  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9327374503430842\n",
      "Average Global Trainning Loss:  0.23871539533676417\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9503430841459011\n",
      "Average Personal Trainning Loss:  0.19019447401052952\n",
      "-------------Round number:  116  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9327374503430842\n",
      "Average Global Trainning Loss:  0.23343236061501219\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9491693752257132\n",
      "Average Personal Trainning Loss:  0.18964745000451427\n",
      "-------------Round number:  117  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9357168652943301\n",
      "Average Global Trainning Loss:  0.23069876150432242\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.949440231130372\n",
      "Average Personal Trainning Loss:  0.18732147933171947\n",
      "-------------Round number:  118  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9375225713253882\n",
      "Average Global Trainning Loss:  0.22369276758306247\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9499819429396894\n",
      "Average Personal Trainning Loss:  0.1841255427698402\n",
      "-------------Round number:  119  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9380642831347057\n",
      "Average Global Trainning Loss:  0.2221203132758893\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.18430930950788868\n",
      "-------------Round number:  120  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9371614301191766\n",
      "Average Global Trainning Loss:  0.2217282907934385\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9507042253521126\n",
      "Average Personal Trainning Loss:  0.18264092706781554\n",
      "-------------Round number:  121  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.21775922021008262\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17734600051984584\n",
      "-------------Round number:  122  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9385157096424702\n",
      "Average Global Trainning Loss:  0.21840541256856041\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.17898924370542163\n",
      "-------------Round number:  123  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.21610886837954812\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17854240199812657\n",
      "-------------Round number:  124  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9378837125315999\n",
      "Average Global Trainning Loss:  0.2210632743022639\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9515167930660888\n",
      "Average Personal Trainning Loss:  0.18053982101997\n",
      "-------------Round number:  125  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9381545684362586\n",
      "Average Global Trainning Loss:  0.2189359489267335\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.1772939586260552\n",
      "-------------Round number:  126  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9395088479595521\n",
      "Average Global Trainning Loss:  0.2160395232724472\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17522053771950613\n",
      "-------------Round number:  127  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.936800288912965\n",
      "Average Global Trainning Loss:  0.22195012460076968\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9520585048754063\n",
      "Average Personal Trainning Loss:  0.1797590493380959\n",
      "-------------Round number:  128  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9365294330083063\n",
      "Average Global Trainning Loss:  0.22399058123278937\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.1772611817111604\n",
      "-------------Round number:  129  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9382448537378115\n",
      "Average Global Trainning Loss:  0.2183784327811823\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.17492975556665313\n",
      "-------------Round number:  130  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.21870864862653486\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.17733400950323333\n",
      "-------------Round number:  131  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.939689418562658\n",
      "Average Global Trainning Loss:  0.21290367404749008\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.17407634345234066\n",
      "-------------Round number:  132  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.21268596215211943\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17387999055531103\n",
      "-------------Round number:  133  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.2156137540134638\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.17632857157719958\n",
      "-------------Round number:  134  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.21608043379971334\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17721910294146692\n",
      "-------------Round number:  135  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9392379920548934\n",
      "Average Global Trainning Loss:  0.21699239028925155\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.17554871465118838\n",
      "-------------Round number:  136  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.21463551629790764\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9515167930660888\n",
      "Average Personal Trainning Loss:  0.17674592067378228\n",
      "-------------Round number:  137  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9384254243409172\n",
      "Average Global Trainning Loss:  0.21462806599714473\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17737188921288147\n",
      "-------------Round number:  138  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9368905742145178\n",
      "Average Global Trainning Loss:  0.22083271174019276\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17904067943568866\n",
      "-------------Round number:  139  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.938696280245576\n",
      "Average Global Trainning Loss:  0.21454752339658947\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9504333694474539\n",
      "Average Personal Trainning Loss:  0.1782655175216967\n",
      "-------------Round number:  140  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.21273216283377347\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.1740406569525325\n",
      "-------------Round number:  141  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.2134119917572341\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.1746579849061315\n",
      "-------------Round number:  142  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.2144594864106514\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.17551009652415697\n",
      "-------------Round number:  143  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9357168652943301\n",
      "Average Global Trainning Loss:  0.22286536539449034\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9505236547490069\n",
      "Average Personal Trainning Loss:  0.17892332617751783\n",
      "-------------Round number:  144  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9337305886601661\n",
      "Average Global Trainning Loss:  0.23087020659110916\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.18124536229798663\n",
      "-------------Round number:  145  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9366197183098591\n",
      "Average Global Trainning Loss:  0.2215813347130056\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9515167930660888\n",
      "Average Personal Trainning Loss:  0.17675912401744198\n",
      "-------------Round number:  146  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9371614301191766\n",
      "Average Global Trainning Loss:  0.22342290358235148\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17817981702061325\n",
      "-------------Round number:  147  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9354460093896714\n",
      "Average Global Trainning Loss:  0.22688068074412018\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17903675590451765\n",
      "-------------Round number:  148  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9361682918020946\n",
      "Average Global Trainning Loss:  0.228365649123104\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9496208017334777\n",
      "Average Personal Trainning Loss:  0.18480046727933708\n",
      "-------------Round number:  149  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9343625857710365\n",
      "Average Global Trainning Loss:  0.23201653896233973\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.18463533731435086\n",
      "-------------Round number:  150  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9371614301191766\n",
      "Average Global Trainning Loss:  0.22228547630434048\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.17926918104177952\n",
      "-------------Round number:  151  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9369808595160708\n",
      "Average Global Trainning Loss:  0.22686686021578187\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9512459371614301\n",
      "Average Personal Trainning Loss:  0.18218089303801577\n",
      "-------------Round number:  152  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9363488624052004\n",
      "Average Global Trainning Loss:  0.22654180227095747\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9512459371614301\n",
      "Average Personal Trainning Loss:  0.18124826086174498\n",
      "-------------Round number:  153  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.936800288912965\n",
      "Average Global Trainning Loss:  0.22473237108951788\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.17929939002756523\n",
      "-------------Round number:  154  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.935807150595883\n",
      "Average Global Trainning Loss:  0.2277959876647707\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9517876489707475\n",
      "Average Personal Trainning Loss:  0.17814558531326177\n",
      "-------------Round number:  155  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.21496445368928313\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.17405188750945175\n",
      "-------------Round number:  156  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.20691352202256005\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16988136123431294\n",
      "-------------Round number:  157  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20996241433476662\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.1721310434723727\n",
      "-------------Round number:  158  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.21142509793839157\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17116617441780088\n",
      "-------------Round number:  159  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.2173210411305977\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17467007511313876\n",
      "-------------Round number:  160  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.22262528055452105\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9507042253521126\n",
      "Average Personal Trainning Loss:  0.1794123238025912\n",
      "-------------Round number:  161  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9369808595160708\n",
      "Average Global Trainning Loss:  0.21972535017295278\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17620041758715352\n",
      "-------------Round number:  162  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.938696280245576\n",
      "Average Global Trainning Loss:  0.21332437357518508\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.17189694311955467\n",
      "-------------Round number:  163  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9361682918020946\n",
      "Average Global Trainning Loss:  0.21804433748927862\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.1739257393696111\n",
      "-------------Round number:  164  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9333694474539544\n",
      "Average Global Trainning Loss:  0.22502403493476886\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9512459371614301\n",
      "Average Personal Trainning Loss:  0.17747966508737925\n",
      "-------------Round number:  165  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9305706031058144\n",
      "Average Global Trainning Loss:  0.23370978512803584\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.18096716630411475\n",
      "-------------Round number:  166  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9287648970747562\n",
      "Average Global Trainning Loss:  0.2397000032798957\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.187871875811157\n",
      "-------------Round number:  167  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9095572354211663\n",
      "Average Global Trainning Accurancy:  0.9256049115204045\n",
      "Average Global Trainning Loss:  0.24681942692815548\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.948537378114843\n",
      "Average Personal Trainning Loss:  0.18891590982191225\n",
      "-------------Round number:  168  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9310220296135789\n",
      "Average Global Trainning Loss:  0.23575008746388587\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9506139400505598\n",
      "Average Personal Trainning Loss:  0.18293427714977767\n",
      "-------------Round number:  169  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9376128566269412\n",
      "Average Global Trainning Loss:  0.21215518332853692\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17419615442807082\n",
      "-------------Round number:  170  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.2115829429199395\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.17335325649560424\n",
      "-------------Round number:  171  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9404117009750813\n",
      "Average Global Trainning Loss:  0.2096914261762482\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.17199124012151837\n",
      "-------------Round number:  172  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.2062172495358771\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.16927885673415494\n",
      "-------------Round number:  173  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.939689418562658\n",
      "Average Global Trainning Loss:  0.2078797246368838\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17188260459693255\n",
      "-------------Round number:  174  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.20489695925452556\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9520585048754063\n",
      "Average Personal Trainning Loss:  0.16980847833646512\n",
      "-------------Round number:  175  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.2006226467629898\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.1675498358994109\n",
      "-------------Round number:  176  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.20056033315276273\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.16780708067767583\n",
      "-------------Round number:  177  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.20321493262459372\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16726124695639785\n",
      "-------------Round number:  178  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.2003297265060717\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16699656289852496\n",
      "-------------Round number:  179  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.20522633749210004\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.17016813168675515\n",
      "-------------Round number:  180  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.20891873300097058\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.16785599256345363\n",
      "-------------Round number:  181  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9393282773564464\n",
      "Average Global Trainning Loss:  0.20833518488736907\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.16904822804515393\n",
      "-------------Round number:  182  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9401408450704225\n",
      "Average Global Trainning Loss:  0.20729320081143915\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.1669788408813256\n",
      "-------------Round number:  183  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.2042289450091978\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.16574954125544533\n",
      "-------------Round number:  184  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.20363153228263814\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16283326650104957\n",
      "-------------Round number:  185  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.19710813269541125\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.1653538707706979\n",
      "-------------Round number:  186  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.20078708239521262\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16819317377875023\n",
      "-------------Round number:  187  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.20206882067646262\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.1686717013065976\n",
      "-------------Round number:  188  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.20319284623002437\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.17067635020610442\n",
      "-------------Round number:  189  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19957237477851886\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16654309747709012\n",
      "-------------Round number:  190  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.19878251064379063\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16450615659350737\n",
      "-------------Round number:  191  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.1978704439427027\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16335108444638183\n",
      "-------------Round number:  192  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.205215448590985\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16969488329214066\n",
      "-------------Round number:  193  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.20336627512470656\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.17043542775835704\n",
      "-------------Round number:  194  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.20176703941094484\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16841817065755912\n",
      "-------------Round number:  195  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20215804794713796\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16733501154664365\n",
      "-------------Round number:  196  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.20472339810598367\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16820211193543472\n",
      "-------------Round number:  197  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.2046076318941292\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.1662234509193583\n",
      "-------------Round number:  198  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.20022645828395855\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16604207577193933\n",
      "-------------Round number:  199  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9414951245937161\n",
      "Average Global Trainning Loss:  0.206583504557997\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.16959338947597846\n",
      "-------------Round number:  200  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.2040742741202826\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16949783606234764\n",
      "-------------Round number:  201  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.2003411885072454\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16631989704654207\n",
      "-------------Round number:  202  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19778441280697004\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16348945504708942\n",
      "-------------Round number:  203  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.19669038683724946\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16520348711106786\n",
      "-------------Round number:  204  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19787238366597823\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.16137030736855024\n",
      "-------------Round number:  205  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9440231130371975\n",
      "Average Global Trainning Loss:  0.20323084717237722\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16801360610074711\n",
      "-------------Round number:  206  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.942578548212351\n",
      "Average Global Trainning Loss:  0.20092026203192714\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16725213246123374\n",
      "-------------Round number:  207  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9381545684362586\n",
      "Average Global Trainning Loss:  0.20839500771657188\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.16931354030886037\n",
      "-------------Round number:  208  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9401408450704225\n",
      "Average Global Trainning Loss:  0.20385614342102293\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16532783880264762\n",
      "-------------Round number:  209  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9394185626579993\n",
      "Average Global Trainning Loss:  0.20483400641730995\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16512479606454836\n",
      "-------------Round number:  210  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.20624343580009705\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16630943797047107\n",
      "-------------Round number:  211  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9380642831347057\n",
      "Average Global Trainning Loss:  0.20927980808025234\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.16674125784353558\n",
      "-------------Round number:  212  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.1993966755259119\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16391606191385089\n",
      "-------------Round number:  213  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.942578548212351\n",
      "Average Global Trainning Loss:  0.19911737741654253\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16124927304461786\n",
      "-------------Round number:  214  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.2020085790433708\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.160736954655618\n",
      "-------------Round number:  215  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9364391477067533\n",
      "Average Global Trainning Loss:  0.21218002501184993\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16826816171719822\n",
      "-------------Round number:  216  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9332791621524016\n",
      "Average Global Trainning Loss:  0.21958163431208244\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.17073989818568866\n",
      "-------------Round number:  217  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9350848681834597\n",
      "Average Global Trainning Loss:  0.2154802216997901\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.1685631429300966\n",
      "-------------Round number:  218  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9373420007222825\n",
      "Average Global Trainning Loss:  0.20989919698983162\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16635291642684633\n",
      "-------------Round number:  219  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9404117009750813\n",
      "Average Global Trainning Loss:  0.20063886990311258\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16549279242915424\n",
      "-------------Round number:  220  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.19753511428144185\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16370615299620236\n",
      "-------------Round number:  221  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.19877514851226752\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.1635587009637956\n",
      "-------------Round number:  222  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.20422680690513273\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.1695273727576799\n",
      "-------------Round number:  223  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9361682918020946\n",
      "Average Global Trainning Loss:  0.20633973865226615\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.16915475852913958\n",
      "-------------Round number:  224  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.19938137816280696\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.16273042810398045\n",
      "-------------Round number:  225  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.19965238836363533\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.1656973340443301\n",
      "-------------Round number:  226  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9414951245937161\n",
      "Average Global Trainning Loss:  0.19557533250383713\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16247770199925515\n",
      "-------------Round number:  227  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19640139011150234\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.1650672215509604\n",
      "-------------Round number:  228  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19378838447854596\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16222907576418044\n",
      "-------------Round number:  229  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.19252950407271352\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.1611835979821235\n",
      "-------------Round number:  230  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.19704222618866243\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.16351475961891138\n",
      "-------------Round number:  231  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9414951245937161\n",
      "Average Global Trainning Loss:  0.19488878067584192\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16105973122136263\n",
      "-------------Round number:  232  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.20072549618121388\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.16440576489284264\n",
      "-------------Round number:  233  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.19850096421880642\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16545555194649467\n",
      "-------------Round number:  234  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.19276063973484336\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16176469939932062\n",
      "-------------Round number:  235  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19393531851666893\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16199011508201855\n",
      "-------------Round number:  236  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.19268675391189283\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.16029723261443662\n",
      "-------------Round number:  237  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9445648248465149\n",
      "Average Global Trainning Loss:  0.1930191960305503\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.16029117097920054\n",
      "-------------Round number:  238  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19296358328254784\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15972090335734357\n",
      "-------------Round number:  239  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.1925074617627641\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15989919258136961\n",
      "-------------Round number:  240  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.1899077917273271\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15877329343146218\n",
      "-------------Round number:  241  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.1893660137910798\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.1576504471414827\n",
      "-------------Round number:  242  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19280503294708154\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.15989202883063605\n",
      "-------------Round number:  243  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9440231130371975\n",
      "Average Global Trainning Loss:  0.19272625373132224\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.15962093046056788\n",
      "-------------Round number:  244  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19166910454614708\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.1591723143473219\n",
      "-------------Round number:  245  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19237454663376896\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15919662701519616\n",
      "-------------Round number:  246  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19199513235260923\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15688325352253746\n",
      "-------------Round number:  247  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19187284161700974\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.15825664372855724\n",
      "-------------Round number:  248  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.19209242710872607\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.1591444198040809\n",
      "-------------Round number:  249  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.1965937533504311\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16219810631870146\n",
      "-------------Round number:  250  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.19664967469077285\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16145741857747042\n",
      "-------------Round number:  251  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.1997597344130891\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16168101576959756\n",
      "-------------Round number:  252  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.1962102832842407\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.1626392941734945\n",
      "-------------Round number:  253  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.19881070275821597\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16332846903637369\n",
      "-------------Round number:  254  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.1986737098018802\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16273749266431925\n",
      "-------------Round number:  255  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.19853074337954812\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.1611121037498025\n",
      "-------------Round number:  256  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.19814105738195198\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16304523637467835\n",
      "-------------Round number:  257  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.19185031437624142\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.1588511027855837\n",
      "-------------Round number:  258  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.19023221044516297\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15466276632400575\n",
      "-------------Round number:  259  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19412508076302365\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.1591364404878792\n",
      "-------------Round number:  260  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.194068696534173\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15973035950831188\n",
      "-------------Round number:  261  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.18931624225521398\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15597794278944904\n",
      "-------------Round number:  262  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9470025279884435\n",
      "Average Global Trainning Loss:  0.18875694068255688\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15517334337051958\n",
      "-------------Round number:  263  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.19140477316523338\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.1558238450005925\n",
      "-------------Round number:  264  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19314968650545097\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.15792208554814463\n",
      "-------------Round number:  265  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.18885617516194925\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15639843291519953\n",
      "-------------Round number:  266  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.18769959311659218\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.1557674277082769\n",
      "-------------Round number:  267  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.1914905177509367\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15591551896767222\n",
      "-------------Round number:  268  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19110162527649874\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15662346285747336\n",
      "-------------Round number:  269  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.18729258186337577\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15497080760554915\n",
      "-------------Round number:  270  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.18986992303883396\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15702930586826247\n",
      "-------------Round number:  271  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19128594307229596\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.1590217323069023\n",
      "-------------Round number:  272  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.19247272308228378\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15896574483963075\n",
      "-------------Round number:  273  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19088946804323537\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15626785427105905\n",
      "-------------Round number:  274  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.18464110137840262\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.1533398860712351\n",
      "-------------Round number:  275  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.18258199695216573\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15199181145819227\n",
      "-------------Round number:  276  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.1859509325836832\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.15293790046468717\n",
      "-------------Round number:  277  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.18686828943915898\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15251122747099585\n",
      "-------------Round number:  278  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18559999696697815\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.15345355826364437\n",
      "-------------Round number:  279  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9432105453232213\n",
      "Average Global Trainning Loss:  0.19169152157536565\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.1561584913502449\n",
      "-------------Round number:  280  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.18918509051101481\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.1545938510419488\n",
      "-------------Round number:  281  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.19181958739617191\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.1605761229410719\n",
      "-------------Round number:  282  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.19091929128859697\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.15783541518542343\n",
      "-------------Round number:  283  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.1955157080554239\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.16054527472829766\n",
      "-------------Round number:  284  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9400505597688696\n",
      "Average Global Trainning Loss:  0.19704350464263948\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16140571833948403\n",
      "-------------Round number:  285  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18710345884400956\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15721251052740723\n",
      "-------------Round number:  286  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.18590830275624098\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15504070377039883\n",
      "-------------Round number:  287  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.18500128374413147\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15500263670111616\n",
      "-------------Round number:  288  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.19090827013362224\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.16061542437971177\n",
      "-------------Round number:  289  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18693862645020765\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15757122707952442\n",
      "-------------Round number:  290  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.18499713978986096\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.958107620079451\n",
      "Average Personal Trainning Loss:  0.15595683727767246\n",
      "-------------Round number:  291  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.18317478079363603\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.15333209411466797\n",
      "-------------Round number:  292  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18593448902046092\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.1546937357694847\n",
      "-------------Round number:  293  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18397114740979933\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15520836860102924\n",
      "-------------Round number:  294  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.18222282853269456\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.958107620079451\n",
      "Average Personal Trainning Loss:  0.15318871990960184\n",
      "-------------Round number:  295  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18386258903329836\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15306975756280472\n",
      "-------------Round number:  296  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.1903565731578977\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15818701207142696\n",
      "-------------Round number:  297  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.19707308542259164\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.15860461465457407\n",
      "-------------Round number:  298  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.19334610552941045\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.15605122244887595\n",
      "-------------Round number:  299  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19145392751642065\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.1568914863253036\n",
      "-------------Round number:  300  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.19057646724195332\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.1566415816362518\n",
      "-------------Round number:  301  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.18556620610582567\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15508829311757968\n",
      "-------------Round number:  302  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.18756846341470296\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.15690300343225216\n",
      "-------------Round number:  303  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.1846063186133024\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15503133578867032\n",
      "-------------Round number:  304  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9445648248465149\n",
      "Average Global Trainning Loss:  0.18505004133373962\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.1542025228922614\n",
      "-------------Round number:  305  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9440231130371975\n",
      "Average Global Trainning Loss:  0.18611060707695692\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.1571880215210534\n",
      "-------------Round number:  306  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9414951245937161\n",
      "Average Global Trainning Loss:  0.1956135318269795\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16157346031819925\n",
      "-------------Round number:  307  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.19822049786700974\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.16455731679490002\n",
      "-------------Round number:  308  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9409534127843987\n",
      "Average Global Trainning Loss:  0.20024779523998962\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.16854492496092338\n",
      "-------------Round number:  309  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19134971147497967\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.1627885206118522\n",
      "-------------Round number:  310  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.19130540643198132\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.16077504376721063\n",
      "-------------Round number:  311  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.18824375162231402\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16034089843044647\n",
      "-------------Round number:  312  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.1904479164903282\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16088765792874232\n",
      "-------------Round number:  313  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.19598181474161475\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16436111819404003\n",
      "-------------Round number:  314  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9414951245937161\n",
      "Average Global Trainning Loss:  0.19187786726367823\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16210930887307015\n",
      "-------------Round number:  315  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.19407052604589878\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.1621139487793145\n",
      "-------------Round number:  316  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.19229669319502754\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16214031138201404\n",
      "-------------Round number:  317  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.18718406757149467\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15825624696697815\n",
      "-------------Round number:  318  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.1908851918351052\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.1616511263973061\n",
      "-------------Round number:  319  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18924392143626986\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.1607486921856661\n",
      "-------------Round number:  320  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.1888230676124052\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15983180923985418\n",
      "-------------Round number:  321  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18694856753199485\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15644982456084666\n",
      "-------------Round number:  322  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.1888013118524851\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15878147112845342\n",
      "-------------Round number:  323  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18765125433087307\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.15842337176101481\n",
      "-------------Round number:  324  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18809798582661835\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15641895430576247\n",
      "-------------Round number:  325  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18178189416446597\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.15301567675534375\n",
      "-------------Round number:  326  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.18398360131492078\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15578022326920254\n",
      "-------------Round number:  327  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.18376488649444744\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.1545593658480329\n",
      "-------------Round number:  328  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.1871644719579496\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.1552081702202397\n",
      "-------------Round number:  329  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.18444093516175175\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1538045820495892\n",
      "-------------Round number:  330  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17927200245745306\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15173591126083424\n",
      "-------------Round number:  331  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.17983052152810694\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.1528543050042039\n",
      "-------------Round number:  332  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.1842649162956505\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15645419995937163\n",
      "-------------Round number:  333  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.18849122063611637\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.15935373357936078\n",
      "-------------Round number:  334  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.1886970296841143\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.158966505299324\n",
      "-------------Round number:  335  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.1871539798184137\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.15725980230340375\n",
      "-------------Round number:  336  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.1866781524735351\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.1567359337439904\n",
      "-------------Round number:  337  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18275632958155585\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15383991587243814\n",
      "-------------Round number:  338  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.18530980995649377\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.1549740588462667\n",
      "-------------Round number:  339  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.18031569481240406\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.1524173823363861\n",
      "-------------Round number:  340  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17920884021829292\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.15272750661621975\n",
      "-------------Round number:  341  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.1795937209923201\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.15326586799442488\n",
      "-------------Round number:  342  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.1817678752553381\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.1524301117703819\n",
      "-------------Round number:  343  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.18007988618056495\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14950233093019252\n",
      "-------------Round number:  344  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17986898535896872\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.15042550695549498\n",
      "-------------Round number:  345  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.18018428958164048\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14979648555646782\n",
      "-------------Round number:  346  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.18329177035369268\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.958107620079451\n",
      "Average Personal Trainning Loss:  0.15274225292157592\n",
      "-------------Round number:  347  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.18477402752855274\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.15245181242452713\n",
      "-------------Round number:  348  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.1830709835560841\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15282265224711652\n",
      "-------------Round number:  349  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.1858570984702284\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.154260692548218\n",
      "-------------Round number:  350  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.18933290624153576\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.15784652450963796\n",
      "-------------Round number:  351  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.189498466031566\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15423231307415808\n",
      "-------------Round number:  352  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18864516412880328\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.15711524883475533\n",
      "-------------Round number:  353  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.186039079781171\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15595861168362338\n",
      "-------------Round number:  354  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.18476720543362338\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15238587285431338\n",
      "-------------Round number:  355  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.1875918503055593\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.1543280097628036\n",
      "-------------Round number:  356  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.1947335807714879\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.159260781158304\n",
      "-------------Round number:  357  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.1951547652300018\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16254009275756703\n",
      "-------------Round number:  358  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.19199544094494853\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15686003194900575\n",
      "-------------Round number:  359  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.19069007330743273\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.15863754586563855\n",
      "-------------Round number:  360  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.18068644646575366\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.15203201663154003\n",
      "-------------Round number:  361  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17923391334586042\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14834663057723343\n",
      "-------------Round number:  362  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17917731971506523\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.1490839458450422\n",
      "-------------Round number:  363  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.1795832508950941\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14928040895362157\n",
      "-------------Round number:  364  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17566853664807353\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14926824159852947\n",
      "-------------Round number:  365  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17739999315806698\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14763935897788574\n",
      "-------------Round number:  366  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.17831060506669827\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.1484739910441213\n",
      "-------------Round number:  367  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17584887580692488\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14912956240548259\n",
      "-------------Round number:  368  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17564673680353354\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14807078208937116\n",
      "-------------Round number:  369  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.17328051687277107\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14483740666404274\n",
      "-------------Round number:  370  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17469403510405382\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.1449510017083672\n",
      "-------------Round number:  371  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17521691175951945\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14719745474801937\n",
      "-------------Round number:  372  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.17716017282581709\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14674132220708064\n",
      "-------------Round number:  373  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.1763305223216301\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14499755506698042\n",
      "-------------Round number:  374  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.180204127660595\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14749044113186732\n",
      "-------------Round number:  375  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.18332621146298866\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.1478516484650088\n",
      "-------------Round number:  376  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.18429847571254854\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.14847645978283563\n",
      "-------------Round number:  377  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.17928151371419623\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.14686626904102904\n",
      "-------------Round number:  378  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.1780706304382787\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.14610270138207046\n",
      "-------------Round number:  379  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.1771800439682365\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.14689599309599585\n",
      "-------------Round number:  380  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17338976958203547\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14257658203830353\n",
      "-------------Round number:  381  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.17458428644281554\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.144111861989747\n",
      "-------------Round number:  382  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17199116297343356\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14384079668314373\n",
      "-------------Round number:  383  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17628532456507878\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.1473490727770066\n",
      "-------------Round number:  384  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17943735284553877\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14816438475857147\n",
      "-------------Round number:  385  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.1809948404242563\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14968708957218874\n",
      "-------------Round number:  386  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.18124019337630348\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.15174923583719868\n",
      "-------------Round number:  387  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.18059919198181879\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14945877532573243\n",
      "-------------Round number:  388  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17855005067967902\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14782700516248534\n",
      "-------------Round number:  389  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.18275839053753612\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14959487556851525\n",
      "-------------Round number:  390  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17647696040777922\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14740105956502234\n",
      "-------------Round number:  391  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.17633245102375067\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14769864177049477\n",
      "-------------Round number:  392  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.17698228036337013\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14714833346029704\n",
      "-------------Round number:  393  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.17073814582204766\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.14250058015359787\n",
      "-------------Round number:  394  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.17134091482992506\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14459829168571123\n",
      "-------------Round number:  395  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.1698487165732778\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.143720787326624\n",
      "-------------Round number:  396  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.17228154836470747\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14687273845899917\n",
      "-------------Round number:  397  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17298008018816022\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14726408865099652\n",
      "-------------Round number:  398  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17279963081775912\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14695806424081348\n",
      "-------------Round number:  399  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17389080230834122\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.1470647269786588\n",
      "-------------Round number:  400  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.17271200161455513\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14625096897994538\n",
      "-------------Round number:  401  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.1724929892228975\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14633325292298663\n",
      "-------------Round number:  402  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.17379848911427298\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14489326187745463\n",
      "-------------Round number:  403  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17609762327470432\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1465983778270585\n",
      "-------------Round number:  404  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.1811046441912694\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15098176668937907\n",
      "-------------Round number:  405  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18145491853867596\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14984373324784445\n",
      "-------------Round number:  406  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17621986992568392\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14659963423872563\n",
      "-------------Round number:  407  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.1855463459845612\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.15451179854316202\n",
      "-------------Round number:  408  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.18204749297820175\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15259415064102563\n",
      "-------------Round number:  409  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9440231130371975\n",
      "Average Global Trainning Loss:  0.19432474000654568\n",
      "Average Personal Accurancy:  0.9252159827213823\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.15951626255177298\n",
      "-------------Round number:  410  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.18912015386590375\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15655393039073787\n",
      "-------------Round number:  411  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.18844645270460905\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.15383770062028823\n",
      "-------------Round number:  412  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.18752129287141117\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.15286632908428133\n",
      "-------------Round number:  413  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.18874296585804892\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.15455128734143644\n",
      "-------------Round number:  414  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.19501867600837397\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.15819752625327285\n",
      "-------------Round number:  415  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.18792614397825252\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15478151926885833\n",
      "-------------Round number:  416  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.1900758643406916\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15492586333556224\n",
      "-------------Round number:  417  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18597976392509705\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1506393394043145\n",
      "-------------Round number:  418  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.1832245302871919\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.1497906994501061\n",
      "-------------Round number:  419  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.17576104822293134\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14827446405445896\n",
      "-------------Round number:  420  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.1739935415150156\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14456579029969077\n",
      "-------------Round number:  421  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.17392644472352947\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14488812601923642\n",
      "-------------Round number:  422  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17396922884714133\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14594461393511307\n",
      "-------------Round number:  423  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.17645898490401543\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14790777920729506\n",
      "-------------Round number:  424  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17161997047388497\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14351299447073063\n",
      "-------------Round number:  425  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16897061707182195\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.1432540854980645\n",
      "-------------Round number:  426  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16993081315668448\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14422634974762436\n",
      "-------------Round number:  427  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.1693225996982496\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.14297421428863646\n",
      "-------------Round number:  428  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.16885291113669196\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1429360039443391\n",
      "-------------Round number:  429  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16962042436913147\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14227816222505305\n",
      "-------------Round number:  430  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17082058406125858\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14204295975673753\n",
      "-------------Round number:  431  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16985476718735892\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14300945994224562\n",
      "-------------Round number:  432  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.173981583561868\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14307298587951991\n",
      "-------------Round number:  433  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.1780998034354968\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14654373494069384\n",
      "-------------Round number:  434  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17458192791565097\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14549754078356356\n",
      "-------------Round number:  435  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.1693671031220375\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.1413545784170165\n",
      "-------------Round number:  436  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17103231146947792\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14362414281865069\n",
      "-------------Round number:  437  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17450972832941156\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14865804433219912\n",
      "-------------Round number:  438  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.17158126417761377\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14653444410705016\n",
      "-------------Round number:  439  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17606191473258623\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.1500219343026307\n",
      "-------------Round number:  440  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17354280934001445\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14874106669262369\n",
      "-------------Round number:  441  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17947783354776092\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14915568254277267\n",
      "-------------Round number:  442  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.1854074133049499\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15503542463716594\n",
      "-------------Round number:  443  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1772001465549104\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.1497149179884999\n",
      "-------------Round number:  444  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.17680684561848253\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.1479929066083198\n",
      "-------------Round number:  445  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.17613889750008463\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14849726772342792\n",
      "-------------Round number:  446  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18531527644936124\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15524228069488646\n",
      "-------------Round number:  447  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18856290222807195\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15633155654681294\n",
      "-------------Round number:  448  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19180543623318436\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.1591778579882742\n",
      "-------------Round number:  449  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.18492349643231987\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15439085238846945\n",
      "-------------Round number:  450  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.1802565663159647\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.1533260655428968\n",
      "-------------Round number:  451  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.1834902944182523\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.15477415713733522\n",
      "-------------Round number:  452  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.1785885696163157\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15056730513539973\n",
      "-------------Round number:  453  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.173912701343276\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.14709979629378836\n",
      "-------------Round number:  454  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.17148184233858682\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.1454541504964281\n",
      "-------------Round number:  455  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17097106691128341\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.1461172493066371\n",
      "-------------Round number:  456  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.17056970951056902\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14364482952653823\n",
      "-------------Round number:  457  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16945559197532953\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14450216517202172\n",
      "-------------Round number:  458  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17375747939661204\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14613079430610104\n",
      "-------------Round number:  459  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.17606871478520564\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14731932667972983\n",
      "-------------Round number:  460  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.17636035658814667\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.14800232969582316\n",
      "-------------Round number:  461  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17213482372852904\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.144598390876106\n",
      "-------------Round number:  462  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.17764602942172264\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.14919122576756613\n",
      "-------------Round number:  463  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.1775570225741468\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.1485910908157277\n",
      "-------------Round number:  464  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.17012901760774987\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14491526010278416\n",
      "-------------Round number:  465  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.17130023574691336\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14545839364109336\n",
      "-------------Round number:  466  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.17522362364289906\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.1484036650542276\n",
      "-------------Round number:  467  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17212786937973998\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14663325978255348\n",
      "-------------Round number:  468  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16744083667671092\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14221724830150775\n",
      "-------------Round number:  469  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17220948103232778\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14511231835373217\n",
      "-------------Round number:  470  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17173255157195175\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.1458382267261421\n",
      "-------------Round number:  471  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16988602318286725\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14359778021595115\n",
      "-------------Round number:  472  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.1677120011737089\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14231741957907298\n",
      "-------------Round number:  473  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16573284420565862\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13998868259637956\n",
      "-------------Round number:  474  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16612410622841617\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14077378559215872\n",
      "-------------Round number:  475  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16488814982493116\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13904910709247473\n",
      "-------------Round number:  476  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16571198115929148\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13786409046728287\n",
      "-------------Round number:  477  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16715225875485284\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.1395637729874842\n",
      "-------------Round number:  478  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.1677781942304871\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14031881027249232\n",
      "-------------Round number:  479  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16666889293997156\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13923260932280382\n",
      "-------------Round number:  480  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.16667952835452216\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13650206307204202\n",
      "-------------Round number:  481  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.1696621725041757\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13835766187167073\n",
      "-------------Round number:  482  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17186890530129897\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14159409015692714\n",
      "-------------Round number:  483  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17204191539209213\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13955818526191202\n",
      "-------------Round number:  484  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17290006660304374\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14294213170650505\n",
      "-------------Round number:  485  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17119218434354122\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.1413988834600149\n",
      "-------------Round number:  486  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.1756030709875237\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14346546022932466\n",
      "-------------Round number:  487  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16825663358909465\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14024245571082747\n",
      "-------------Round number:  488  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17445754316060627\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14449117708051193\n",
      "-------------Round number:  489  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.17057431635334847\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14160419655603895\n",
      "-------------Round number:  490  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16554168227262211\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13974069558829338\n",
      "-------------Round number:  491  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.1643668491946269\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13776421676090195\n",
      "-------------Round number:  492  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16417806783106492\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1384200085453627\n",
      "-------------Round number:  493  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16546984638449688\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13761643409384594\n",
      "-------------Round number:  494  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16647413811041328\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.13976419269069948\n",
      "-------------Round number:  495  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16682828088321597\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13828715954329746\n",
      "-------------Round number:  496  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1669715669190423\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13810382263029297\n",
      "-------------Round number:  497  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1685713316482428\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14059230023319\n",
      "-------------Round number:  498  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.16431524814703527\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.1362612067512245\n",
      "-------------Round number:  499  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16540116254669443\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13542815071015032\n",
      "-------------Round number:  500  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.16797510920642042\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13627450928527898\n",
      "-------------Round number:  501  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16819104669584012\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13830111232549544\n",
      "-------------Round number:  502  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17051658754359086\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.13882066059215872\n",
      "-------------Round number:  503  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.17012879718465038\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13735868234245216\n",
      "-------------Round number:  504  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17177426664353107\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.1376120917587859\n",
      "-------------Round number:  505  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.1695198673511421\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.13836375657037175\n",
      "-------------Round number:  506  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17062849635120417\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13750224390715285\n",
      "-------------Round number:  507  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17300588071195602\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.13892288180454926\n",
      "-------------Round number:  508  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.1705018412382347\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1382471086661193\n",
      "-------------Round number:  509  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.16832997937545144\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.1381144029390687\n",
      "-------------Round number:  510  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.16538571088741988\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1346078902300018\n",
      "-------------Round number:  511  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16707115407539386\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13964984820783677\n",
      "-------------Round number:  512  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.17292002591470296\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14384697955108455\n",
      "-------------Round number:  513  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.1690520413647752\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13915041354900234\n",
      "-------------Round number:  514  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1664022030318933\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.14033289530855003\n",
      "-------------Round number:  515  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16784564369893237\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1393918209275686\n",
      "-------------Round number:  516  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1648198186640879\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13788323421347395\n",
      "-------------Round number:  517  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16754348771414546\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13703265453598998\n",
      "-------------Round number:  518  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.16809241837997133\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13876484946336673\n",
      "-------------Round number:  519  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16896097356121909\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.13998041673014852\n",
      "-------------Round number:  520  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16774698231959867\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13653857615847328\n",
      "-------------Round number:  521  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16250642312911925\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13648338221435988\n",
      "-------------Round number:  522  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.16637967579112495\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13680766867833605\n",
      "-------------Round number:  523  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17218607209916148\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14015940028693796\n",
      "-------------Round number:  524  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.16965409399757922\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.1387144717639773\n",
      "-------------Round number:  525  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16610065321062997\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13700891496817444\n",
      "-------------Round number:  526  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.165230026052247\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.138224581425351\n",
      "-------------Round number:  527  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16451118224017583\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13666933114109336\n",
      "-------------Round number:  528  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.1638115593223806\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1359064578148982\n",
      "-------------Round number:  529  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16573014402268982\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14012053969449711\n",
      "-------------Round number:  530  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.171622571466459\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14575593176194587\n",
      "-------------Round number:  531  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17359705546480003\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14570890449366874\n",
      "-------------Round number:  532  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16809743300548483\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14291893217528326\n",
      "-------------Round number:  533  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1663102425147842\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.14290198163893214\n",
      "-------------Round number:  534  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16985881195123465\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14297409305593176\n",
      "-------------Round number:  535  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16745818397464113\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1399919338370971\n",
      "-------------Round number:  536  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16348619278521692\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.1387015659915019\n",
      "-------------Round number:  537  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16428888554433574\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13817505235489458\n",
      "-------------Round number:  538  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16676555949025482\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14147680302568616\n",
      "-------------Round number:  539  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.173306714158146\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14500725368335815\n",
      "-------------Round number:  540  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.1674728310896025\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14047334890754784\n",
      "-------------Round number:  541  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16344422422707316\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13989657880425582\n",
      "-------------Round number:  542  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.1629824819182523\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13753466814508847\n",
      "-------------Round number:  543  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16501361465316336\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.1386140249575377\n",
      "-------------Round number:  544  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1624672098597192\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13682421143195309\n",
      "-------------Round number:  545  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.16615670680483138\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.14061586346252597\n",
      "-------------Round number:  546  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1631545552108726\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13841623931036137\n",
      "-------------Round number:  547  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.1611663388534331\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.135991992998657\n",
      "-------------Round number:  548  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.16011150411080263\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13690854530981966\n",
      "-------------Round number:  549  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16116702216504153\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1373157990284455\n",
      "-------------Round number:  550  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15956579162222936\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13482790554676213\n",
      "-------------Round number:  551  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16170401692002978\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.139070774683155\n",
      "-------------Round number:  552  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.16074770028171836\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13699011287778756\n",
      "-------------Round number:  553  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16124577933849088\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13803010212466707\n",
      "-------------Round number:  554  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16198134224265867\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13775903681806384\n",
      "-------------Round number:  555  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1592833194202273\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13589373940205737\n",
      "-------------Round number:  556  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15927623281757855\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13439194171942714\n",
      "-------------Round number:  557  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15955443983260542\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13753893333206368\n",
      "-------------Round number:  558  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15920416548519886\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13538149816114234\n",
      "-------------Round number:  559  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16179267109064643\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1376849415931688\n",
      "-------------Round number:  560  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16671484013506116\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14217591897035256\n",
      "-------------Round number:  561  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.170308574264598\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.1459219323981751\n",
      "-------------Round number:  562  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16798961304636714\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.1436391756740362\n",
      "-------------Round number:  563  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16577310448478128\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14171694297143034\n",
      "-------------Round number:  564  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.17284834432274737\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.14823366373874255\n",
      "-------------Round number:  565  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.16913743327351932\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14463763720897096\n",
      "-------------Round number:  566  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16718687620262843\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.1440353310896025\n",
      "-------------Round number:  567  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1684575051596639\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14250415100780967\n",
      "-------------Round number:  568  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1699870981951404\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1429163422038642\n",
      "-------------Round number:  569  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.16378053477112675\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13886211115601865\n",
      "-------------Round number:  570  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.16081658250031036\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.137286813390862\n",
      "-------------Round number:  571  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.16117904624511895\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.138329205249526\n",
      "-------------Round number:  572  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15919195404548686\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.1359967431164511\n",
      "-------------Round number:  573  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15799470393827306\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13418564774061034\n",
      "-------------Round number:  574  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15964775595177635\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13447925130913688\n",
      "-------------Round number:  575  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15777944976046182\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13471583142182422\n",
      "-------------Round number:  576  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1571621658914827\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13372822572453955\n",
      "-------------Round number:  577  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.1570871008049499\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13367572094223998\n",
      "-------------Round number:  578  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.1564229109003984\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13397083440899807\n",
      "-------------Round number:  579  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15684080003357484\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13303382683420234\n",
      "-------------Round number:  580  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15941412950862224\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13525158078630034\n",
      "-------------Round number:  581  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16357015194381433\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13974621718693572\n",
      "-------------Round number:  582  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.16107272516307783\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13752311797467498\n",
      "-------------Round number:  583  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16430028141857958\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.1373602363253036\n",
      "-------------Round number:  584  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16296590610117032\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.1372857112753645\n",
      "-------------Round number:  585  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16558702330418812\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14069487412253973\n",
      "-------------Round number:  586  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.17044644891333174\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14233809526580557\n",
      "-------------Round number:  587  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17533441931385993\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.1454796093644197\n",
      "-------------Round number:  588  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.1798784194676271\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.14940584071838886\n",
      "-------------Round number:  589  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9445648248465149\n",
      "Average Global Trainning Loss:  0.18384929752039883\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15042343497835975\n",
      "-------------Round number:  590  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.1740295917129379\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14411479361697024\n",
      "-------------Round number:  591  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.17006032274879243\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13893788159646983\n",
      "-------------Round number:  592  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16535768409031915\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1384589903705083\n",
      "-------------Round number:  593  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1612601619457329\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13657328177548866\n",
      "-------------Round number:  594  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15858710203931925\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13422475079846063\n",
      "-------------Round number:  595  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15995580825447475\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.1355134324073447\n",
      "-------------Round number:  596  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1632191281578695\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13492193804100647\n",
      "-------------Round number:  597  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16561991043063268\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.13765618739983973\n",
      "-------------Round number:  598  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16305741475092542\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13459602044609403\n",
      "-------------Round number:  599  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.15982590190078774\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13369713504635586\n",
      "-------------Round number:  600  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16447357805940208\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13572579904255258\n",
      "-------------Round number:  601  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1614989793528801\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13420533152339517\n",
      "-------------Round number:  602  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15712351470098637\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13300021231152942\n",
      "-------------Round number:  603  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15636302194426577\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13292444187107824\n",
      "-------------Round number:  604  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.1588754264746129\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13266192898073537\n",
      "-------------Round number:  605  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15532578798612992\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13090251180057105\n",
      "-------------Round number:  606  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1555685068821382\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.1311622473598603\n",
      "-------------Round number:  607  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16050171912383757\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.1340890914018768\n",
      "-------------Round number:  608  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.15746700001692848\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1320844755658349\n",
      "-------------Round number:  609  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.15864325482391545\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13218367698176237\n",
      "-------------Round number:  610  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.15922695723368657\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1322500243347102\n",
      "-------------Round number:  611  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15607758505157548\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.1294304161305977\n",
      "-------------Round number:  612  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15651620497725938\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13156940188809138\n",
      "-------------Round number:  613  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15640465986776025\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13036637669567083\n",
      "-------------Round number:  614  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.15846494355757945\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13125789996388587\n",
      "-------------Round number:  615  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.15745290395971584\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.129635619015072\n",
      "-------------Round number:  616  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.1600103739927546\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1319173728141082\n",
      "-------------Round number:  617  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.15978309573486593\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13181703621921836\n",
      "-------------Round number:  618  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.15712456171070896\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.12912770908806204\n",
      "-------------Round number:  619  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15590618404940862\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13020770512749977\n",
      "-------------Round number:  620  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.1559711978426045\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13084348249452646\n",
      "-------------Round number:  621  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1553500345270743\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1299111038048201\n",
      "-------------Round number:  622  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.15711676975414185\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13048452347699982\n",
      "-------------Round number:  623  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.15716297043579586\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13018225728066316\n",
      "-------------Round number:  624  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.1553826020400246\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.12976347543393374\n",
      "-------------Round number:  625  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15507906841086583\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.13002792804755214\n",
      "-------------Round number:  626  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15374253294708154\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.13009437459089473\n",
      "-------------Round number:  627  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15333697648632177\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12833826375722282\n",
      "-------------Round number:  628  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15624090754714587\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13350678867878746\n",
      "-------------Round number:  629  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15578064207309159\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13336869360695422\n",
      "-------------Round number:  630  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15629227715048302\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13297427953387392\n",
      "-------------Round number:  631  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9284557235421166\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15610900636440841\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.1328456846976289\n",
      "-------------Round number:  632  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9295356371490281\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15993367777528553\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13601450921827035\n",
      "-------------Round number:  633  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.1574839505532796\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13389407206459913\n",
      "-------------Round number:  634  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.16089623238731265\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13678964908995236\n",
      "-------------Round number:  635  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15961912299115205\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13509700908777988\n",
      "-------------Round number:  636  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15714905071706278\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.1341625584209383\n",
      "-------------Round number:  637  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1568319610672851\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13380844871160053\n",
      "-------------Round number:  638  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15824174312703143\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13448746206959303\n",
      "-------------Round number:  639  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15903625818915898\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13449569487235916\n",
      "-------------Round number:  640  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1636633688725905\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13865385541161634\n",
      "-------------Round number:  641  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15981261038788822\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.1360845486581347\n",
      "-------------Round number:  642  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.16034303653451157\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13540613044251085\n",
      "-------------Round number:  643  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15816221447273385\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13461614507507788\n",
      "-------------Round number:  644  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16175021760168382\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1368206736412062\n",
      "-------------Round number:  645  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15677814476754356\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13289523581039522\n",
      "-------------Round number:  646  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1540759228850668\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13069268003100737\n",
      "-------------Round number:  647  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.154061022283541\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13098562233023542\n",
      "-------------Round number:  648  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1529919922933031\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.13034620798206709\n",
      "-------------Round number:  649  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15329886533241918\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.1298068657210692\n",
      "-------------Round number:  650  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15457291084749683\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.12890013325898902\n",
      "-------------Round number:  651  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15301619474962758\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12928333881746004\n",
      "-------------Round number:  652  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15492089279466864\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.12957243473360194\n",
      "-------------Round number:  653  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.1537324375691247\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.12819146197295955\n",
      "-------------Round number:  654  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.1561106705588096\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12925078232566473\n",
      "-------------Round number:  655  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.1539759169248262\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12920703936157008\n",
      "-------------Round number:  656  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.15463176381506186\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.1301368942067872\n",
      "-------------Round number:  657  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15389210104124346\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.1287000882750429\n",
      "-------------Round number:  658  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9575659082701337\n",
      "Average Global Trainning Loss:  0.15506604140568572\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.1307689133599675\n",
      "-------------Round number:  659  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9574756229685807\n",
      "Average Global Trainning Loss:  0.15367559045176507\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12992003094034962\n",
      "-------------Round number:  660  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.1553953424951754\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13068733477084463\n",
      "-------------Round number:  661  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9576561935716865\n",
      "Average Global Trainning Loss:  0.15602166371123374\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.13128146319322184\n",
      "-------------Round number:  662  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15456676104302094\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13053010697397527\n",
      "-------------Round number:  663  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.156463182200676\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.1309854570129108\n",
      "-------------Round number:  664  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15621787333324869\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.13059363291124954\n",
      "-------------Round number:  665  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15710288309887369\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1296086833123138\n",
      "-------------Round number:  666  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16198874845880168\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13241438281884818\n",
      "-------------Round number:  667  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16317733593820535\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.1343311049439667\n",
      "-------------Round number:  668  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16567008974923259\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.1392924211308516\n",
      "-------------Round number:  669  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.17112587005405833\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13954067264665718\n",
      "-------------Round number:  670  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.17512621867523248\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.1398744924096865\n",
      "-------------Round number:  671  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16595143779342722\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13743346087895564\n",
      "-------------Round number:  672  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16358702533208064\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13487546183047805\n",
      "-------------Round number:  673  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.16359974374492145\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13365869325780402\n",
      "-------------Round number:  674  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15893077471489594\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13369397197487812\n",
      "-------------Round number:  675  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16052936018051417\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.134968788970804\n",
      "-------------Round number:  676  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.1687360868939599\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13823811540365993\n",
      "-------------Round number:  677  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.1664638884362868\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13847942359183144\n",
      "-------------Round number:  678  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16397423156980748\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.1364517184361175\n",
      "-------------Round number:  679  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15736545109499142\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13297173364707476\n",
      "-------------Round number:  680  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.15793916833835545\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13340030227942173\n",
      "-------------Round number:  681  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1549372151251862\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.12945466267154207\n",
      "-------------Round number:  682  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15538486137679441\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13096450579730384\n",
      "-------------Round number:  683  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15653292406935604\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1337631627858094\n",
      "-------------Round number:  684  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.15784797930209463\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13123198922854032\n",
      "-------------Round number:  685  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1552754874348253\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.1310194131913879\n",
      "-------------Round number:  686  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15568945303683077\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13105153985813922\n",
      "-------------Round number:  687  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.15782133014936575\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.1304268497730171\n",
      "-------------Round number:  688  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.15775232669806902\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13133868502985058\n",
      "-------------Round number:  689  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.15654787977665674\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13076613602891388\n",
      "-------------Round number:  690  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.1547492383059374\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13037064188264605\n",
      "-------------Round number:  691  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.15887491950148405\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13222322088581168\n",
      "-------------Round number:  692  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15467129669795618\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13040544669005621\n",
      "-------------Round number:  693  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15811591460068505\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13228752932508916\n",
      "-------------Round number:  694  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16086798516711245\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13289331812942962\n",
      "-------------Round number:  695  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16447590352310176\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.137908064875632\n",
      "-------------Round number:  696  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16184453664595747\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13437842978342812\n",
      "-------------Round number:  697  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.16787341700946867\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13693347516237248\n",
      "-------------Round number:  698  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1617223230584428\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13346476501486887\n",
      "-------------Round number:  699  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16027698675274807\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13445607382022504\n",
      "-------------Round number:  700  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15636948034108095\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1315047297506997\n",
      "-------------Round number:  701  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.15672017349237655\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13025409316878836\n",
      "-------------Round number:  702  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15434856421683144\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.12870489349861186\n",
      "-------------Round number:  703  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.154057958402458\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.1291583699412017\n",
      "-------------Round number:  704  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15527359179616965\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.12829317621222125\n",
      "-------------Round number:  705  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1528648522495147\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.12802829377355882\n",
      "-------------Round number:  706  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15301502650720025\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.1265850845507742\n",
      "-------------Round number:  707  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15552602032971063\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13240598469875745\n",
      "-------------Round number:  708  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15746135718558144\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13210417036977473\n",
      "-------------Round number:  709  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1543624839355645\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13038987379807693\n",
      "-------------Round number:  710  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15542396443464473\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13159315247706188\n",
      "-------------Round number:  711  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15592016989507154\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1300171714002968\n",
      "-------------Round number:  712  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15671380326480114\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1307933362393915\n",
      "-------------Round number:  713  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.1552683787898666\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.12839709468247787\n",
      "-------------Round number:  714  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15384549257685537\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.12925020922560604\n",
      "-------------Round number:  715  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.15520330989089587\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.12977011016922851\n",
      "-------------Round number:  716  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.1550468205114098\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1277695060335974\n",
      "-------------Round number:  717  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.156883022078283\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13264697327343467\n",
      "-------------Round number:  718  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16501998488073877\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1368752173371761\n",
      "-------------Round number:  719  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16216690542896803\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1359600867550052\n",
      "-------------Round number:  720  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16793594002164025\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14082683041105204\n",
      "-------------Round number:  721  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17280204445069858\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14253626665340602\n",
      "-------------Round number:  722  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17143568574155268\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.14289077312432286\n",
      "-------------Round number:  723  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.1659831897409094\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.1407046058023824\n",
      "-------------Round number:  724  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16604724469362248\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.13829052099556474\n",
      "-------------Round number:  725  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16587251530265326\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13821800179583107\n",
      "-------------Round number:  726  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.1679052350838807\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.13797549230176734\n",
      "-------------Round number:  727  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16072457789858138\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13582643320862675\n",
      "-------------Round number:  728  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15453214359524536\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13232000866879964\n",
      "-------------Round number:  729  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15229344944869538\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.130844551546559\n",
      "-------------Round number:  730  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.1513519783061349\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12972266409706235\n",
      "-------------Round number:  731  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.15113701067835297\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12911526620409558\n",
      "-------------Round number:  732  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.15311190245942805\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13170735368490993\n",
      "-------------Round number:  733  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1550751559008498\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.132314200520128\n",
      "-------------Round number:  734  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1550906296024343\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13227335611979166\n",
      "-------------Round number:  735  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.15441452582935514\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.1323060007808268\n",
      "-------------Round number:  736  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9579270494763452\n",
      "Average Global Trainning Loss:  0.1534785211796621\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13153818997720296\n",
      "-------------Round number:  737  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15584327529681294\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1339215147404862\n",
      "-------------Round number:  738  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15531147150581776\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13220677732258937\n",
      "-------------Round number:  739  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.958107620079451\n",
      "Average Global Trainning Loss:  0.15440200579730384\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13266751670630755\n",
      "-------------Round number:  740  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15654380194931608\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13385004255047514\n",
      "-------------Round number:  741  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15645478408058527\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13302811787592542\n",
      "-------------Round number:  742  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15255028644422625\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1311910125743443\n",
      "-------------Round number:  743  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.15205508390890213\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13007200164629604\n",
      "-------------Round number:  744  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.15064015496978264\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12915197767131636\n",
      "-------------Round number:  745  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.150626477716459\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12813778894823266\n",
      "-------------Round number:  746  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15126118603145314\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.1297801835048754\n",
      "-------------Round number:  747  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15235693130134975\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.12920960729067918\n",
      "-------------Round number:  748  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.1518065568642222\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12897785444387075\n",
      "-------------Round number:  749  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15308661992991604\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13106687028470906\n",
      "-------------Round number:  750  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15498381256841934\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12998017338304668\n",
      "-------------Round number:  751  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9575659082701337\n",
      "Average Global Trainning Loss:  0.15300828156035573\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12944877737478558\n",
      "-------------Round number:  752  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.1559725975292863\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12954174081699735\n",
      "-------------Round number:  753  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15367437812471785\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12751731996546586\n",
      "-------------Round number:  754  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.15231705676265123\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12915399454267673\n",
      "-------------Round number:  755  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.15190332260490025\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9663235825207657\n",
      "Average Personal Trainning Loss:  0.12765078615220973\n",
      "-------------Round number:  756  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15387732167242235\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12915185643861163\n",
      "-------------Round number:  757  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1535307945177072\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.13062074495248735\n",
      "-------------Round number:  758  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15533038380775438\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13273850396549972\n",
      "-------------Round number:  759  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.153732735140309\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13047212467765326\n",
      "-------------Round number:  760  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15557482200393868\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13034434540687637\n",
      "-------------Round number:  761  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15679667132905606\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.13202450946161745\n",
      "-------------Round number:  762  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9588299024918743\n",
      "Average Global Trainning Loss:  0.1493051624676948\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.1288247706012719\n",
      "-------------Round number:  763  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.1522738648563053\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.13028910737814306\n",
      "-------------Round number:  764  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9580173347778982\n",
      "Average Global Trainning Loss:  0.15025276137242122\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.12982157896296045\n",
      "-------------Round number:  765  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.958107620079451\n",
      "Average Global Trainning Loss:  0.14986451914612675\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9661430119176598\n",
      "Average Personal Trainning Loss:  0.12704788489047264\n",
      "-------------Round number:  766  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9582881906825569\n",
      "Average Global Trainning Loss:  0.14980275659364842\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.12763538959871004\n",
      "-------------Round number:  767  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9584687612856627\n",
      "Average Global Trainning Loss:  0.14766770538848073\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12654151792515914\n",
      "-------------Round number:  768  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.14830970970806812\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9661430119176598\n",
      "Average Personal Trainning Loss:  0.1253843517585884\n",
      "-------------Round number:  769  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.14894532175777017\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12573696259084957\n",
      "-------------Round number:  770  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.14997533685939757\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12580381691692624\n",
      "-------------Round number:  771  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15158991402088412\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.12763295392346063\n",
      "-------------Round number:  772  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15186603803762075\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12703269773891748\n",
      "-------------Round number:  773  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15468510620513948\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13185728547718603\n",
      "-------------Round number:  774  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15306044468685107\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1290105431895258\n",
      "-------------Round number:  775  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.1517024069497111\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.1276801795725273\n",
      "-------------Round number:  776  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15147615365923506\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.12822574878608592\n",
      "-------------Round number:  777  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15291206687742642\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12850826507270788\n",
      "-------------Round number:  778  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1549527439325456\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.12985379379895157\n",
      "-------------Round number:  779  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15597632267966774\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.1296384514519005\n",
      "-------------Round number:  780  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15392003966910436\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.1267222318032796\n",
      "-------------Round number:  781  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15427658505369155\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.1282572692893136\n",
      "-------------Round number:  782  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.156573922765862\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12967336647086042\n",
      "-------------Round number:  783  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9588299024918743\n",
      "Average Global Trainning Loss:  0.1485699412193312\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.12585094337559813\n",
      "-------------Round number:  784  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9586493318887686\n",
      "Average Global Trainning Loss:  0.14961968418836336\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9662332972192127\n",
      "Average Personal Trainning Loss:  0.12563832325382585\n",
      "-------------Round number:  785  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9577464788732394\n",
      "Average Global Trainning Loss:  0.15181172578590535\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9662332972192127\n",
      "Average Personal Trainning Loss:  0.1280034520902458\n",
      "-------------Round number:  786  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.14902087177512188\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12692821718975714\n",
      "-------------Round number:  787  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.14941029326499863\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9664138678223185\n",
      "Average Personal Trainning Loss:  0.12588580328878318\n",
      "-------------Round number:  788  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15056590544871795\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.1284226747831742\n",
      "-------------Round number:  789  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9577464788732394\n",
      "Average Global Trainning Loss:  0.14728442268192488\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9662332972192127\n",
      "Average Personal Trainning Loss:  0.12537052020909512\n",
      "-------------Round number:  790  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.14870269103100173\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12542033582958084\n",
      "-------------Round number:  791  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9576561935716865\n",
      "Average Global Trainning Loss:  0.14650327628078164\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12512631345716527\n",
      "-------------Round number:  792  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.14814024842917684\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.1257147659847305\n",
      "-------------Round number:  793  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9580173347778982\n",
      "Average Global Trainning Loss:  0.1496010474153011\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9665944384254244\n",
      "Average Personal Trainning Loss:  0.1266166932232417\n",
      "-------------Round number:  794  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.14944703779568436\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12723625847130057\n",
      "-------------Round number:  795  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.14937222619571597\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9664138678223185\n",
      "Average Personal Trainning Loss:  0.12653772664784782\n",
      "-------------Round number:  796  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.1525684052230047\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12884712150356062\n",
      "-------------Round number:  797  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9585590465872156\n",
      "Average Global Trainning Loss:  0.14797412656024286\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9665944384254244\n",
      "Average Personal Trainning Loss:  0.1265642104832521\n",
      "-------------Round number:  798  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9579270494763452\n",
      "Average Global Trainning Loss:  0.14665520290210815\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9674070061394006\n",
      "Average Personal Trainning Loss:  0.12451814408335027\n",
      "-------------Round number:  799  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9593716143011918\n",
      "Average Global Trainning Loss:  0.14611836244328955\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9669555796316359\n",
      "Average Personal Trainning Loss:  0.12531943715578728\n",
      "---------------Running time:------------ 1\n",
      "Number of users / total users: 5  /  20\n",
      "Finished creating pFedMe server.\n",
      "-------------Round number:  0  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.06965442764578833\n",
      "Average Global Trainning Accurancy:  0.06247742867461177\n",
      "Average Global Trainning Loss:  2.5435273903033586\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9438425424340917\n",
      "Average Personal Trainning Loss:  0.6483020720476707\n",
      "-------------Round number:  1  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.5294276457883369\n",
      "Average Global Trainning Accurancy:  0.530155290718671\n",
      "Average Global Trainning Loss:  1.5192207179374322\n",
      "Average Personal Accurancy:  0.9379049676025918\n",
      "Average Personal Trainning Accurancy:  0.9431202600216685\n",
      "Average Personal Trainning Loss:  0.49960592758272393\n",
      "-------------Round number:  2  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.5904427645788337\n",
      "Average Global Trainning Accurancy:  0.5967858432647165\n",
      "Average Global Trainning Loss:  1.2585708436315006\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9307511737089202\n",
      "Average Personal Trainning Loss:  0.44548341607134795\n",
      "-------------Round number:  3  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.6241900647948164\n",
      "Average Global Trainning Accurancy:  0.627392560491152\n",
      "Average Global Trainning Loss:  1.1574819887876941\n",
      "Average Personal Accurancy:  0.9184665226781857\n",
      "Average Personal Trainning Accurancy:  0.9219032141567353\n",
      "Average Personal Trainning Loss:  0.44182130669634795\n",
      "-------------Round number:  4  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.646328293736501\n",
      "Average Global Trainning Accurancy:  0.644907908992416\n",
      "Average Global Trainning Loss:  1.0841870760822951\n",
      "Average Personal Accurancy:  0.896598272138229\n",
      "Average Personal Trainning Accurancy:  0.899783315276273\n",
      "Average Personal Trainning Loss:  0.45406395831922625\n",
      "-------------Round number:  5  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.6641468682505399\n",
      "Average Global Trainning Accurancy:  0.6735283495846877\n",
      "Average Global Trainning Loss:  1.0116046590037018\n",
      "Average Personal Accurancy:  0.9030777537796977\n",
      "Average Personal Trainning Accurancy:  0.9084507042253521\n",
      "Average Personal Trainning Loss:  0.43007526831663057\n",
      "-------------Round number:  6  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.6482181425485961\n",
      "Average Global Trainning Accurancy:  0.6479776092452149\n",
      "Average Global Trainning Loss:  1.0587102215657729\n",
      "Average Personal Accurancy:  0.894438444924406\n",
      "Average Personal Trainning Accurancy:  0.8994221740700614\n",
      "Average Personal Trainning Loss:  0.439682012346515\n",
      "-------------Round number:  7  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.6943844492440605\n",
      "Average Global Trainning Accurancy:  0.6933008306247743\n",
      "Average Global Trainning Loss:  0.9233184186247292\n",
      "Average Personal Accurancy:  0.8987580993520519\n",
      "Average Personal Trainning Accurancy:  0.9047490068616829\n",
      "Average Personal Trainning Loss:  0.4071788188566495\n",
      "-------------Round number:  8  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.6924946004319654\n",
      "Average Global Trainning Accurancy:  0.7002527988443481\n",
      "Average Global Trainning Loss:  0.9391172883656104\n",
      "Average Personal Accurancy:  0.8844492440604752\n",
      "Average Personal Trainning Accurancy:  0.89689418562658\n",
      "Average Personal Trainning Loss:  0.4295971706138272\n",
      "-------------Round number:  9  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7464902807775378\n",
      "Average Global Trainning Accurancy:  0.7475622968580715\n",
      "Average Global Trainning Loss:  0.7535364682082882\n",
      "Average Personal Accurancy:  0.908207343412527\n",
      "Average Personal Trainning Accurancy:  0.9171180931744312\n",
      "Average Personal Trainning Loss:  0.3712009637955941\n",
      "-------------Round number:  10  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7688984881209503\n",
      "Average Global Trainning Accurancy:  0.7717587576742506\n",
      "Average Global Trainning Loss:  0.6833659647689825\n",
      "Average Personal Accurancy:  0.9190064794816415\n",
      "Average Personal Trainning Accurancy:  0.9241603466955579\n",
      "Average Personal Trainning Loss:  0.34252530721689917\n",
      "-------------Round number:  11  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8110151187904968\n",
      "Average Global Trainning Accurancy:  0.810220296135789\n",
      "Average Global Trainning Loss:  0.5758668094302998\n",
      "Average Personal Accurancy:  0.9111771058315334\n",
      "Average Personal Trainning Accurancy:  0.9194655110148068\n",
      "Average Personal Trainning Loss:  0.3332572432793879\n",
      "-------------Round number:  12  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7921166306695464\n",
      "Average Global Trainning Accurancy:  0.797760924521488\n",
      "Average Global Trainning Loss:  0.6016572819327826\n",
      "Average Personal Accurancy:  0.9068574514038877\n",
      "Average Personal Trainning Accurancy:  0.9180209461899603\n",
      "Average Personal Trainning Loss:  0.34394020309255374\n",
      "-------------Round number:  13  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7915766738660908\n",
      "Average Global Trainning Accurancy:  0.7962260743950885\n",
      "Average Global Trainning Loss:  0.6023600789432105\n",
      "Average Personal Accurancy:  0.9090172786177105\n",
      "Average Personal Trainning Accurancy:  0.9171180931744312\n",
      "Average Personal Trainning Loss:  0.3373402064782525\n",
      "-------------Round number:  14  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8647408207343412\n",
      "Average Global Trainning Accurancy:  0.8752257132538823\n",
      "Average Global Trainning Loss:  0.47061050321359243\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9328277356446371\n",
      "Average Personal Trainning Loss:  0.2954744536681225\n",
      "-------------Round number:  15  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8644708423326134\n",
      "Average Global Trainning Accurancy:  0.875496569158541\n",
      "Average Global Trainning Loss:  0.4676977001230137\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9320151679306609\n",
      "Average Personal Trainning Loss:  0.2889311057903914\n",
      "-------------Round number:  16  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8604211663066955\n",
      "Average Global Trainning Accurancy:  0.8675514626218852\n",
      "Average Global Trainning Loss:  0.45161615979934094\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9337305886601661\n",
      "Average Personal Trainning Loss:  0.27534338832977834\n",
      "-------------Round number:  17  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8623110151187905\n",
      "Average Global Trainning Accurancy:  0.8673708920187794\n",
      "Average Global Trainning Loss:  0.43730523414928674\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9344528710725893\n",
      "Average Personal Trainning Loss:  0.26830314065885696\n",
      "-------------Round number:  18  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.855561555075594\n",
      "Average Global Trainning Accurancy:  0.8633080534488985\n",
      "Average Global Trainning Loss:  0.43803139600826113\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9346334416756952\n",
      "Average Personal Trainning Loss:  0.2671405410628837\n",
      "-------------Round number:  19  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8582613390928726\n",
      "Average Global Trainning Accurancy:  0.8688154568436258\n",
      "Average Global Trainning Loss:  0.42776307408755415\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9349042975803539\n",
      "Average Personal Trainning Loss:  0.26289574322437026\n",
      "-------------Round number:  20  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8755399568034558\n",
      "Average Global Trainning Accurancy:  0.8859696641386782\n",
      "Average Global Trainning Loss:  0.3803249812375858\n",
      "Average Personal Accurancy:  0.9200863930885529\n",
      "Average Personal Trainning Accurancy:  0.9351751534850127\n",
      "Average Personal Trainning Loss:  0.25518007509197815\n",
      "-------------Round number:  21  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8731101511879049\n",
      "Average Global Trainning Accurancy:  0.8819068255687974\n",
      "Average Global Trainning Loss:  0.3862925398948176\n",
      "Average Personal Accurancy:  0.9211663066954644\n",
      "Average Personal Trainning Accurancy:  0.9375225713253882\n",
      "Average Personal Trainning Loss:  0.2512061331581234\n",
      "-------------Round number:  22  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8755399568034558\n",
      "Average Global Trainning Accurancy:  0.8840736728060672\n",
      "Average Global Trainning Loss:  0.3736722153332656\n",
      "Average Personal Accurancy:  0.9198164146868251\n",
      "Average Personal Trainning Accurancy:  0.9344528710725893\n",
      "Average Personal Trainning Loss:  0.25312231524664813\n",
      "-------------Round number:  23  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8782397408207343\n",
      "Average Global Trainning Accurancy:  0.8902130733116649\n",
      "Average Global Trainning Loss:  0.3770152402294375\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9371614301191766\n",
      "Average Personal Trainning Loss:  0.25681883266747924\n",
      "-------------Round number:  24  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8798596112311015\n",
      "Average Global Trainning Accurancy:  0.8873239436619719\n",
      "Average Global Trainning Loss:  0.38455035980103375\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9340917298663778\n",
      "Average Personal Trainning Loss:  0.2616207058053449\n",
      "-------------Round number:  25  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8733801295896328\n",
      "Average Global Trainning Accurancy:  0.8790176959191044\n",
      "Average Global Trainning Loss:  0.411448899224675\n",
      "Average Personal Accurancy:  0.9208963282937365\n",
      "Average Personal Trainning Accurancy:  0.9320151679306609\n",
      "Average Personal Trainning Loss:  0.2712816959600149\n",
      "-------------Round number:  26  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8803995680345572\n",
      "Average Global Trainning Accurancy:  0.8872336583604189\n",
      "Average Global Trainning Loss:  0.3956497649760744\n",
      "Average Personal Accurancy:  0.9222462203023758\n",
      "Average Personal Trainning Accurancy:  0.9350848681834597\n",
      "Average Personal Trainning Loss:  0.26433444479477025\n",
      "-------------Round number:  27  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8736501079913607\n",
      "Average Global Trainning Accurancy:  0.8777537016973637\n",
      "Average Global Trainning Loss:  0.4082978628481627\n",
      "Average Personal Accurancy:  0.92170626349892\n",
      "Average Personal Trainning Accurancy:  0.933911159263272\n",
      "Average Personal Trainning Loss:  0.2631897435544759\n",
      "-------------Round number:  28  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8766198704103672\n",
      "Average Global Trainning Accurancy:  0.880371975442398\n",
      "Average Global Trainning Loss:  0.4107662929701607\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.933820873961719\n",
      "Average Personal Trainning Loss:  0.2628771835993928\n",
      "-------------Round number:  29  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8839092872570194\n",
      "Average Global Trainning Accurancy:  0.8931022029613579\n",
      "Average Global Trainning Loss:  0.38592284627234563\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.939779703864211\n",
      "Average Personal Trainning Loss:  0.24941272673601705\n",
      "-------------Round number:  30  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8922786177105831\n",
      "Average Global Trainning Accurancy:  0.8988804622607439\n",
      "Average Global Trainning Loss:  0.3754321615288687\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9373420007222825\n",
      "Average Personal Trainning Loss:  0.25451393444299614\n",
      "-------------Round number:  31  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8876889848812095\n",
      "Average Global Trainning Accurancy:  0.8931022029613579\n",
      "Average Global Trainning Loss:  0.3907436757967678\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9321957385337667\n",
      "Average Personal Trainning Loss:  0.26691396815891344\n",
      "-------------Round number:  32  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8860691144708424\n",
      "Average Global Trainning Accurancy:  0.8931022029613579\n",
      "Average Global Trainning Loss:  0.3896888190118274\n",
      "Average Personal Accurancy:  0.9235961123110151\n",
      "Average Personal Trainning Accurancy:  0.9350848681834597\n",
      "Average Personal Trainning Loss:  0.25736151433843446\n",
      "-------------Round number:  33  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8952483801295896\n",
      "Average Global Trainning Accurancy:  0.9059227157818707\n",
      "Average Global Trainning Loss:  0.34935293476604823\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9395088479595521\n",
      "Average Personal Trainning Loss:  0.24648217958592902\n",
      "-------------Round number:  34  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8941684665226782\n",
      "Average Global Trainning Accurancy:  0.9063741422896352\n",
      "Average Global Trainning Loss:  0.34628136091690365\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9430299747201155\n",
      "Average Personal Trainning Loss:  0.23528314316991694\n",
      "-------------Round number:  35  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9057775377969762\n",
      "Average Global Trainning Accurancy:  0.9147706753340556\n",
      "Average Global Trainning Loss:  0.3049350351407322\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9423076923076923\n",
      "Average Personal Trainning Loss:  0.22880645123747292\n",
      "-------------Round number:  36  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8992980561555075\n",
      "Average Global Trainning Accurancy:  0.9145901047309498\n",
      "Average Global Trainning Loss:  0.30414587635992235\n",
      "Average Personal Accurancy:  0.9222462203023758\n",
      "Average Personal Trainning Accurancy:  0.9389671361502347\n",
      "Average Personal Trainning Loss:  0.22983611366214113\n",
      "-------------Round number:  37  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8990280777537797\n",
      "Average Global Trainning Accurancy:  0.915402672444926\n",
      "Average Global Trainning Loss:  0.2945401903609155\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9401408450704225\n",
      "Average Personal Trainning Loss:  0.22669440118273745\n",
      "-------------Round number:  38  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9011879049676026\n",
      "Average Global Trainning Accurancy:  0.9117009750812568\n",
      "Average Global Trainning Loss:  0.29601268279246795\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9417659804983749\n",
      "Average Personal Trainning Loss:  0.222217233312737\n",
      "-------------Round number:  39  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9041576673866091\n",
      "Average Global Trainning Accurancy:  0.9170278078728783\n",
      "Average Global Trainning Loss:  0.288075048598885\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9445648248465149\n",
      "Average Personal Trainning Loss:  0.21569938838761737\n",
      "-------------Round number:  40  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9019978401727862\n",
      "Average Global Trainning Accurancy:  0.9157638136511376\n",
      "Average Global Trainning Loss:  0.287200475867021\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.942668833513904\n",
      "Average Personal Trainning Loss:  0.21762925875062072\n",
      "-------------Round number:  41  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9073974082073434\n",
      "Average Global Trainning Accurancy:  0.9195557963163596\n",
      "Average Global Trainning Loss:  0.28018626016414994\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9443842542434092\n",
      "Average Personal Trainning Loss:  0.21309594911717902\n",
      "-------------Round number:  42  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9044276457883369\n",
      "Average Global Trainning Accurancy:  0.9175695196821957\n",
      "Average Global Trainning Loss:  0.27980279009795955\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9440231130371975\n",
      "Average Personal Trainning Loss:  0.21228410879943121\n",
      "-------------Round number:  43  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9065874730021598\n",
      "Average Global Trainning Accurancy:  0.91738894907909\n",
      "Average Global Trainning Loss:  0.2790732557655629\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9440231130371975\n",
      "Average Personal Trainning Loss:  0.21073239630592047\n",
      "-------------Round number:  44  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8995680345572354\n",
      "Average Global Trainning Accurancy:  0.918201516793066\n",
      "Average Global Trainning Loss:  0.281971510931575\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9419465511014807\n",
      "Average Personal Trainning Loss:  0.2151292640407751\n",
      "-------------Round number:  45  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9017278617710583\n",
      "Average Global Trainning Accurancy:  0.9191043698085951\n",
      "Average Global Trainning Loss:  0.27809462128842766\n",
      "Average Personal Accurancy:  0.9252159827213823\n",
      "Average Personal Trainning Accurancy:  0.9436619718309859\n",
      "Average Personal Trainning Loss:  0.21122473334095115\n",
      "-------------Round number:  46  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9038876889848813\n",
      "Average Global Trainning Accurancy:  0.9178403755868545\n",
      "Average Global Trainning Loss:  0.28199478761088165\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9428494041170098\n",
      "Average Personal Trainning Loss:  0.21344763417242235\n",
      "-------------Round number:  47  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9025377969762419\n",
      "Average Global Trainning Accurancy:  0.91738894907909\n",
      "Average Global Trainning Loss:  0.28675627923691993\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9412242686890574\n",
      "Average Personal Trainning Loss:  0.21439230144992552\n",
      "-------------Round number:  48  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9025377969762419\n",
      "Average Global Trainning Accurancy:  0.915402672444926\n",
      "Average Global Trainning Loss:  0.2882958464176485\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9440231130371975\n",
      "Average Personal Trainning Loss:  0.21266085596108703\n",
      "-------------Round number:  49  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8984881209503239\n",
      "Average Global Trainning Accurancy:  0.9119718309859155\n",
      "Average Global Trainning Loss:  0.2915754996727158\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9427591188154568\n",
      "Average Personal Trainning Loss:  0.2120498651715985\n",
      "-------------Round number:  50  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9079373650107991\n",
      "Average Global Trainning Accurancy:  0.9213615023474179\n",
      "Average Global Trainning Loss:  0.27565149573825165\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9450162513542795\n",
      "Average Personal Trainning Loss:  0.20790260455461132\n",
      "-------------Round number:  51  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9228060671722643\n",
      "Average Global Trainning Loss:  0.27273752440524557\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9465511014806789\n",
      "Average Personal Trainning Loss:  0.20488234520302906\n",
      "-------------Round number:  52  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9046976241900648\n",
      "Average Global Trainning Accurancy:  0.917298663777537\n",
      "Average Global Trainning Loss:  0.2816356081702555\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9450162513542795\n",
      "Average Personal Trainning Loss:  0.20726829300119629\n",
      "-------------Round number:  53  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.900377969762419\n",
      "Average Global Trainning Accurancy:  0.914409534127844\n",
      "Average Global Trainning Loss:  0.29040864591092225\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9445648248465149\n",
      "Average Personal Trainning Loss:  0.2133157770743048\n",
      "-------------Round number:  54  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9209100758396533\n",
      "Average Global Trainning Loss:  0.27995642499830714\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9469122426868906\n",
      "Average Personal Trainning Loss:  0.20517165052111547\n",
      "-------------Round number:  55  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9256049115204045\n",
      "Average Global Trainning Loss:  0.2634173524470138\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9470025279884435\n",
      "Average Personal Trainning Loss:  0.20173948652350804\n",
      "-------------Round number:  56  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9276814734561214\n",
      "Average Global Trainning Loss:  0.2633163986674454\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.20468755731000587\n",
      "-------------Round number:  57  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9282231852654388\n",
      "Average Global Trainning Loss:  0.26496575859403215\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.20540441731418158\n",
      "-------------Round number:  58  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9256951968219573\n",
      "Average Global Trainning Loss:  0.26868601558267874\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9481762369086313\n",
      "Average Personal Trainning Loss:  0.20379693777649874\n",
      "-------------Round number:  59  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9265077645359335\n",
      "Average Global Trainning Loss:  0.26529046386189736\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.949440231130372\n",
      "Average Personal Trainning Loss:  0.2028158125183392\n",
      "-------------Round number:  60  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9267786204405922\n",
      "Average Global Trainning Loss:  0.2577458660970228\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9480859516070783\n",
      "Average Personal Trainning Loss:  0.1979169091320761\n",
      "-------------Round number:  61  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9098272138228942\n",
      "Average Global Trainning Accurancy:  0.9250631997110871\n",
      "Average Global Trainning Loss:  0.25625816447160527\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9450162513542795\n",
      "Average Personal Trainning Loss:  0.20085021157090782\n",
      "-------------Round number:  62  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9256049115204045\n",
      "Average Global Trainning Loss:  0.25517502740299974\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.946460816179126\n",
      "Average Personal Trainning Loss:  0.19735419100137686\n",
      "-------------Round number:  63  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9090172786177105\n",
      "Average Global Trainning Accurancy:  0.9243409172986637\n",
      "Average Global Trainning Loss:  0.2592048906771962\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9446551101480679\n",
      "Average Personal Trainning Loss:  0.20250411221334416\n",
      "-------------Round number:  64  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9253340556157458\n",
      "Average Global Trainning Loss:  0.2583672388144976\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9446551101480679\n",
      "Average Personal Trainning Loss:  0.20108943676078908\n",
      "-------------Round number:  65  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9285843264716505\n",
      "Average Global Trainning Loss:  0.2562521028363692\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9482665222101841\n",
      "Average Personal Trainning Loss:  0.19926285666220883\n",
      "-------------Round number:  66  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9286746117732033\n",
      "Average Global Trainning Loss:  0.255077247716064\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9483568075117371\n",
      "Average Personal Trainning Loss:  0.19515701354561665\n",
      "-------------Round number:  67  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9092872570194385\n",
      "Average Global Trainning Accurancy:  0.9227157818707115\n",
      "Average Global Trainning Loss:  0.2629871085991107\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9465511014806789\n",
      "Average Personal Trainning Loss:  0.1983898048497314\n",
      "-------------Round number:  68  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9269591910436981\n",
      "Average Global Trainning Loss:  0.25390292161119765\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.19423643851288822\n",
      "-------------Round number:  69  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9269591910436981\n",
      "Average Global Trainning Loss:  0.2574612117063358\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.1963505825870689\n",
      "-------------Round number:  70  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9284037558685446\n",
      "Average Global Trainning Loss:  0.2535973270260586\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9478150957024196\n",
      "Average Personal Trainning Loss:  0.19740894409929127\n",
      "-------------Round number:  71  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.9281328999638859\n",
      "Average Global Trainning Loss:  0.25834517446223815\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.19695288870643735\n",
      "-------------Round number:  72  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9249729144095341\n",
      "Average Global Trainning Loss:  0.26618815897689824\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.946460816179126\n",
      "Average Personal Trainning Loss:  0.198775809781566\n",
      "-------------Round number:  73  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9245214879017696\n",
      "Average Global Trainning Loss:  0.26722383895218266\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.1979489586507426\n",
      "-------------Round number:  74  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9253340556157458\n",
      "Average Global Trainning Loss:  0.2632300148547535\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9481762369086313\n",
      "Average Personal Trainning Loss:  0.1962432365376151\n",
      "-------------Round number:  75  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9256049115204045\n",
      "Average Global Trainning Loss:  0.25387924817031193\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.19266162567855047\n",
      "-------------Round number:  76  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9284037558685446\n",
      "Average Global Trainning Loss:  0.2463284785586516\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9486276634163958\n",
      "Average Personal Trainning Loss:  0.18993009854499593\n",
      "-------------Round number:  77  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9301191765980499\n",
      "Average Global Trainning Loss:  0.24472509889061936\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.19016299759192173\n",
      "-------------Round number:  78  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9335500180570603\n",
      "Average Global Trainning Loss:  0.2414118311128792\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.19320986201161294\n",
      "-------------Round number:  79  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9321054532322138\n",
      "Average Global Trainning Loss:  0.24494953369052455\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.19339988876568706\n",
      "-------------Round number:  80  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9312026002166848\n",
      "Average Global Trainning Loss:  0.2461598769298483\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9486276634163958\n",
      "Average Personal Trainning Loss:  0.19210049459416756\n",
      "-------------Round number:  81  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9300288912964969\n",
      "Average Global Trainning Loss:  0.24940014057703594\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9487179487179487\n",
      "Average Personal Trainning Loss:  0.19220473267791846\n",
      "-------------Round number:  82  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9303900325027086\n",
      "Average Global Trainning Loss:  0.24670086134293742\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.949440231130372\n",
      "Average Personal Trainning Loss:  0.18878522096622202\n",
      "-------------Round number:  83  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9321957385337667\n",
      "Average Global Trainning Loss:  0.24791545874808144\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.948537378114843\n",
      "Average Personal Trainning Loss:  0.19212491747359156\n",
      "-------------Round number:  84  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9117170626349892\n",
      "Average Global Trainning Accurancy:  0.9243409172986637\n",
      "Average Global Trainning Loss:  0.25653431053065184\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.18946509397430256\n",
      "-------------Round number:  85  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9285843264716505\n",
      "Average Global Trainning Loss:  0.24665957609640213\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.1862362702859787\n",
      "-------------Round number:  86  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9313831708197905\n",
      "Average Global Trainning Loss:  0.24081792311360148\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.18641838385078097\n",
      "-------------Round number:  87  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9312026002166848\n",
      "Average Global Trainning Loss:  0.23861512486880418\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9501625135427952\n",
      "Average Personal Trainning Loss:  0.18544684699744943\n",
      "-------------Round number:  88  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9304803178042614\n",
      "Average Global Trainning Loss:  0.23519865499588075\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.1861492913309182\n",
      "-------------Round number:  89  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9303900325027086\n",
      "Average Global Trainning Loss:  0.23600114937421002\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9503430841459011\n",
      "Average Personal Trainning Loss:  0.18337147534646983\n",
      "-------------Round number:  90  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9098272138228942\n",
      "Average Global Trainning Accurancy:  0.9271397616468039\n",
      "Average Global Trainning Loss:  0.2418262926668585\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.1895568340683121\n",
      "-------------Round number:  91  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9117170626349892\n",
      "Average Global Trainning Accurancy:  0.9267786204405922\n",
      "Average Global Trainning Loss:  0.24340694671333288\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9470025279884435\n",
      "Average Personal Trainning Loss:  0.18902687081019773\n",
      "-------------Round number:  92  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9293968941856265\n",
      "Average Global Trainning Loss:  0.23595058431518598\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.18419027001300672\n",
      "-------------Round number:  93  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9296677500902853\n",
      "Average Global Trainning Loss:  0.2354501357100939\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.18171632931352136\n",
      "-------------Round number:  94  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9283134705669916\n",
      "Average Global Trainning Loss:  0.23653016481299657\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9492596605272662\n",
      "Average Personal Trainning Loss:  0.18279979701677615\n",
      "-------------Round number:  95  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9264174792343807\n",
      "Average Global Trainning Loss:  0.24056174738736907\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9491693752257132\n",
      "Average Personal Trainning Loss:  0.1849440178228828\n",
      "-------------Round number:  96  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9090172786177105\n",
      "Average Global Trainning Accurancy:  0.9258757674250632\n",
      "Average Global Trainning Loss:  0.24209780984081572\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.18835438197595025\n",
      "-------------Round number:  97  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9103671706263499\n",
      "Average Global Trainning Accurancy:  0.9295774647887324\n",
      "Average Global Trainning Loss:  0.2340836447470883\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9499819429396894\n",
      "Average Personal Trainning Loss:  0.18300378757420324\n",
      "-------------Round number:  98  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.929035752979415\n",
      "Average Global Trainning Loss:  0.2346926517286814\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.18421477004051554\n",
      "-------------Round number:  99  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9330083062477429\n",
      "Average Global Trainning Loss:  0.23220167232360509\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9505236547490069\n",
      "Average Personal Trainning Loss:  0.18359728779074688\n",
      "-------------Round number:  100  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9335500180570603\n",
      "Average Global Trainning Loss:  0.23199328432534308\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.1830193163815626\n",
      "-------------Round number:  101  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9310220296135789\n",
      "Average Global Trainning Loss:  0.23588214294279297\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.18112124205066135\n",
      "-------------Round number:  102  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9254243409172986\n",
      "Average Global Trainning Loss:  0.2452886105444768\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9497110870350307\n",
      "Average Personal Trainning Loss:  0.18664312724302545\n",
      "-------------Round number:  103  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9278620440592271\n",
      "Average Global Trainning Loss:  0.24101295347203414\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.1820956333831313\n",
      "-------------Round number:  104  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9316540267244493\n",
      "Average Global Trainning Loss:  0.23095227011105093\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.18008599190042096\n",
      "-------------Round number:  105  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9312928855182376\n",
      "Average Global Trainning Loss:  0.23594031259874954\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.18443840029610759\n",
      "-------------Round number:  106  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9349945828819068\n",
      "Average Global Trainning Loss:  0.22998677285064553\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.1807959416404275\n",
      "-------------Round number:  107  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9360780065005417\n",
      "Average Global Trainning Loss:  0.22536051079614708\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.180676273939712\n",
      "-------------Round number:  108  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9360780065005417\n",
      "Average Global Trainning Loss:  0.22959307515263858\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9504333694474539\n",
      "Average Personal Trainning Loss:  0.18598578147571326\n",
      "-------------Round number:  109  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.22713661400494312\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.18388313246617122\n",
      "-------------Round number:  110  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9372517154207295\n",
      "Average Global Trainning Loss:  0.22437424967976932\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9511556518598772\n",
      "Average Personal Trainning Loss:  0.18200093961958852\n",
      "-------------Round number:  111  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.22286640138305797\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.18011145076841256\n",
      "-------------Round number:  112  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9368905742145178\n",
      "Average Global Trainning Loss:  0.22299171191512054\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.17978395714833875\n",
      "-------------Round number:  113  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9117170626349892\n",
      "Average Global Trainning Accurancy:  0.9342723004694836\n",
      "Average Global Trainning Loss:  0.22630213623487722\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.1818084331056451\n",
      "-------------Round number:  114  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9314734561213435\n",
      "Average Global Trainning Loss:  0.2326406008416283\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.18506677144699124\n",
      "-------------Round number:  115  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9365294330083063\n",
      "Average Global Trainning Loss:  0.22314010074570018\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17969227216010406\n",
      "-------------Round number:  116  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9336403033586133\n",
      "Average Global Trainning Loss:  0.22855622693492686\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9512459371614301\n",
      "Average Personal Trainning Loss:  0.1820112774629548\n",
      "-------------Round number:  117  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9325568797399784\n",
      "Average Global Trainning Loss:  0.2302111856082408\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9492596605272662\n",
      "Average Personal Trainning Loss:  0.18338895489825974\n",
      "-------------Round number:  118  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9308414590104731\n",
      "Average Global Trainning Loss:  0.23166520658405562\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9495305164319249\n",
      "Average Personal Trainning Loss:  0.182406176466854\n",
      "-------------Round number:  119  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9316540267244493\n",
      "Average Global Trainning Loss:  0.2307439702820287\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.1820550094058945\n",
      "-------------Round number:  120  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9302094618996027\n",
      "Average Global Trainning Loss:  0.2311533841470296\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.18384872442034014\n",
      "-------------Round number:  121  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9103671706263499\n",
      "Average Global Trainning Accurancy:  0.9257854821235103\n",
      "Average Global Trainning Loss:  0.23994482721650415\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.1840795845535956\n",
      "-------------Round number:  122  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9355362946912242\n",
      "Average Global Trainning Loss:  0.222776138123815\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.17899264924230882\n",
      "-------------Round number:  123  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9360780065005417\n",
      "Average Global Trainning Loss:  0.22157280433905516\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.1785075971907164\n",
      "-------------Round number:  124  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9357168652943301\n",
      "Average Global Trainning Loss:  0.22014715181614528\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.951426507764536\n",
      "Average Personal Trainning Loss:  0.1757557470473885\n",
      "-------------Round number:  125  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9363488624052004\n",
      "Average Global Trainning Loss:  0.2199054799298596\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17410730187666462\n",
      "-------------Round number:  126  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9362585771036476\n",
      "Average Global Trainning Loss:  0.2223770621021804\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.17760043490359223\n",
      "-------------Round number:  127  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.21879448138147797\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17915812086309926\n",
      "-------------Round number:  128  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.21724257050717768\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.1760614518440773\n",
      "-------------Round number:  129  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.939779703864211\n",
      "Average Global Trainning Loss:  0.2142330457605408\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.17319068343857213\n",
      "-------------Round number:  130  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9362585771036476\n",
      "Average Global Trainning Loss:  0.22060591841312296\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17482279525762345\n",
      "-------------Round number:  131  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9353557240881184\n",
      "Average Global Trainning Loss:  0.21978142580946416\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17512059788619538\n",
      "-------------Round number:  132  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9388768508486819\n",
      "Average Global Trainning Loss:  0.21406644998194294\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1698886131542863\n",
      "-------------Round number:  133  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9369808595160708\n",
      "Average Global Trainning Loss:  0.21759121372364798\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17246280227942173\n",
      "-------------Round number:  134  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9383351390393644\n",
      "Average Global Trainning Loss:  0.22113896759463028\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.1801332726552625\n",
      "-------------Round number:  135  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.21955591093637145\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17735136782231853\n",
      "-------------Round number:  136  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9395991332611051\n",
      "Average Global Trainning Loss:  0.21746544030307646\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17655174996543765\n",
      "-------------Round number:  137  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.21670447363669196\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.1756762734988658\n",
      "-------------Round number:  138  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.2156237391798709\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17426393453116537\n",
      "-------------Round number:  139  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9381545684362586\n",
      "Average Global Trainning Loss:  0.21714419567787333\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.1783834438799262\n",
      "-------------Round number:  140  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9382448537378115\n",
      "Average Global Trainning Loss:  0.21867776735029568\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17655534286195942\n",
      "-------------Round number:  141  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9384254243409172\n",
      "Average Global Trainning Loss:  0.2158870566145269\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.17593489592150258\n",
      "-------------Round number:  142  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9374322860238353\n",
      "Average Global Trainning Loss:  0.2168244719720567\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.1778229189590669\n",
      "-------------Round number:  143  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9364391477067533\n",
      "Average Global Trainning Loss:  0.21873071297879423\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.1771523257634751\n",
      "-------------Round number:  144  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9364391477067533\n",
      "Average Global Trainning Loss:  0.21642742384293742\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.1744008172759514\n",
      "-------------Round number:  145  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9336403033586133\n",
      "Average Global Trainning Loss:  0.2253712674434024\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9501625135427952\n",
      "Average Personal Trainning Loss:  0.18057249874447004\n",
      "-------------Round number:  146  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9349042975803539\n",
      "Average Global Trainning Loss:  0.2219388168957656\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9504333694474539\n",
      "Average Personal Trainning Loss:  0.17791626814170278\n",
      "-------------Round number:  147  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9362585771036476\n",
      "Average Global Trainning Loss:  0.21848331009192173\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.17399398236121455\n",
      "-------------Round number:  148  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9373420007222825\n",
      "Average Global Trainning Loss:  0.2149700965206302\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.17301878648443142\n",
      "-------------Round number:  149  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9392379920548934\n",
      "Average Global Trainning Loss:  0.21256045323926734\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.16937080623010903\n",
      "-------------Round number:  150  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.939689418562658\n",
      "Average Global Trainning Loss:  0.2190885257962035\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17798672638545618\n",
      "-------------Round number:  151  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.939689418562658\n",
      "Average Global Trainning Loss:  0.2178141496464766\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.17779149764623398\n",
      "-------------Round number:  152  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.2130202778671226\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.17412298498019366\n",
      "-------------Round number:  153  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.939689418562658\n",
      "Average Global Trainning Loss:  0.21305867557105454\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17386290776510022\n",
      "-------------Round number:  154  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9364391477067533\n",
      "Average Global Trainning Loss:  0.22039922767272707\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9507042253521126\n",
      "Average Personal Trainning Loss:  0.18149009806535527\n",
      "-------------Round number:  155  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.23179682121676373\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.18805403346057917\n",
      "-------------Round number:  156  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.231565200623815\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.18632108909466413\n",
      "-------------Round number:  157  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9383351390393644\n",
      "Average Global Trainning Loss:  0.21944748481373014\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9503430841459011\n",
      "Average Personal Trainning Loss:  0.18122377185539115\n",
      "-------------Round number:  158  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9332791621524016\n",
      "Average Global Trainning Loss:  0.2289256560496795\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.18629790058459733\n",
      "-------------Round number:  159  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.22760485879519907\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.18566508790825884\n",
      "-------------Round number:  160  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9340917298663778\n",
      "Average Global Trainning Loss:  0.2251093827588931\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9478150957024196\n",
      "Average Personal Trainning Loss:  0.18664184878904838\n",
      "-------------Round number:  161  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9371614301191766\n",
      "Average Global Trainning Loss:  0.2176397288478467\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9497110870350307\n",
      "Average Personal Trainning Loss:  0.17971582436828504\n",
      "-------------Round number:  162  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9375225713253882\n",
      "Average Global Trainning Loss:  0.21654726788213255\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17870215363948516\n",
      "-------------Round number:  163  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9355362946912242\n",
      "Average Global Trainning Loss:  0.22068456537502257\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.18160442050590805\n",
      "-------------Round number:  164  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9358974358974359\n",
      "Average Global Trainning Loss:  0.21890815357388724\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9491693752257132\n",
      "Average Personal Trainning Loss:  0.18157323063732958\n",
      "-------------Round number:  165  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9344528710725893\n",
      "Average Global Trainning Loss:  0.2237222381514649\n",
      "Average Personal Accurancy:  0.9252159827213823\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.18400796908856987\n",
      "-------------Round number:  166  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9092872570194385\n",
      "Average Global Trainning Accurancy:  0.931924882629108\n",
      "Average Global Trainning Loss:  0.23003738199428944\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9462802455760202\n",
      "Average Personal Trainning Loss:  0.1900772089215985\n",
      "-------------Round number:  167  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9347237269772481\n",
      "Average Global Trainning Loss:  0.2238040151213773\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.1857422800777018\n",
      "-------------Round number:  168  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.936800288912965\n",
      "Average Global Trainning Loss:  0.22001941662998825\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9492596605272662\n",
      "Average Personal Trainning Loss:  0.18093900725315434\n",
      "-------------Round number:  169  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9357168652943301\n",
      "Average Global Trainning Loss:  0.22396684166497383\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.18229798178846718\n",
      "-------------Round number:  170  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.21527756470211493\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9501625135427952\n",
      "Average Personal Trainning Loss:  0.1800922078318267\n",
      "-------------Round number:  171  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.938696280245576\n",
      "Average Global Trainning Loss:  0.21732249592305436\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9492596605272662\n",
      "Average Personal Trainning Loss:  0.17895975109470927\n",
      "-------------Round number:  172  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.20793383850780967\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17344534926657298\n",
      "-------------Round number:  173  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9393282773564464\n",
      "Average Global Trainning Loss:  0.20969574646899827\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9512459371614301\n",
      "Average Personal Trainning Loss:  0.17425734388049047\n",
      "-------------Round number:  174  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9395088479595521\n",
      "Average Global Trainning Loss:  0.21038531809345656\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.1753659949228625\n",
      "-------------Round number:  175  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9402311303719755\n",
      "Average Global Trainning Loss:  0.21003184761110735\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.1740961154043653\n",
      "-------------Round number:  176  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9394185626579993\n",
      "Average Global Trainning Loss:  0.21113471254711763\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9511556518598772\n",
      "Average Personal Trainning Loss:  0.17481807820329429\n",
      "-------------Round number:  177  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9393282773564464\n",
      "Average Global Trainning Loss:  0.21083645805119178\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.17102852019216663\n",
      "-------------Round number:  178  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9372517154207295\n",
      "Average Global Trainning Loss:  0.21556195458508262\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9497110870350307\n",
      "Average Personal Trainning Loss:  0.17556791350315434\n",
      "-------------Round number:  179  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.21566372393011918\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.1758166830132437\n",
      "-------------Round number:  180  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9401408450704225\n",
      "Average Global Trainning Loss:  0.21079847915114888\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17046450156518034\n",
      "-------------Round number:  181  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9395991332611051\n",
      "Average Global Trainning Loss:  0.21287307932128025\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17125966687545144\n",
      "-------------Round number:  182  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.2068717298028959\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16932731675257878\n",
      "-------------Round number:  183  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.21101142990757044\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.1726651837482225\n",
      "-------------Round number:  184  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.20901915776510022\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16840783281419286\n",
      "-------------Round number:  185  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.21169194214263948\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.17464602695298392\n",
      "-------------Round number:  186  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.21068225005078547\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17269843457278125\n",
      "-------------Round number:  187  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.20521591147949395\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.1684268112430593\n",
      "-------------Round number:  188  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.20428206697617596\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16797604600459326\n",
      "-------------Round number:  189  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.20934443613302411\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.17244120081567127\n",
      "-------------Round number:  190  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.20436238915363172\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.17032811477236817\n",
      "-------------Round number:  191  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.203920198373736\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.16964435129658156\n",
      "-------------Round number:  192  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20429588750451427\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16795268115604686\n",
      "-------------Round number:  193  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.2015047800071664\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.16804608544445762\n",
      "-------------Round number:  194  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.19993206119227383\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16593996477109854\n",
      "-------------Round number:  195  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.2014668892763633\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.16566042419631974\n",
      "-------------Round number:  196  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.203819487059577\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16862903841569046\n",
      "-------------Round number:  197  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.21032229912931114\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.1740821626221673\n",
      "-------------Round number:  198  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.2046159198026702\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.1695450286479494\n",
      "-------------Round number:  199  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20409382564920775\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.1671398930189712\n",
      "-------------Round number:  200  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.2058051024244425\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1692477770771262\n",
      "-------------Round number:  201  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.2052438390861999\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16799571876622313\n",
      "-------------Round number:  202  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.21798116422896352\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.177028547171954\n",
      "-------------Round number:  203  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.21514251146905472\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.951426507764536\n",
      "Average Personal Trainning Loss:  0.17755511591433618\n",
      "-------------Round number:  204  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9393282773564464\n",
      "Average Global Trainning Loss:  0.21185252037062116\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9512459371614301\n",
      "Average Personal Trainning Loss:  0.17284013356229122\n",
      "-------------Round number:  205  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9409534127843987\n",
      "Average Global Trainning Loss:  0.20474995908947274\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17161580447730454\n",
      "-------------Round number:  206  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9420368364030336\n",
      "Average Global Trainning Loss:  0.2016839619447454\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16860776758658924\n",
      "-------------Round number:  207  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.20472509536384975\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.17089254118208852\n",
      "-------------Round number:  208  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.20564110763841864\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.16987425258935424\n",
      "-------------Round number:  209  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9384254243409172\n",
      "Average Global Trainning Loss:  0.2096084148369786\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.17648473032203638\n",
      "-------------Round number:  210  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9409534127843987\n",
      "Average Global Trainning Loss:  0.20328729752815772\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.1715121064301474\n",
      "-------------Round number:  211  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20168550490644185\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.17010949914228962\n",
      "-------------Round number:  212  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.20130240955952058\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.1697567670773237\n",
      "-------------Round number:  213  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.1974207367351142\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16637609391575817\n",
      "-------------Round number:  214  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.20016297643130418\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.167249410235955\n",
      "-------------Round number:  215  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.20140924863584553\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.1693542083707171\n",
      "-------------Round number:  216  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.20869015424679488\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.17301837870169737\n",
      "-------------Round number:  217  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20421040742653035\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.1674114101929284\n",
      "-------------Round number:  218  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.20489175726937747\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.16897980871507087\n",
      "-------------Round number:  219  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.20580281002420775\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.1713922072851774\n",
      "-------------Round number:  220  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.21042272389344077\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9517876489707475\n",
      "Average Personal Trainning Loss:  0.17370439049309883\n",
      "-------------Round number:  221  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9380642831347057\n",
      "Average Global Trainning Loss:  0.21104074617980317\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9515167930660888\n",
      "Average Personal Trainning Loss:  0.1718876853493759\n",
      "-------------Round number:  222  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.20255465523005822\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.17066389630098297\n",
      "-------------Round number:  223  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.19743991354477022\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.16605910345637528\n",
      "-------------Round number:  224  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.1971595133199034\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16563440324942444\n",
      "-------------Round number:  225  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20384192613110555\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.17084932723343266\n",
      "-------------Round number:  226  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.20078646521053403\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16770564196728852\n",
      "-------------Round number:  227  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.1971141282037175\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16403161872376085\n",
      "-------------Round number:  228  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9432105453232213\n",
      "Average Global Trainning Loss:  0.19780824054402538\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.16317266296849608\n",
      "-------------Round number:  229  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19740867959157188\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16267989610842137\n",
      "-------------Round number:  230  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.19755268200247156\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16286559154859043\n",
      "-------------Round number:  231  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9414951245937161\n",
      "Average Global Trainning Loss:  0.2000003041838773\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16433853584749683\n",
      "-------------Round number:  232  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.20369413244289455\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16490536486900167\n",
      "-------------Round number:  233  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9389671361502347\n",
      "Average Global Trainning Loss:  0.20736120133763317\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.1713733390678607\n",
      "-------------Round number:  234  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9351751534850127\n",
      "Average Global Trainning Loss:  0.21528743965697228\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.17740832515122787\n",
      "-------------Round number:  235  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9381545684362586\n",
      "Average Global Trainning Loss:  0.21124192634271172\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.17274145014064757\n",
      "-------------Round number:  236  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.20545321898840962\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.16844605417964517\n",
      "-------------Round number:  237  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19992904139581077\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.16759958539296677\n",
      "-------------Round number:  238  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.1969781932782593\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.1649193507146646\n",
      "-------------Round number:  239  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.19577959859013858\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.1625696184317443\n",
      "-------------Round number:  240  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.19843333841188154\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16466294354417774\n",
      "-------------Round number:  241  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9454676778620441\n",
      "Average Global Trainning Loss:  0.1968072992492213\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.16130891953534104\n",
      "-------------Round number:  242  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20272008276622877\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.1630559048526939\n",
      "-------------Round number:  243  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.19514716063306925\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.1600381473032909\n",
      "-------------Round number:  244  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.19327001547546496\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16180460700148405\n",
      "-------------Round number:  245  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9454676778620441\n",
      "Average Global Trainning Loss:  0.1897582126120102\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.15935643376232958\n",
      "-------------Round number:  246  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19225721541790808\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.15888243592917684\n",
      "-------------Round number:  247  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9432105453232213\n",
      "Average Global Trainning Loss:  0.1937308540495779\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9561213434452871\n",
      "Average Personal Trainning Loss:  0.15949844134417884\n",
      "-------------Round number:  248  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.194388684747709\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.1599881333020156\n",
      "-------------Round number:  249  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19511451597203414\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16033791169744832\n",
      "-------------Round number:  250  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19902001653349585\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16474518340259908\n",
      "-------------Round number:  251  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.19981168813763994\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16397312945431\n",
      "-------------Round number:  252  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.19798122859250858\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.16707228925435627\n",
      "-------------Round number:  253  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.2002180601638678\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.16666885987650665\n",
      "-------------Round number:  254  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19995273687900642\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.1651587853064904\n",
      "-------------Round number:  255  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.19869295273846604\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.1650372770728941\n",
      "-------------Round number:  256  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.19895598362309272\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.1666643852875869\n",
      "-------------Round number:  257  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.19365987781154073\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.16301060790574778\n",
      "-------------Round number:  258  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.19122422460443753\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.1605362814658383\n",
      "-------------Round number:  259  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9451968219573853\n",
      "Average Global Trainning Loss:  0.19417930484549928\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16506809222220342\n",
      "-------------Round number:  260  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.18882198753921767\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.16115413843487608\n",
      "-------------Round number:  261  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.1897423862334665\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.15929272046542073\n",
      "-------------Round number:  262  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.19069128563447996\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16109691659824735\n",
      "-------------Round number:  263  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18777830620542163\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15825004205672738\n",
      "-------------Round number:  264  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.19327964796491287\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16336736269227947\n",
      "-------------Round number:  265  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.19585048665893598\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16536538787764649\n",
      "-------------Round number:  266  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.19671529464749232\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16441177142230384\n",
      "-------------Round number:  267  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20426837870169737\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16877383434974833\n",
      "-------------Round number:  268  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20747743043799657\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17253521126760563\n",
      "-------------Round number:  269  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9349042975803539\n",
      "Average Global Trainning Loss:  0.22023375605193662\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.17622068549115205\n",
      "-------------Round number:  270  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9364391477067533\n",
      "Average Global Trainning Loss:  0.22003145173122066\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17710058144086877\n",
      "-------------Round number:  271  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.20670151908546633\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.17373646205407525\n",
      "-------------Round number:  272  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.20744203048821777\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9520585048754063\n",
      "Average Personal Trainning Loss:  0.17387597885490025\n",
      "-------------Round number:  273  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9359877211989888\n",
      "Average Global Trainning Loss:  0.21855353689142065\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9499819429396894\n",
      "Average Personal Trainning Loss:  0.17901324778095656\n",
      "-------------Round number:  274  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9327374503430842\n",
      "Average Global Trainning Loss:  0.22512531934898655\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.18672904816720837\n",
      "-------------Round number:  275  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9359877211989888\n",
      "Average Global Trainning Loss:  0.21963632128306698\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.17931789454676778\n",
      "-------------Round number:  276  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.910097192224622\n",
      "Average Global Trainning Accurancy:  0.9305706031058144\n",
      "Average Global Trainning Loss:  0.23046517914578818\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.1862333386587554\n",
      "-------------Round number:  277  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9355362946912242\n",
      "Average Global Trainning Loss:  0.21843931364126265\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.18090448899577352\n",
      "-------------Round number:  278  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.20293109379937477\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.17063883419457046\n",
      "-------------Round number:  279  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20516375937415357\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.17364260589831054\n",
      "-------------Round number:  280  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.20085208516725353\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.1691942914120339\n",
      "-------------Round number:  281  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9449259660527266\n",
      "Average Global Trainning Loss:  0.19654202004897978\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.16834393215764942\n",
      "-------------Round number:  282  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19860703181428313\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16704951954817848\n",
      "-------------Round number:  283  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.1994251762326765\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16786007039079429\n",
      "-------------Round number:  284  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.19928011579089924\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16673303606192444\n",
      "-------------Round number:  285  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.19929115898818392\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16656270411179014\n",
      "-------------Round number:  286  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.20001842296265573\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16714123759987812\n",
      "-------------Round number:  287  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.1936317297817353\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16246968961958852\n",
      "-------------Round number:  288  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.1982148109510428\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.1646143402507392\n",
      "-------------Round number:  289  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.1903995115776792\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16201313827476074\n",
      "-------------Round number:  290  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.1933200074344303\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16473269643401273\n",
      "-------------Round number:  291  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.1990023386009164\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16806155914604212\n",
      "-------------Round number:  292  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.1996790816009841\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.16949948923559385\n",
      "-------------Round number:  293  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.1957020317014265\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16756359030081933\n",
      "-------------Round number:  294  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.19340566385089383\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16389263093837464\n",
      "-------------Round number:  295  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.19198479450924297\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.16132709341989437\n",
      "-------------Round number:  296  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.19252957019964337\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16407826025161384\n",
      "-------------Round number:  297  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9451968219573853\n",
      "Average Global Trainning Loss:  0.19093705739041622\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.16058914994625204\n",
      "-------------Round number:  298  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.1885867740497472\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.16058090612233095\n",
      "-------------Round number:  299  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.19204020887645584\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16423271071742956\n",
      "-------------Round number:  300  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19228769993256817\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.1642812699262482\n",
      "-------------Round number:  301  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9470025279884435\n",
      "Average Global Trainning Loss:  0.18797534241405967\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16137536607868364\n",
      "-------------Round number:  302  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.1873447119264062\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.15852743350628612\n",
      "-------------Round number:  303  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.18662619874898428\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.16014550437389966\n",
      "-------------Round number:  304  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18745163917197094\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15971229583530833\n",
      "-------------Round number:  305  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18353400431888203\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15661265110444317\n",
      "-------------Round number:  306  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.18994001758447318\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.1599403235317353\n",
      "-------------Round number:  307  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.1892932962105566\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.16045311583039906\n",
      "-------------Round number:  308  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.18893552747776723\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15956301429117575\n",
      "-------------Round number:  309  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18645338703898068\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15592809410549838\n",
      "-------------Round number:  310  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.18920794838643237\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15656484133416282\n",
      "-------------Round number:  311  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.19086204740965826\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15863190303429148\n",
      "-------------Round number:  312  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19126974197448313\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.15667513003199485\n",
      "-------------Round number:  313  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18563482381669827\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.15512518092328006\n",
      "-------------Round number:  314  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.18153509744111707\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15481054899106175\n",
      "-------------Round number:  315  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.1826381607579169\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.15266206299797985\n",
      "-------------Round number:  316  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.18190927667366377\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15258672238257268\n",
      "-------------Round number:  317  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.1803377812069734\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.15133145691557195\n",
      "-------------Round number:  318  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.18080464835285753\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.1517812302500903\n",
      "-------------Round number:  319  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.1836624669012674\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15236634336769816\n",
      "-------------Round number:  320  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.1870175158775167\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15493110940533023\n",
      "-------------Round number:  321  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18448984704752958\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15291712558755982\n",
      "-------------Round number:  322  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.18636698118397887\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15489425466309475\n",
      "-------------Round number:  323  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.18584515153823583\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.15827496088812523\n",
      "-------------Round number:  324  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.1798585262828977\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.1517899920682952\n",
      "-------------Round number:  325  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.1795324764341256\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15244699617980317\n",
      "-------------Round number:  326  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.17910850362340308\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15264524471548843\n",
      "-------------Round number:  327  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.1803310693235938\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.15241626919973367\n",
      "-------------Round number:  328  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.18079151113612765\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.1522958410393249\n",
      "-------------Round number:  329  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.1828924188031837\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.1537522205423043\n",
      "-------------Round number:  330  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.18779133321060176\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15790516807525845\n",
      "-------------Round number:  331  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.19271011876043923\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.16154304193046903\n",
      "-------------Round number:  332  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.18730609379937477\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.158248466031566\n",
      "-------------Round number:  333  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18534512173703277\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.1554915020723298\n",
      "-------------Round number:  334  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9475442397977609\n",
      "Average Global Trainning Loss:  0.18631877465211943\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.958107620079451\n",
      "Average Personal Trainning Loss:  0.15681401862698627\n",
      "-------------Round number:  335  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18782166342909218\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15729605088211562\n",
      "-------------Round number:  336  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.19146854156791712\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15910560329625992\n",
      "-------------Round number:  337  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19326183777847372\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15747853916618704\n",
      "-------------Round number:  338  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.18870644175046272\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.1548685974143136\n",
      "-------------Round number:  339  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.18659344387639942\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.1541723690122506\n",
      "-------------Round number:  340  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.18081523968278823\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.15246224945828818\n",
      "-------------Round number:  341  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.1785908289530855\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1512939849886579\n",
      "-------------Round number:  342  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17931045526715986\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.15052197512498872\n",
      "-------------Round number:  343  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.1826259493182049\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.15091060309170728\n",
      "-------------Round number:  344  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.18195985275384277\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15301370396860328\n",
      "-------------Round number:  345  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.1838789113638159\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.1536404329673957\n",
      "-------------Round number:  346  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18103507866106897\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.15045341251989097\n",
      "-------------Round number:  347  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.1782959799940468\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14954704375592498\n",
      "-------------Round number:  348  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17935830912206008\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.15110655922715782\n",
      "-------------Round number:  349  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.1793700686944181\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.15055094974141725\n",
      "-------------Round number:  350  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.17816108105715625\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.15077805166082633\n",
      "-------------Round number:  351  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.17775318811154184\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.15003123615742936\n",
      "-------------Round number:  352  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17804165582185016\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.15047758191275054\n",
      "-------------Round number:  353  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1782124506604934\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.15094940857837327\n",
      "-------------Round number:  354  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17860024101943392\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14822913404404794\n",
      "-------------Round number:  355  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.17932836464399377\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14891596140091753\n",
      "-------------Round number:  356  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.1779069662869041\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14672743555181247\n",
      "-------------Round number:  357  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.1766409221303381\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14767467075842475\n",
      "-------------Round number:  358  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17696051358229506\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.1465936717938843\n",
      "-------------Round number:  359  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17579554443800222\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.1479319926847745\n",
      "-------------Round number:  360  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.17841261687714427\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14785664104821236\n",
      "-------------Round number:  361  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.17885146824708265\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14579366819657932\n",
      "-------------Round number:  362  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.17919614384776206\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14683401012041802\n",
      "-------------Round number:  363  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.1759610821857225\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14637537577730003\n",
      "-------------Round number:  364  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.17921459326118974\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14751074209933077\n",
      "-------------Round number:  365  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17595435928118794\n",
      "Average Personal Accurancy:  0.9357451403887689\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14544813294581188\n",
      "-------------Round number:  366  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.1759413873817827\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14587950095152244\n",
      "-------------Round number:  367  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17662755346935377\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14739233081028236\n",
      "-------------Round number:  368  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.18246157981291192\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.1521536240555311\n",
      "-------------Round number:  369  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.1830742127544917\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.15102224739160122\n",
      "-------------Round number:  370  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.1800386780821145\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1501209814223885\n",
      "-------------Round number:  371  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.1827799699589766\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.1510178940353862\n",
      "-------------Round number:  372  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.18309720288376896\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.15050844114667974\n",
      "-------------Round number:  373  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.18380380219266318\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.15059588299024917\n",
      "-------------Round number:  374  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18217754260690344\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15120903392611276\n",
      "-------------Round number:  375  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18220043354578594\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.958107620079451\n",
      "Average Personal Trainning Loss:  0.1511081793369391\n",
      "-------------Round number:  376  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.18411136956454272\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15108608192121478\n",
      "-------------Round number:  377  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.1879633073128273\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15418685080988737\n",
      "-------------Round number:  378  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.18002731527133556\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.1485727295715398\n",
      "-------------Round number:  379  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17749456568890506\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14886275126469958\n",
      "-------------Round number:  380  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.18450041633515032\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.1502684224336403\n",
      "-------------Round number:  381  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.18732540286289048\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.15279682968101074\n",
      "-------------Round number:  382  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.18045958701175402\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15048355537874683\n",
      "-------------Round number:  383  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17999378891790244\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.15021499187432286\n",
      "-------------Round number:  384  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.1776181018150167\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14650095081708198\n",
      "-------------Round number:  385  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.1742063269541125\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14675778781261287\n",
      "-------------Round number:  386  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17864045721393668\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.15183766958471584\n",
      "-------------Round number:  387  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.1757679144024806\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1480717739933189\n",
      "-------------Round number:  388  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.17866414167597733\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14867775015729393\n",
      "-------------Round number:  389  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.1765921094349551\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14887576724872473\n",
      "-------------Round number:  390  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9451968219573853\n",
      "Average Global Trainning Loss:  0.18356425738928764\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15064066194291148\n",
      "-------------Round number:  391  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.1784494385559148\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14873174279551507\n",
      "-------------Round number:  392  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.1759970993201799\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14701776583731152\n",
      "-------------Round number:  393  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.17698553160408767\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14725865522159398\n",
      "-------------Round number:  394  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.1736876934433121\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14710128414970997\n",
      "-------------Round number:  395  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.17490385585246254\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14598489625654568\n",
      "-------------Round number:  396  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17730582840996298\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14851016247474833\n",
      "-------------Round number:  397  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.17965521903707904\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14747254277618838\n",
      "-------------Round number:  398  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.18347127190476595\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1511722232684972\n",
      "-------------Round number:  399  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9470025279884435\n",
      "Average Global Trainning Loss:  0.1854464722781803\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.15328881403908226\n",
      "-------------Round number:  400  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.19230387898807105\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15837831727947815\n",
      "-------------Round number:  401  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.18473927782691743\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.15109158147754717\n",
      "-------------Round number:  402  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.17956871399168248\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14742744421003182\n",
      "-------------Round number:  403  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.18472735293723477\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.1521193592847147\n",
      "-------------Round number:  404  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17540713689438311\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.1475352751903045\n",
      "-------------Round number:  405  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17423015469116784\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14631952056388814\n",
      "-------------Round number:  406  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.17349767771039296\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1457901083635225\n",
      "-------------Round number:  407  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17090270268697522\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.1445999999647323\n",
      "-------------Round number:  408  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17210755739112157\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14555196324682873\n",
      "-------------Round number:  409  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17453920991896893\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14700397837243814\n",
      "-------------Round number:  410  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.175518792215432\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.1482909737446111\n",
      "-------------Round number:  411  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17389341432207026\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14566533786805366\n",
      "-------------Round number:  412  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17658120951268508\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.1480007095860419\n",
      "-------------Round number:  413  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17856799311997787\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15027445100541148\n",
      "-------------Round number:  414  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.17928142554495644\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.1494173798676474\n",
      "-------------Round number:  415  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.17413444698136737\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14556878152932015\n",
      "-------------Round number:  416  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17706563335844394\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1474986408711685\n",
      "-------------Round number:  417  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.18244084902040447\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.15032069577168541\n",
      "-------------Round number:  418  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17910987024661995\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14915652015055075\n",
      "-------------Round number:  419  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.18034518742311642\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.15128438556267493\n",
      "-------------Round number:  420  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.18630632074699802\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15313133275564847\n",
      "-------------Round number:  421  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.18448753260498488\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.15194809053640754\n",
      "-------------Round number:  422  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9445648248465149\n",
      "Average Global Trainning Loss:  0.1905698104643486\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.15688835631729076\n",
      "-------------Round number:  423  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.18518648323232664\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15313048412671543\n",
      "-------------Round number:  424  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18461235820622857\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15153788314824845\n",
      "-------------Round number:  425  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17646123321963028\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1491676956016951\n",
      "-------------Round number:  426  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17389255467198222\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1496268589602519\n",
      "-------------Round number:  427  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.1755066248603399\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14828889074632087\n",
      "-------------Round number:  428  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1716307822269152\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14656646056225173\n",
      "-------------Round number:  429  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.17221515692713976\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14558000106508442\n",
      "-------------Round number:  430  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1701991011322341\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14490126323596628\n",
      "-------------Round number:  431  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.17131122383842318\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1461492547406837\n",
      "-------------Round number:  432  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17363070305093783\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14548725804597215\n",
      "-------------Round number:  433  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.1735971877186597\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14722104001966527\n",
      "-------------Round number:  434  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.17670086619224562\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.150362719435604\n",
      "-------------Round number:  435  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17631932482817578\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.1475073255412886\n",
      "-------------Round number:  436  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17877648030863466\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14734498392851098\n",
      "-------------Round number:  437  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.1816893605472982\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.1495471209040098\n",
      "-------------Round number:  438  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.1853633727696709\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.15115003768353308\n",
      "-------------Round number:  439  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.18417793734059001\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.14910250547001963\n",
      "-------------Round number:  440  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.1832681630397368\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.1504089752230329\n",
      "-------------Round number:  441  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16958285325182262\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1435164991980126\n",
      "-------------Round number:  442  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17167644287197545\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14577120708274083\n",
      "-------------Round number:  443  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17334676503532412\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14574335662411972\n",
      "-------------Round number:  444  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17727504632411858\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.1465450574792908\n",
      "-------------Round number:  445  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.17112622273101752\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14632578057991377\n",
      "-------------Round number:  446  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.1746770404830828\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14611404215053944\n",
      "-------------Round number:  447  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17498210605278305\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1450746811094935\n",
      "-------------Round number:  448  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.1762115930382979\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14594404083505438\n",
      "-------------Round number:  449  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17694586646733365\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14565693974796293\n",
      "-------------Round number:  450  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.1767073796948357\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.14475021830703774\n",
      "-------------Round number:  451  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.1796443742205839\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14820762074953728\n",
      "-------------Round number:  452  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17501710924098277\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14555835551671406\n",
      "-------------Round number:  453  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.1756536470677027\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.1447280437432286\n",
      "-------------Round number:  454  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.17796506981593085\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1478270712894152\n",
      "-------------Round number:  455  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18461193940233953\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15355025787739257\n",
      "-------------Round number:  456  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.17997996838956415\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14818648217429578\n",
      "-------------Round number:  457  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.1751137427278011\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14688475151792163\n",
      "-------------Round number:  458  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.17338475495652197\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14723477237876376\n",
      "-------------Round number:  459  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.17177249223758012\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14673286898121501\n",
      "-------------Round number:  460  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.17849390891623781\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.1510825882150878\n",
      "-------------Round number:  461  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.17754498747291442\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.15137301769098163\n",
      "-------------Round number:  462  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.1779868476181609\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.1516112399557602\n",
      "-------------Round number:  463  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18100345896744652\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15412073490119402\n",
      "-------------Round number:  464  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17567858794141047\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14973346659232237\n",
      "-------------Round number:  465  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1724276778585173\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1480027154362473\n",
      "-------------Round number:  466  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17499579432726164\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14684230905011397\n",
      "-------------Round number:  467  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.1731735675848964\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14711427809142516\n",
      "-------------Round number:  468  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.17226407983407255\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14453419264837825\n",
      "-------------Round number:  469  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17112502142512528\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.1441245363179679\n",
      "-------------Round number:  470  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1713844483920752\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.1454257600012132\n",
      "-------------Round number:  471  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16757147042662626\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.14153136876396602\n",
      "-------------Round number:  472  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16750742649506817\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14081789225436755\n",
      "-------------Round number:  473  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.16888015543178944\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.140861293562658\n",
      "-------------Round number:  474  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16979087755197048\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14260124738313695\n",
      "-------------Round number:  475  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.1717985352267854\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.1427487986059385\n",
      "-------------Round number:  476  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16946780341504153\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.14028600029413257\n",
      "-------------Round number:  477  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16835781881291756\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14169926503885089\n",
      "-------------Round number:  478  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16819258965753656\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.14028235229183594\n",
      "-------------Round number:  479  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.1687455540660832\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1419176822881399\n",
      "-------------Round number:  480  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16602751682621772\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13900382116668358\n",
      "-------------Round number:  481  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.165905325281013\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.1394320591643813\n",
      "-------------Round number:  482  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16820558359925175\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14210337772830894\n",
      "-------------Round number:  483  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16635272906721177\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.1386615922624086\n",
      "-------------Round number:  484  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.16875588088829452\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.14024695234205714\n",
      "-------------Round number:  485  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16719424935530652\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13832749697050492\n",
      "-------------Round number:  486  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16584662660961763\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13932889013266297\n",
      "-------------Round number:  487  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16868415521171903\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.14250766675624663\n",
      "-------------Round number:  488  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.17049916309757585\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14477877411957724\n",
      "-------------Round number:  489  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.17455390111855024\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14746070605574554\n",
      "-------------Round number:  490  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.17191616401383059\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1450216693540651\n",
      "-------------Round number:  491  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.17171901759364278\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.14315415668590872\n",
      "-------------Round number:  492  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.17026208703291462\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14336819853667276\n",
      "-------------Round number:  493  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9281857451403888\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16844606520080016\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1420709645115283\n",
      "-------------Round number:  494  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.17118291555220747\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14517418009660527\n",
      "-------------Round number:  495  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.168328855217644\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.14232079205249526\n",
      "-------------Round number:  496  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.1693579555634085\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14208604145153372\n",
      "-------------Round number:  497  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.17687289540024603\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14707851444353218\n",
      "-------------Round number:  498  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17295427966436439\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1418193295011455\n",
      "-------------Round number:  499  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.1685482864131907\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13943208120669126\n",
      "-------------Round number:  500  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.16578079725095363\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13903353420049544\n",
      "-------------Round number:  501  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16596584244297918\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13974631637733048\n",
      "-------------Round number:  502  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16755141192457226\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14117914367212892\n",
      "-------------Round number:  503  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.1705346181531295\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.1416755034287254\n",
      "-------------Round number:  504  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17308078048116424\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14284344828486142\n",
      "-------------Round number:  505  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.168675878324333\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14129263952605858\n",
      "-------------Round number:  506  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16568946493967812\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13912307006351007\n",
      "-------------Round number:  507  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1676710686041328\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13988833498033473\n",
      "-------------Round number:  508  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.1665524323953537\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13845303894682195\n",
      "-------------Round number:  509  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1692585116820716\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.14074119603689847\n",
      "-------------Round number:  510  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.17059169671474358\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.1406573030052309\n",
      "-------------Round number:  511  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16698607075898902\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13928403403191586\n",
      "-------------Round number:  512  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17017546075481332\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14053424078878318\n",
      "-------------Round number:  513  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.1718011913251343\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.1395948967291328\n",
      "-------------Round number:  514  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.17215579698644592\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14148578526699057\n",
      "-------------Round number:  515  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.172863333093513\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1398127078148982\n",
      "-------------Round number:  516  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.176306154547981\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14354481254514265\n",
      "-------------Round number:  517  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.1743732092827397\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.140144135987298\n",
      "-------------Round number:  518  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16595760964021308\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13836048328734427\n",
      "-------------Round number:  519  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16370747553479933\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.1373283631451167\n",
      "-------------Round number:  520  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16334222343778215\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13594159325695762\n",
      "-------------Round number:  521  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16480177703339427\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13746304165890777\n",
      "-------------Round number:  522  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1667826643227756\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13673033323387843\n",
      "-------------Round number:  523  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.1659417281558945\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13756660745220523\n",
      "-------------Round number:  524  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16339681121837193\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13631707298579135\n",
      "-------------Round number:  525  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16365157623676757\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13610408916590488\n",
      "-------------Round number:  526  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16127900812073967\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13670930487018668\n",
      "-------------Round number:  527  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.16113593148685784\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.1356403850914985\n",
      "-------------Round number:  528  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16349926387501693\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13658984657141568\n",
      "-------------Round number:  529  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16600382134302208\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13877433867779998\n",
      "-------------Round number:  530  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16325344803446076\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13640002921928607\n",
      "-------------Round number:  531  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.1622565955881523\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13520416777759908\n",
      "-------------Round number:  532  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.1656872496875282\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13973694839560197\n",
      "-------------Round number:  533  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16901692796502574\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14343709177641972\n",
      "-------------Round number:  534  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.17413650793734764\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14504475867373715\n",
      "-------------Round number:  535  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16696051270060266\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.1411362493369673\n",
      "-------------Round number:  536  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.16358356468941856\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13906157201875113\n",
      "-------------Round number:  537  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16308751352516138\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13778964256542864\n",
      "-------------Round number:  538  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.16593772747663868\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.14218620170794397\n",
      "-------------Round number:  539  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.1659974400942917\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.14086769685369832\n",
      "-------------Round number:  540  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.17110973508317534\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1422063263369278\n",
      "-------------Round number:  541  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.168872076925193\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14144466533777988\n",
      "-------------Round number:  542  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16769041073111343\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14084160977987314\n",
      "-------------Round number:  543  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.17051468088378025\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14245020245420842\n",
      "-------------Round number:  544  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.16826990305968423\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14146228816458445\n",
      "-------------Round number:  545  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.17033641370206415\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14216429165185424\n",
      "-------------Round number:  546  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.1697512785421463\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14249793507640393\n",
      "-------------Round number:  547  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16561751884000317\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.1382499080394829\n",
      "-------------Round number:  548  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16513141977868814\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14010360017930096\n",
      "-------------Round number:  549  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16310828840228872\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.1374027338988861\n",
      "-------------Round number:  550  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16196785234896963\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13618188749887145\n",
      "-------------Round number:  551  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16321608631909648\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13899297635018848\n",
      "-------------Round number:  552  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1618772253916125\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.1364755241308629\n",
      "-------------Round number:  553  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16104469836597712\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13726600545026973\n",
      "-------------Round number:  554  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16284514730611233\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13805858078912175\n",
      "-------------Round number:  555  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16429796697603488\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13794067647320218\n",
      "-------------Round number:  556  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15955106735918315\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13478689582910122\n",
      "-------------Round number:  557  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.16087208503676304\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.1382792463540256\n",
      "-------------Round number:  558  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.1612198355396804\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13542297076731222\n",
      "-------------Round number:  559  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15982923028959012\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.1361606717755451\n",
      "-------------Round number:  560  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15950121867523248\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13702613001224495\n",
      "-------------Round number:  561  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.1595596748812184\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13548092000016929\n",
      "-------------Round number:  562  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15960567718208288\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13481059131229686\n",
      "-------------Round number:  563  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.1601696737667592\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13606429177529117\n",
      "-------------Round number:  564  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16431599758557353\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13910820252544917\n",
      "-------------Round number:  565  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16441933193461652\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13866200004514265\n",
      "-------------Round number:  566  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1635992808564125\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13966024115697792\n",
      "-------------Round number:  567  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.1645181365889649\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13957695428883396\n",
      "-------------Round number:  568  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.16654112469034962\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.14032842071963028\n",
      "-------------Round number:  569  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16540472237975126\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.1399802514128239\n",
      "-------------Round number:  570  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16613144631762933\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13871208017334777\n",
      "-------------Round number:  571  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.16208467659170164\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13731067419138226\n",
      "-------------Round number:  572  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15989487228861954\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13686208012044623\n",
      "-------------Round number:  573  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.1595807363083751\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13544552005039048\n",
      "-------------Round number:  574  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15895356646338366\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13415137194863894\n",
      "-------------Round number:  575  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.16061242662555864\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13590426460505822\n",
      "-------------Round number:  576  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15951331990339473\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13322281759970883\n",
      "-------------Round number:  577  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16130700185437546\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13424963656639355\n",
      "-------------Round number:  578  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1626991831296271\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13547161814537062\n",
      "-------------Round number:  579  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.16050318493744922\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13342269726633035\n",
      "-------------Round number:  580  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16491501940075953\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13801026404571257\n",
      "-------------Round number:  581  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16362650310920007\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13710949402847372\n",
      "-------------Round number:  582  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.16174798030722395\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13570277584981041\n",
      "-------------Round number:  583  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.1623787210064272\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13569763999159218\n",
      "-------------Round number:  584  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.16950062441455624\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14206039522390754\n",
      "-------------Round number:  585  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16914697759372743\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.1431249616463807\n",
      "-------------Round number:  586  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17119223944931608\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14167693617887211\n",
      "-------------Round number:  587  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1704126029464044\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14157721676866084\n",
      "-------------Round number:  588  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.1598411331369628\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13606512938306925\n",
      "-------------Round number:  589  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15988512958762188\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13598216212841954\n",
      "-------------Round number:  590  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15916470975038935\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.1357444578579248\n",
      "-------------Round number:  591  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15932549738031554\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13299214482608793\n",
      "-------------Round number:  592  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15684189112791735\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13479318890859177\n",
      "-------------Round number:  593  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.15702458881393327\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1338752148684374\n",
      "-------------Round number:  594  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.15770108934859156\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13430235075063765\n",
      "-------------Round number:  595  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.16184607960765393\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13640832814898204\n",
      "-------------Round number:  596  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.16114102326045618\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13776270686267042\n",
      "-------------Round number:  597  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.16270430796669036\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13976144842311078\n",
      "-------------Round number:  598  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.16042578336606175\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.1371631670532006\n",
      "-------------Round number:  599  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16644371972268304\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.1421835235672851\n",
      "-------------Round number:  600  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16650000476113894\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.14327756055816065\n",
      "-------------Round number:  601  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16955386761423913\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.14147976771637436\n",
      "-------------Round number:  602  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.1634071159982733\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1383137756325614\n",
      "-------------Round number:  603  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.16123865967237722\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13850767081203164\n",
      "-------------Round number:  604  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.16066862349477473\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13682010054114752\n",
      "-------------Round number:  605  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.1587621620649377\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13630683433281984\n",
      "-------------Round number:  606  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1594236077019005\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13515788994786024\n",
      "-------------Round number:  607  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15877699653953367\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.135348511844303\n",
      "-------------Round number:  608  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15935310537352723\n",
      "Average Personal Accurancy:  0.9360151187904968\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13533776621820265\n",
      "-------------Round number:  609  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15862166438131997\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13417243337579565\n",
      "-------------Round number:  610  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16294728034926304\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13582247661399083\n",
      "-------------Round number:  611  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16523046689844598\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13584941231674905\n",
      "-------------Round number:  612  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16562283103670097\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13756705931955918\n",
      "-------------Round number:  613  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1616802112252844\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13349030103094528\n",
      "-------------Round number:  614  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16067468513001085\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.1341855816136805\n",
      "-------------Round number:  615  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16203931351782572\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13453291331270878\n",
      "-------------Round number:  616  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.16207639970431564\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.1342972259135744\n",
      "-------------Round number:  617  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.1661352596372506\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13853832064401633\n",
      "-------------Round number:  618  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.16116247042803697\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13491366115362044\n",
      "-------------Round number:  619  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.16008729063332316\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13470238561275505\n",
      "-------------Round number:  620  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16239195741355184\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13574781931019209\n",
      "-------------Round number:  621  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16059504626416352\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13611215665134638\n",
      "-------------Round number:  622  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.15966337292837554\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.1346792081238432\n",
      "-------------Round number:  623  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15833595195975533\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13318846465965262\n",
      "-------------Round number:  624  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1575900732545312\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13321564282782028\n",
      "-------------Round number:  625  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16008596809472622\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1350501802002923\n",
      "-------------Round number:  626  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16114581746287018\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13616382382586786\n",
      "-------------Round number:  627  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15881830382837892\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13435832719675425\n",
      "-------------Round number:  628  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16196336673889491\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13674484809498014\n",
      "-------------Round number:  629  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15917651340736727\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1344472017904704\n",
      "-------------Round number:  630  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.15915891262287266\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.1333623784851537\n",
      "-------------Round number:  631  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1568858214516466\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13399432049024917\n",
      "-------------Round number:  632  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15613083927241334\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13159631554853962\n",
      "-------------Round number:  633  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16119038701358793\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13385448407592992\n",
      "-------------Round number:  634  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.15950743460663822\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1327896531457374\n",
      "-------------Round number:  635  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15672177155984787\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1319656344517425\n",
      "-------------Round number:  636  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15595419220047851\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.131206838952888\n",
      "-------------Round number:  637  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1572700740198402\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13237675659576448\n",
      "-------------Round number:  638  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.1559038034799341\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13070477023801463\n",
      "-------------Round number:  639  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15542527595208672\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13083016893931698\n",
      "-------------Round number:  640  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15597376577171362\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13483396718199825\n",
      "-------------Round number:  641  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15535935842418291\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13341361583463118\n",
      "-------------Round number:  642  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15579229143389986\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1318512789477248\n",
      "-------------Round number:  643  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15693441372393013\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13242648404701043\n",
      "-------------Round number:  644  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15626040397029614\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13287493484293178\n",
      "-------------Round number:  645  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.1558029599119154\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13205806887851548\n",
      "-------------Round number:  646  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15507944313013497\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13151987281763497\n",
      "-------------Round number:  647  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.1555134782553494\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13161284728100173\n",
      "-------------Round number:  648  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15734965777991264\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13343909674493273\n",
      "-------------Round number:  649  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15708520516629423\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13269661255544082\n",
      "-------------Round number:  650  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15546581176008373\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12968503787397864\n",
      "-------------Round number:  651  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15590378143762415\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.1303224794354065\n",
      "-------------Round number:  652  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15534438067457226\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13113510225515754\n",
      "-------------Round number:  653  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15592282599342047\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13137623410484944\n",
      "-------------Round number:  654  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15583114100518577\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1295676625734979\n",
      "-------------Round number:  655  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15531927448353985\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12936421205266455\n",
      "-------------Round number:  656  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.1555146575189317\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.13008634016891815\n",
      "-------------Round number:  657  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15553542137490406\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.128547015453599\n",
      "-------------Round number:  658  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15495389013266297\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12978378742255214\n",
      "-------------Round number:  659  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15480623971946664\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13007776571034782\n",
      "-------------Round number:  660  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15563490934086088\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.12920697323464023\n",
      "-------------Round number:  661  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1565151579675368\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1296319159070005\n",
      "-------------Round number:  662  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.15669318268384344\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12924418065383486\n",
      "-------------Round number:  663  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15568030547820175\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12887317551392086\n",
      "-------------Round number:  664  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15476862451753792\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.128685220736982\n",
      "-------------Round number:  665  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15346472269363376\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12699932568165404\n",
      "-------------Round number:  666  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15360602492156464\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.12815306426902762\n",
      "-------------Round number:  667  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15300152559235622\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.12756161398730928\n",
      "-------------Round number:  668  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.1532264563442353\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12937118844376355\n",
      "-------------Round number:  669  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15473866901831662\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.128216997989036\n",
      "-------------Round number:  670  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15574059119591346\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.12870843128935874\n",
      "-------------Round number:  671  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1545664304083717\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.12960434097725373\n",
      "-------------Round number:  672  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15529072969215535\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.1287992676486604\n",
      "-------------Round number:  673  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15403410862309272\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.1269523865826167\n",
      "-------------Round number:  674  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1540961136409805\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12748262536960545\n",
      "-------------Round number:  675  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1528732283272955\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.1275839208049781\n",
      "-------------Round number:  676  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15316990679806\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12703064780409218\n",
      "-------------Round number:  677  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15299897970555706\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12845977199081912\n",
      "-------------Round number:  678  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15334163843487608\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12798192777458017\n",
      "-------------Round number:  679  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15246190780248398\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.12780259154083154\n",
      "-------------Round number:  680  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.1533283799854415\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.127988981313764\n",
      "-------------Round number:  681  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15322272017269886\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.1278381678290899\n",
      "-------------Round number:  682  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15297900937274286\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.1275340500787175\n",
      "-------------Round number:  683  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.1552379052963615\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.129043573590985\n",
      "-------------Round number:  684  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.1540554896637437\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12705942403973117\n",
      "-------------Round number:  685  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15324539068848186\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12706000816094484\n",
      "-------------Round number:  686  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.158544053407988\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13094261778352406\n",
      "-------------Round number:  687  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.1607281487527932\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.12979802675477947\n",
      "-------------Round number:  688  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15710934149568886\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12987232036046406\n",
      "-------------Round number:  689  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15487504478997383\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.1285205977451246\n",
      "-------------Round number:  690  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15401821611761918\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12776828268539522\n",
      "-------------Round number:  691  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15752386917659805\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13032630377618273\n",
      "-------------Round number:  692  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15825817566909872\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13153950149464494\n",
      "-------------Round number:  693  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.1556273047439283\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12961748921513858\n",
      "-------------Round number:  694  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15468071978545955\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12917475839864911\n",
      "-------------Round number:  695  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15721010791562273\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13549837750964924\n",
      "-------------Round number:  696  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1625645597216109\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.1380215937930266\n",
      "-------------Round number:  697  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15877496864701832\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13554867806095386\n",
      "-------------Round number:  698  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15645968849454903\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13326362893658023\n",
      "-------------Round number:  699  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.156105700017916\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13370111368330173\n",
      "-------------Round number:  700  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.15482179056913598\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.1329542320529749\n",
      "-------------Round number:  701  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.15441541854290808\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.13101377036004086\n",
      "-------------Round number:  702  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15580748960661\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.1309765629408462\n",
      "-------------Round number:  703  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15480642707910122\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.13109673761469054\n",
      "-------------Round number:  704  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15576315150014672\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13105945304741107\n",
      "-------------Round number:  705  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.158739789120339\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13121754049436846\n",
      "-------------Round number:  706  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16150598880744402\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13185811206380912\n",
      "-------------Round number:  707  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.16760090793156374\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1365893065348219\n",
      "-------------Round number:  708  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16038297720013994\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13131048189427028\n",
      "-------------Round number:  709  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1603131581833751\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13161728880645654\n",
      "-------------Round number:  710  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15781687760275595\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13011433390255395\n",
      "-------------Round number:  711  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.1596837069593039\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13013051295805683\n",
      "-------------Round number:  712  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1592056312988105\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13083987857684973\n",
      "-------------Round number:  713  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15927508661746118\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.129421995968197\n",
      "-------------Round number:  714  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.1597776623054634\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1316151727447014\n",
      "-------------Round number:  715  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16232919193597078\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13236551501769028\n",
      "-------------Round number:  716  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15300461151574915\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12795122283682062\n",
      "-------------Round number:  717  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15596965488090805\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13080437943667614\n",
      "-------------Round number:  718  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15335847875967745\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9665041531238714\n",
      "Average Personal Trainning Loss:  0.128759767829231\n",
      "-------------Round number:  719  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15322704046544894\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.1292902931662491\n",
      "-------------Round number:  720  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15408770449973477\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.12954584068664793\n",
      "-------------Round number:  721  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15645741813662423\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.1300657857148903\n",
      "-------------Round number:  722  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1592229785967407\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13205614017639491\n",
      "-------------Round number:  723  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.1555464425298788\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13077364143545164\n",
      "-------------Round number:  724  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15285192443472936\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.12749029609346785\n",
      "-------------Round number:  725  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.15381890955105634\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.1293569931961561\n",
      "-------------Round number:  726  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.15330277784243523\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.1283786011844303\n",
      "-------------Round number:  727  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15642288885808844\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13242350833516725\n",
      "-------------Round number:  728  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15560471137623014\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13123421550184522\n",
      "-------------Round number:  729  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.1575339535333999\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13185514737312093\n",
      "-------------Round number:  730  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15315693489865476\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13029181858226685\n",
      "-------------Round number:  731  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15147336530702646\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12954531167120914\n",
      "-------------Round number:  732  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15090594114315298\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.1283034038440378\n",
      "-------------Round number:  733  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15145709808228378\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12844207201592972\n",
      "-------------Round number:  734  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15353098187734177\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.1301598292302896\n",
      "-------------Round number:  735  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15015300889874503\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.12725894000823854\n",
      "-------------Round number:  736  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9574756229685807\n",
      "Average Global Trainning Loss:  0.14913489664449034\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.1268922661822296\n",
      "-------------Round number:  737  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15025994716546473\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12862359043836336\n",
      "-------------Round number:  738  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15239083237405202\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13050184873262008\n",
      "-------------Round number:  739  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15257717806236457\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.12877018282068212\n",
      "-------------Round number:  740  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15104071884733883\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12855679121806157\n",
      "-------------Round number:  741  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15062908973018801\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.1284181010038597\n",
      "-------------Round number:  742  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15046545864227834\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12858593115181474\n",
      "-------------Round number:  743  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15034425900102136\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.12780877440877234\n",
      "-------------Round number:  744  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15016032694564824\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9663235825207657\n",
      "Average Personal Trainning Loss:  0.1280364604493951\n",
      "-------------Round number:  745  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.14937872867715105\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9661430119176598\n",
      "Average Personal Trainning Loss:  0.12874177028315728\n",
      "-------------Round number:  746  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15094293916040313\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.1279399812587464\n",
      "-------------Round number:  747  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1486621552230047\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.1257934239677851\n",
      "-------------Round number:  748  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.14906393142760813\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.12650301000967745\n",
      "-------------Round number:  749  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.15008691503236163\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.1272104799898147\n",
      "-------------Round number:  750  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9284557235421166\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.1530933428344506\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.13031785055031714\n",
      "-------------Round number:  751  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.15328557381951968\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.1315310262264694\n",
      "-------------Round number:  752  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.1591736258647639\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13390746276789342\n",
      "-------------Round number:  753  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15616634943374189\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13066032192000157\n",
      "-------------Round number:  754  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1567453017257189\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13132043399721244\n",
      "-------------Round number:  755  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15416026778408834\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13055779211527177\n",
      "-------------Round number:  756  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15212762515094574\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12753781931371885\n",
      "-------------Round number:  757  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1512409291486096\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12819390866936395\n",
      "-------------Round number:  758  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.15006641568410867\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12824903648654748\n",
      "-------------Round number:  759  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.14939337579211245\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.1275159974268689\n",
      "-------------Round number:  760  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15006703286878725\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.12847711928874933\n",
      "-------------Round number:  761  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.1520634710078379\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.12936252581595342\n",
      "-------------Round number:  762  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.15081906137848727\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.1294633252993522\n",
      "-------------Round number:  763  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1523786650189599\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13008905137304194\n",
      "-------------Round number:  764  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15606847055641138\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.133506998080732\n",
      "-------------Round number:  765  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15341000265918428\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13017167697188742\n",
      "-------------Round number:  766  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.1512893671247235\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12978291675130912\n",
      "-------------Round number:  767  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.15068312645302906\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.12884458663791645\n",
      "-------------Round number:  768  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.15052766204095566\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.12767244272173506\n",
      "-------------Round number:  769  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15103865789135856\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1286489501159602\n",
      "-------------Round number:  770  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15373005699965014\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12871593669589654\n",
      "-------------Round number:  771  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15091588222494018\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.12772207098258623\n",
      "-------------Round number:  772  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15047082594475103\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12649428125493747\n",
      "-------------Round number:  773  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15021442979541916\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.1266240994393847\n",
      "-------------Round number:  774  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1531015866583717\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12764283989947295\n",
      "-------------Round number:  775  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15512661367342678\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.12778781217201043\n",
      "-------------Round number:  776  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1564885528994278\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.12918027999729145\n",
      "-------------Round number:  777  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.1536840767410956\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12637462457537693\n",
      "-------------Round number:  778  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1529720991085737\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.12745447733980003\n",
      "-------------Round number:  779  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.15821162231048552\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.12897030495271308\n",
      "-------------Round number:  780  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15740222868914205\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.1271291218237913\n",
      "-------------Round number:  781  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15589962646219868\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.12724323486239955\n",
      "-------------Round number:  782  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1535921272451415\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12564456122754153\n",
      "-------------Round number:  783  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16005840418613443\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.1288102998247901\n",
      "-------------Round number:  784  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16051345665388567\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.12775227996837193\n",
      "-------------Round number:  785  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.15922352965448944\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.1283729363107733\n",
      "-------------Round number:  786  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16058163351855928\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.1305894228300492\n",
      "-------------Round number:  787  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15439053277497516\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9664138678223185\n",
      "Average Personal Trainning Loss:  0.12694711847053877\n",
      "-------------Round number:  788  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.152933172389203\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12756056697758666\n",
      "-------------Round number:  789  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.1536805058868838\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9663235825207657\n",
      "Average Personal Trainning Loss:  0.1274773241940626\n",
      "-------------Round number:  790  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15388595123676757\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12908868317829655\n",
      "-------------Round number:  791  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15630703447699418\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.1306247346105882\n",
      "-------------Round number:  792  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.15174212719223998\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12735472486612381\n",
      "-------------Round number:  793  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9582881906825569\n",
      "Average Global Trainning Loss:  0.15013167194271398\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9668652943300831\n",
      "Average Personal Trainning Loss:  0.1272226363237518\n",
      "-------------Round number:  794  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.14926763543500587\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9663235825207657\n",
      "Average Personal Trainning Loss:  0.1263583463294793\n",
      "-------------Round number:  795  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9575659082701337\n",
      "Average Global Trainning Loss:  0.15056887013940615\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9668652943300831\n",
      "Average Personal Trainning Loss:  0.1262493030221594\n",
      "-------------Round number:  796  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9582881906825569\n",
      "Average Global Trainning Loss:  0.1481340214766161\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9668652943300831\n",
      "Average Personal Trainning Loss:  0.12480932299778237\n",
      "-------------Round number:  797  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.14886948519038912\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.1277203406612552\n",
      "-------------Round number:  798  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.1503898865826167\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9661430119176598\n",
      "Average Personal Trainning Loss:  0.12520401259973704\n",
      "-------------Round number:  799  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9583784759841097\n",
      "Average Global Trainning Loss:  0.14926436215197839\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9661430119176598\n",
      "Average Personal Trainning Loss:  0.12608288358204112\n",
      "---------------Running time:------------ 2\n",
      "Number of users / total users: 5  /  20\n",
      "Finished creating pFedMe server.\n",
      "-------------Round number:  0  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.08720302375809935\n",
      "Average Global Trainning Accurancy:  0.0879378837125316\n",
      "Average Global Trainning Loss:  2.507899258531961\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9394185626579993\n",
      "Average Personal Trainning Loss:  0.6520153636663732\n",
      "-------------Round number:  1  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.6792656587473002\n",
      "Average Global Trainning Accurancy:  0.6835500180570603\n",
      "Average Global Trainning Loss:  1.3083973971029703\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9395088479595521\n",
      "Average Personal Trainning Loss:  0.4905052749892786\n",
      "-------------Round number:  2  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7135529157667386\n",
      "Average Global Trainning Accurancy:  0.7154207295052365\n",
      "Average Global Trainning Loss:  1.0970230185197725\n",
      "Average Personal Accurancy:  0.9227861771058316\n",
      "Average Personal Trainning Accurancy:  0.9360780065005417\n",
      "Average Personal Trainning Loss:  0.4312856997251941\n",
      "-------------Round number:  3  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7956263498920086\n",
      "Average Global Trainning Accurancy:  0.7963163596966414\n",
      "Average Global Trainning Loss:  0.814974557884164\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9365294330083063\n",
      "Average Personal Trainning Loss:  0.37763299800808053\n",
      "-------------Round number:  4  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7551295896328294\n",
      "Average Global Trainning Accurancy:  0.7552365474900686\n",
      "Average Global Trainning Loss:  0.8366974306778169\n",
      "Average Personal Accurancy:  0.9130669546436285\n",
      "Average Personal Trainning Accurancy:  0.9233477789815818\n",
      "Average Personal Trainning Loss:  0.3832693489160121\n",
      "-------------Round number:  5  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7640388768898488\n",
      "Average Global Trainning Accurancy:  0.7663416395810762\n",
      "Average Global Trainning Loss:  0.7622692787332972\n",
      "Average Personal Accurancy:  0.9036177105831533\n",
      "Average Personal Trainning Accurancy:  0.9171180931744312\n",
      "Average Personal Trainning Loss:  0.3685143148050966\n",
      "-------------Round number:  6  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7378509719222462\n",
      "Average Global Trainning Accurancy:  0.7424160346695557\n",
      "Average Global Trainning Loss:  0.8248721722361412\n",
      "Average Personal Accurancy:  0.8968682505399568\n",
      "Average Personal Trainning Accurancy:  0.9096244131455399\n",
      "Average Personal Trainning Loss:  0.3972268481683369\n",
      "-------------Round number:  7  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8345032397408207\n",
      "Average Global Trainning Accurancy:  0.8440772842181293\n",
      "Average Global Trainning Loss:  0.6050968962311529\n",
      "Average Personal Accurancy:  0.9208963282937365\n",
      "Average Personal Trainning Accurancy:  0.928042614662333\n",
      "Average Personal Trainning Loss:  0.34511695385151453\n",
      "-------------Round number:  8  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8480021598272138\n",
      "Average Global Trainning Accurancy:  0.8529252437703142\n",
      "Average Global Trainning Loss:  0.5425970284850127\n",
      "Average Personal Accurancy:  0.9195464362850972\n",
      "Average Personal Trainning Accurancy:  0.9296677500902853\n",
      "Average Personal Trainning Loss:  0.32147428403050515\n",
      "-------------Round number:  9  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8312634989200864\n",
      "Average Global Trainning Accurancy:  0.8386601661249549\n",
      "Average Global Trainning Loss:  0.5287787043777086\n",
      "Average Personal Accurancy:  0.9146868250539957\n",
      "Average Personal Trainning Accurancy:  0.9275009028530156\n",
      "Average Personal Trainning Loss:  0.32094200632984604\n",
      "-------------Round number:  10  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8407127429805615\n",
      "Average Global Trainning Accurancy:  0.8477789815817984\n",
      "Average Global Trainning Loss:  0.5383565288969393\n",
      "Average Personal Accurancy:  0.916036717062635\n",
      "Average Personal Trainning Accurancy:  0.9238894907908992\n",
      "Average Personal Trainning Loss:  0.3284867363485803\n",
      "-------------Round number:  11  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8566414686825053\n",
      "Average Global Trainning Accurancy:  0.8648429035752979\n",
      "Average Global Trainning Loss:  0.4796649110407638\n",
      "Average Personal Accurancy:  0.9141468682505399\n",
      "Average Personal Trainning Accurancy:  0.9278620440592271\n",
      "Average Personal Trainning Loss:  0.3148457867094393\n",
      "-------------Round number:  12  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8588012958963283\n",
      "Average Global Trainning Accurancy:  0.8633983387504515\n",
      "Average Global Trainning Loss:  0.4806618406351571\n",
      "Average Personal Accurancy:  0.916036717062635\n",
      "Average Personal Trainning Accurancy:  0.9264174792343807\n",
      "Average Personal Trainning Loss:  0.31304283596712484\n",
      "-------------Round number:  13  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8663606911447084\n",
      "Average Global Trainning Accurancy:  0.8727880101119537\n",
      "Average Global Trainning Loss:  0.4605307752968129\n",
      "Average Personal Accurancy:  0.9198164146868251\n",
      "Average Personal Trainning Accurancy:  0.9312026002166848\n",
      "Average Personal Trainning Loss:  0.29926167519439556\n",
      "-------------Round number:  14  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8922786177105831\n",
      "Average Global Trainning Accurancy:  0.8963524738172626\n",
      "Average Global Trainning Loss:  0.40719310227349675\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9374322860238353\n",
      "Average Personal Trainning Loss:  0.277939267087904\n",
      "-------------Round number:  15  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8855291576673866\n",
      "Average Global Trainning Accurancy:  0.8924702058504875\n",
      "Average Global Trainning Loss:  0.4096921271217046\n",
      "Average Personal Accurancy:  0.9252159827213823\n",
      "Average Personal Trainning Accurancy:  0.9340917298663778\n",
      "Average Personal Trainning Loss:  0.2793892543209981\n",
      "-------------Round number:  16  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8849892008639308\n",
      "Average Global Trainning Accurancy:  0.8894005055976887\n",
      "Average Global Trainning Loss:  0.40148745034308414\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.933820873961719\n",
      "Average Personal Trainning Loss:  0.26890928214015664\n",
      "-------------Round number:  17  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8725701943844493\n",
      "Average Global Trainning Accurancy:  0.8801011195377393\n",
      "Average Global Trainning Loss:  0.4294231686190863\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9327374503430842\n",
      "Average Personal Trainning Loss:  0.27830173083271265\n",
      "-------------Round number:  18  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8844492440604752\n",
      "Average Global Trainning Accurancy:  0.8916576381365113\n",
      "Average Global Trainning Loss:  0.41821139174792343\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9345431563741423\n",
      "Average Personal Trainning Loss:  0.27949649015890216\n",
      "-------------Round number:  19  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8771598272138229\n",
      "Average Global Trainning Accurancy:  0.8894907908992417\n",
      "Average Global Trainning Loss:  0.3904410789657819\n",
      "Average Personal Accurancy:  0.9133369330453563\n",
      "Average Personal Trainning Accurancy:  0.9271397616468039\n",
      "Average Personal Trainning Loss:  0.2820072194736931\n",
      "-------------Round number:  20  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8752699784017278\n",
      "Average Global Trainning Accurancy:  0.8879559407728422\n",
      "Average Global Trainning Loss:  0.3848614208790403\n",
      "Average Personal Accurancy:  0.9149568034557235\n",
      "Average Personal Trainning Accurancy:  0.9291260382809678\n",
      "Average Personal Trainning Loss:  0.27352798368234243\n",
      "-------------Round number:  21  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8947084233261339\n",
      "Average Global Trainning Accurancy:  0.9061935716865295\n",
      "Average Global Trainning Loss:  0.3458912781577284\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.9376128566269412\n",
      "Average Personal Trainning Loss:  0.25250460155262505\n",
      "-------------Round number:  22  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8952483801295896\n",
      "Average Global Trainning Accurancy:  0.9020404478150957\n",
      "Average Global Trainning Loss:  0.3579698468253431\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.9354460093896714\n",
      "Average Personal Trainning Loss:  0.2624464768629808\n",
      "-------------Round number:  23  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9014578833693304\n",
      "Average Global Trainning Accurancy:  0.9118815456843626\n",
      "Average Global Trainning Loss:  0.3381130980343197\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9392379920548934\n",
      "Average Personal Trainning Loss:  0.24886444631833468\n",
      "-------------Round number:  24  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.91242325749368\n",
      "Average Global Trainning Loss:  0.33130616821421316\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9409534127843987\n",
      "Average Personal Trainning Loss:  0.24252701770015123\n",
      "-------------Round number:  25  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8979481641468683\n",
      "Average Global Trainning Accurancy:  0.9098952690501986\n",
      "Average Global Trainning Loss:  0.32829150760935805\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9413145539906104\n",
      "Average Personal Trainning Loss:  0.23944812580410346\n",
      "-------------Round number:  26  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8976781857451404\n",
      "Average Global Trainning Accurancy:  0.9072769953051644\n",
      "Average Global Trainning Loss:  0.3343155827493003\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9386059949440231\n",
      "Average Personal Trainning Loss:  0.24470109481508442\n",
      "-------------Round number:  27  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8901187904967602\n",
      "Average Global Trainning Accurancy:  0.9034850126399422\n",
      "Average Global Trainning Loss:  0.33673704070879606\n",
      "Average Personal Accurancy:  0.9198164146868251\n",
      "Average Personal Trainning Accurancy:  0.933911159263272\n",
      "Average Personal Trainning Loss:  0.24783806819784895\n",
      "-------------Round number:  28  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8974082073434125\n",
      "Average Global Trainning Accurancy:  0.9090827013362225\n",
      "Average Global Trainning Loss:  0.32842310019975623\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.9365294330083063\n",
      "Average Personal Trainning Loss:  0.2421600793664229\n",
      "-------------Round number:  29  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9017278617710583\n",
      "Average Global Trainning Accurancy:  0.9108884073672806\n",
      "Average Global Trainning Loss:  0.32123040791322455\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9395991332611051\n",
      "Average Personal Trainning Loss:  0.23732684002149917\n",
      "-------------Round number:  30  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.896328293736501\n",
      "Average Global Trainning Accurancy:  0.9079992777175876\n",
      "Average Global Trainning Loss:  0.3193155042786769\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9375225713253882\n",
      "Average Personal Trainning Loss:  0.2355117439664026\n",
      "-------------Round number:  31  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8930885529157667\n",
      "Average Global Trainning Accurancy:  0.90465872156013\n",
      "Average Global Trainning Loss:  0.33271037356954225\n",
      "Average Personal Accurancy:  0.9214362850971922\n",
      "Average Personal Trainning Accurancy:  0.9356265799927772\n",
      "Average Personal Trainning Loss:  0.24635265897266612\n",
      "-------------Round number:  32  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8903887688984882\n",
      "Average Global Trainning Accurancy:  0.8996027446731673\n",
      "Average Global Trainning Loss:  0.3362420365542615\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9351751534850127\n",
      "Average Personal Trainning Loss:  0.24031042096932556\n",
      "-------------Round number:  33  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.884719222462203\n",
      "Average Global Trainning Accurancy:  0.8950884795955218\n",
      "Average Global Trainning Loss:  0.35416968646312974\n",
      "Average Personal Accurancy:  0.9235961123110151\n",
      "Average Personal Trainning Accurancy:  0.9321054532322138\n",
      "Average Personal Trainning Loss:  0.2489092583344619\n",
      "-------------Round number:  34  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8760799136069114\n",
      "Average Global Trainning Accurancy:  0.885247381726255\n",
      "Average Global Trainning Loss:  0.36804803178042617\n",
      "Average Personal Accurancy:  0.9230561555075594\n",
      "Average Personal Trainning Accurancy:  0.9305706031058144\n",
      "Average Personal Trainning Loss:  0.24783284417039095\n",
      "-------------Round number:  35  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8960583153347732\n",
      "Average Global Trainning Accurancy:  0.9080895630191405\n",
      "Average Global Trainning Loss:  0.3216441641132855\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9400505597688696\n",
      "Average Personal Trainning Loss:  0.23363008013525866\n",
      "-------------Round number:  36  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8982181425485961\n",
      "Average Global Trainning Accurancy:  0.9083604189237992\n",
      "Average Global Trainning Loss:  0.31895295236462845\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9429396894185627\n",
      "Average Personal Trainning Loss:  0.22667844255033406\n",
      "-------------Round number:  37  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9014578833693304\n",
      "Average Global Trainning Accurancy:  0.9137775370169736\n",
      "Average Global Trainning Loss:  0.31511494535623197\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9434814012278802\n",
      "Average Personal Trainning Loss:  0.2241192201536543\n",
      "-------------Round number:  38  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9196460816179126\n",
      "Average Global Trainning Loss:  0.290510767932918\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9439328277356447\n",
      "Average Personal Trainning Loss:  0.21829636926124052\n",
      "-------------Round number:  39  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.900377969762419\n",
      "Average Global Trainning Accurancy:  0.915402672444926\n",
      "Average Global Trainning Loss:  0.2993871620649377\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9423979776092453\n",
      "Average Personal Trainning Loss:  0.21738864489521262\n",
      "-------------Round number:  40  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.902267818574514\n",
      "Average Global Trainning Accurancy:  0.9163055254604551\n",
      "Average Global Trainning Loss:  0.2965705075303584\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.945557963163597\n",
      "Average Personal Trainning Loss:  0.21565369467909218\n",
      "-------------Round number:  41  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8947084233261339\n",
      "Average Global Trainning Accurancy:  0.906554712892741\n",
      "Average Global Trainning Loss:  0.3125253706987518\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9433008306247743\n",
      "Average Personal Trainning Loss:  0.22110123115999683\n",
      "-------------Round number:  42  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8995680345572354\n",
      "Average Global Trainning Accurancy:  0.9117912603828097\n",
      "Average Global Trainning Loss:  0.2916515897266613\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9433008306247743\n",
      "Average Personal Trainning Loss:  0.21620838940896983\n",
      "-------------Round number:  43  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8998380129589633\n",
      "Average Global Trainning Accurancy:  0.9096244131455399\n",
      "Average Global Trainning Loss:  0.3000238982724472\n",
      "Average Personal Accurancy:  0.9249460043196545\n",
      "Average Personal Trainning Accurancy:  0.9394185626579993\n",
      "Average Personal Trainning Loss:  0.22515769950230227\n",
      "-------------Round number:  44  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8984881209503239\n",
      "Average Global Trainning Accurancy:  0.9098952690501986\n",
      "Average Global Trainning Loss:  0.3009654134996276\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9404117009750813\n",
      "Average Personal Trainning Loss:  0.22199085878955624\n",
      "-------------Round number:  45  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.896328293736501\n",
      "Average Global Trainning Accurancy:  0.9096244131455399\n",
      "Average Global Trainning Loss:  0.29471498587881456\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9402311303719755\n",
      "Average Personal Trainning Loss:  0.22066417623831933\n",
      "-------------Round number:  46  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9095572354211663\n",
      "Average Global Trainning Accurancy:  0.9224449259660528\n",
      "Average Global Trainning Loss:  0.276806645033462\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9437522571325389\n",
      "Average Personal Trainning Loss:  0.21507911778564012\n",
      "-------------Round number:  47  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.908207343412527\n",
      "Average Global Trainning Accurancy:  0.9246117732033226\n",
      "Average Global Trainning Loss:  0.27093351563205353\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9469122426868906\n",
      "Average Personal Trainning Loss:  0.20823720681964383\n",
      "-------------Round number:  48  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9248826291079812\n",
      "Average Global Trainning Loss:  0.2740021137693549\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9474539544962081\n",
      "Average Personal Trainning Loss:  0.20724312068323403\n",
      "-------------Round number:  49  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9255146262188516\n",
      "Average Global Trainning Loss:  0.2763470187863963\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.945557963163597\n",
      "Average Personal Trainning Loss:  0.21135603938131997\n",
      "-------------Round number:  50  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9258757674250632\n",
      "Average Global Trainning Loss:  0.26866809518468987\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9452871072589383\n",
      "Average Personal Trainning Loss:  0.20961359477981673\n",
      "-------------Round number:  51  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9257854821235103\n",
      "Average Global Trainning Loss:  0.26657929976695105\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9457385337667028\n",
      "Average Personal Trainning Loss:  0.20671181284421272\n",
      "-------------Round number:  52  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9213615023474179\n",
      "Average Global Trainning Loss:  0.27484975079846063\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9471830985915493\n",
      "Average Personal Trainning Loss:  0.205559000033857\n",
      "-------------Round number:  53  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.908207343412527\n",
      "Average Global Trainning Accurancy:  0.9233477789815818\n",
      "Average Global Trainning Loss:  0.26840969318515256\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.2056273973216301\n",
      "-------------Round number:  54  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906317494600432\n",
      "Average Global Trainning Accurancy:  0.9191946551101481\n",
      "Average Global Trainning Loss:  0.28147240690738984\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9440231130371975\n",
      "Average Personal Trainning Loss:  0.2106243889871682\n",
      "-------------Round number:  55  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9017278617710583\n",
      "Average Global Trainning Accurancy:  0.9163055254604551\n",
      "Average Global Trainning Loss:  0.2946996223887798\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.943571686529433\n",
      "Average Personal Trainning Loss:  0.21836452408360418\n",
      "-------------Round number:  56  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.9191946551101481\n",
      "Average Global Trainning Loss:  0.2814885859628927\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.942578548212351\n",
      "Average Personal Trainning Loss:  0.21736444243888814\n",
      "-------------Round number:  57  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8982181425485961\n",
      "Average Global Trainning Accurancy:  0.9195557963163596\n",
      "Average Global Trainning Loss:  0.27914608355763587\n",
      "Average Personal Accurancy:  0.9227861771058316\n",
      "Average Personal Trainning Accurancy:  0.9419465511014807\n",
      "Average Personal Trainning Loss:  0.21625146008261106\n",
      "-------------Round number:  58  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8947084233261339\n",
      "Average Global Trainning Accurancy:  0.9158540989526905\n",
      "Average Global Trainning Loss:  0.2863267407429352\n",
      "Average Personal Accurancy:  0.9208963282937365\n",
      "Average Personal Trainning Accurancy:  0.9411339833875045\n",
      "Average Personal Trainning Loss:  0.217658773403643\n",
      "-------------Round number:  59  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9046976241900648\n",
      "Average Global Trainning Accurancy:  0.9225352112676056\n",
      "Average Global Trainning Loss:  0.273870851813606\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9437522571325389\n",
      "Average Personal Trainning Loss:  0.21305166611649062\n",
      "-------------Round number:  60  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.9250631997110871\n",
      "Average Global Trainning Loss:  0.2707833854589879\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9437522571325389\n",
      "Average Personal Trainning Loss:  0.21282242609301644\n",
      "-------------Round number:  61  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906047516198704\n",
      "Average Global Trainning Accurancy:  0.9247020585048754\n",
      "Average Global Trainning Loss:  0.2684958786170549\n",
      "Average Personal Accurancy:  0.9241360691144709\n",
      "Average Personal Trainning Accurancy:  0.9447453954496208\n",
      "Average Personal Trainning Loss:  0.21003041486096063\n",
      "-------------Round number:  62  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9087473002159827\n",
      "Average Global Trainning Accurancy:  0.926146623329722\n",
      "Average Global Trainning Loss:  0.26787382258797177\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9454676778620441\n",
      "Average Personal Trainning Loss:  0.20722301809656013\n",
      "-------------Round number:  63  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9284037558685446\n",
      "Average Global Trainning Loss:  0.25976271541508666\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9459191043698086\n",
      "Average Personal Trainning Loss:  0.20572464799312704\n",
      "-------------Round number:  64  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9292163235825208\n",
      "Average Global Trainning Loss:  0.2516986906162536\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9480859516070783\n",
      "Average Personal Trainning Loss:  0.19854787025437884\n",
      "-------------Round number:  65  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9087473002159827\n",
      "Average Global Trainning Accurancy:  0.9281328999638859\n",
      "Average Global Trainning Loss:  0.2521267302331618\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.19997343460804892\n",
      "-------------Round number:  66  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9098272138228942\n",
      "Average Global Trainning Accurancy:  0.929035752979415\n",
      "Average Global Trainning Loss:  0.25123035765675783\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.19420516047506997\n",
      "-------------Round number:  67  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9095572354211663\n",
      "Average Global Trainning Accurancy:  0.926056338028169\n",
      "Average Global Trainning Loss:  0.25550561796762145\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.19699342451443436\n",
      "-------------Round number:  68  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9277717587576743\n",
      "Average Global Trainning Loss:  0.24982813610932422\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9474539544962081\n",
      "Average Personal Trainning Loss:  0.1968869821996885\n",
      "-------------Round number:  69  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9284037558685446\n",
      "Average Global Trainning Loss:  0.25100396109126716\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9486276634163958\n",
      "Average Personal Trainning Loss:  0.19379012582103197\n",
      "-------------Round number:  70  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9079373650107991\n",
      "Average Global Trainning Accurancy:  0.9268689057421452\n",
      "Average Global Trainning Loss:  0.254001737286701\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9471830985915493\n",
      "Average Personal Trainning Loss:  0.19880618408467632\n",
      "-------------Round number:  71  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9052375809935205\n",
      "Average Global Trainning Accurancy:  0.9267786204405922\n",
      "Average Global Trainning Loss:  0.2517699093197003\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9469122426868906\n",
      "Average Personal Trainning Loss:  0.19863083750902852\n",
      "-------------Round number:  72  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906317494600432\n",
      "Average Global Trainning Accurancy:  0.9251534850126399\n",
      "Average Global Trainning Loss:  0.2546464748527221\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9459191043698086\n",
      "Average Personal Trainning Loss:  0.1993406439740204\n",
      "-------------Round number:  73  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9033477321814255\n",
      "Average Global Trainning Accurancy:  0.9205489346334417\n",
      "Average Global Trainning Loss:  0.26304397775878025\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9460996749729144\n",
      "Average Personal Trainning Loss:  0.19949721050159128\n",
      "-------------Round number:  74  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9243409172986637\n",
      "Average Global Trainning Loss:  0.2591850746405516\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9454676778620441\n",
      "Average Personal Trainning Loss:  0.20224440971751986\n",
      "-------------Round number:  75  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9073974082073434\n",
      "Average Global Trainning Accurancy:  0.9208197905381004\n",
      "Average Global Trainning Loss:  0.2654627685987721\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9439328277356447\n",
      "Average Personal Trainning Loss:  0.20402699336544106\n",
      "-------------Round number:  76  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9263271939328277\n",
      "Average Global Trainning Loss:  0.25282425913151185\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.19756301984583785\n",
      "-------------Round number:  77  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9258757674250632\n",
      "Average Global Trainning Loss:  0.2536414557305774\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9461899602744673\n",
      "Average Personal Trainning Loss:  0.20038754348506907\n",
      "-------------Round number:  78  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.927049476345251\n",
      "Average Global Trainning Loss:  0.25958022713101525\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9441133983387504\n",
      "Average Personal Trainning Loss:  0.20645501993330173\n",
      "-------------Round number:  79  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9321054532322138\n",
      "Average Global Trainning Loss:  0.24701372989035977\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9467316720837847\n",
      "Average Personal Trainning Loss:  0.1985123600930503\n",
      "-------------Round number:  80  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9287648970747562\n",
      "Average Global Trainning Loss:  0.2544636779763114\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9471830985915493\n",
      "Average Personal Trainning Loss:  0.20252566959247473\n",
      "-------------Round number:  81  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.929938605994944\n",
      "Average Global Trainning Loss:  0.25247973782700206\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.20222430713084596\n",
      "-------------Round number:  82  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9114470842332614\n",
      "Average Global Trainning Accurancy:  0.9267786204405922\n",
      "Average Global Trainning Loss:  0.26367892853918384\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9436619718309859\n",
      "Average Personal Trainning Loss:  0.21130069114103692\n",
      "-------------Round number:  83  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9071274298056156\n",
      "Average Global Trainning Accurancy:  0.9253340556157458\n",
      "Average Global Trainning Loss:  0.2636530949519231\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9437522571325389\n",
      "Average Personal Trainning Loss:  0.21263167194271398\n",
      "-------------Round number:  84  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9302094618996027\n",
      "Average Global Trainning Loss:  0.25182847573723594\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.2034274204925063\n",
      "-------------Round number:  85  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9071274298056156\n",
      "Average Global Trainning Accurancy:  0.924070061394005\n",
      "Average Global Trainning Loss:  0.2682688207822657\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9441133983387504\n",
      "Average Personal Trainning Loss:  0.2137765936061078\n",
      "-------------Round number:  86  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.908207343412527\n",
      "Average Global Trainning Accurancy:  0.9268689057421452\n",
      "Average Global Trainning Loss:  0.2594082089441698\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9453773925604911\n",
      "Average Personal Trainning Loss:  0.20733311943475757\n",
      "-------------Round number:  87  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.900377969762419\n",
      "Average Global Trainning Accurancy:  0.918291802094619\n",
      "Average Global Trainning Loss:  0.28038197383419106\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9418562657999278\n",
      "Average Personal Trainning Loss:  0.21802496229883306\n",
      "-------------Round number:  88  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9087473002159827\n",
      "Average Global Trainning Accurancy:  0.9258757674250632\n",
      "Average Global Trainning Loss:  0.262500436437737\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9446551101480679\n",
      "Average Personal Trainning Loss:  0.20695099394947408\n",
      "-------------Round number:  89  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9092872570194385\n",
      "Average Global Trainning Accurancy:  0.9275009028530156\n",
      "Average Global Trainning Loss:  0.2623549571920707\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9449259660527266\n",
      "Average Personal Trainning Loss:  0.20614744154026723\n",
      "-------------Round number:  90  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9315637414228963\n",
      "Average Global Trainning Loss:  0.25438827123397434\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9459191043698086\n",
      "Average Personal Trainning Loss:  0.20375391118747743\n",
      "-------------Round number:  91  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9292163235825208\n",
      "Average Global Trainning Loss:  0.2583419783272955\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9463705308775732\n",
      "Average Personal Trainning Loss:  0.20396390827436575\n",
      "-------------Round number:  92  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9335500180570603\n",
      "Average Global Trainning Loss:  0.24431253297529568\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.19763079994893237\n",
      "-------------Round number:  93  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9328277356446371\n",
      "Average Global Trainning Loss:  0.23902048294877437\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9482665222101841\n",
      "Average Personal Trainning Loss:  0.19498162288534895\n",
      "-------------Round number:  94  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9323763091368725\n",
      "Average Global Trainning Loss:  0.24164770587164816\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9469122426868906\n",
      "Average Personal Trainning Loss:  0.19731272941636196\n",
      "-------------Round number:  95  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9350848681834597\n",
      "Average Global Trainning Loss:  0.2339144479759164\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9487179487179487\n",
      "Average Personal Trainning Loss:  0.19126471632781464\n",
      "-------------Round number:  96  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9114470842332614\n",
      "Average Global Trainning Accurancy:  0.9301191765980499\n",
      "Average Global Trainning Loss:  0.24133018639682646\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9471830985915493\n",
      "Average Personal Trainning Loss:  0.19373261743437387\n",
      "-------------Round number:  97  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9304803178042614\n",
      "Average Global Trainning Loss:  0.23897044690518915\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.19066926536684048\n",
      "-------------Round number:  98  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9359877211989888\n",
      "Average Global Trainning Loss:  0.23261185766945422\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.1870249661782796\n",
      "-------------Round number:  99  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9349945828819068\n",
      "Average Global Trainning Loss:  0.23240902433329946\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9491693752257132\n",
      "Average Personal Trainning Loss:  0.1884101710624323\n",
      "-------------Round number:  100  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.23478291498792433\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9481762369086313\n",
      "Average Personal Trainning Loss:  0.188641791655381\n",
      "-------------Round number:  101  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9304803178042614\n",
      "Average Global Trainning Loss:  0.2385129587621885\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9486276634163958\n",
      "Average Personal Trainning Loss:  0.1888582030544646\n",
      "-------------Round number:  102  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.933820873961719\n",
      "Average Global Trainning Loss:  0.232967267875079\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.949349945828819\n",
      "Average Personal Trainning Loss:  0.1866970427331618\n",
      "-------------Round number:  103  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9350848681834597\n",
      "Average Global Trainning Loss:  0.2277851208059656\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.18260433683329946\n",
      "-------------Round number:  104  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9349042975803539\n",
      "Average Global Trainning Loss:  0.2301984892377099\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.18324618685671723\n",
      "-------------Round number:  105  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9341820151679306\n",
      "Average Global Trainning Loss:  0.2331290584301079\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.18491443704293067\n",
      "-------------Round number:  106  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.23125120791858522\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9503430841459011\n",
      "Average Personal Trainning Loss:  0.18258582129294196\n",
      "-------------Round number:  107  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9353557240881184\n",
      "Average Global Trainning Loss:  0.2278855235277853\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.18217357499111253\n",
      "-------------Round number:  108  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.23010639646674116\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.18158484693467294\n",
      "-------------Round number:  109  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9353557240881184\n",
      "Average Global Trainning Loss:  0.22456683334179758\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17995082845581098\n",
      "-------------Round number:  110  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9370711448176237\n",
      "Average Global Trainning Loss:  0.22243005181529885\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17911614128380057\n",
      "-------------Round number:  111  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9365294330083063\n",
      "Average Global Trainning Loss:  0.22390095720053493\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.17859351811489932\n",
      "-------------Round number:  112  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.2267178321582137\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.951426507764536\n",
      "Average Personal Trainning Loss:  0.17906038526078344\n",
      "-------------Round number:  113  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9330985915492958\n",
      "Average Global Trainning Loss:  0.22609498260597238\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.17731341096458558\n",
      "-------------Round number:  114  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9342723004694836\n",
      "Average Global Trainning Loss:  0.22424695533981132\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9517876489707475\n",
      "Average Personal Trainning Loss:  0.17904194686851074\n",
      "-------------Round number:  115  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9360780065005417\n",
      "Average Global Trainning Loss:  0.22414165922518284\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.1777207308101413\n",
      "-------------Round number:  116  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9347237269772481\n",
      "Average Global Trainning Loss:  0.22813067809904297\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.18251902207264017\n",
      "-------------Round number:  117  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.935807150595883\n",
      "Average Global Trainning Loss:  0.22585139303872112\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17854289795010045\n",
      "-------------Round number:  118  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9343625857710365\n",
      "Average Global Trainning Loss:  0.22669920640630642\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9503430841459011\n",
      "Average Personal Trainning Loss:  0.18140349382956392\n",
      "-------------Round number:  119  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.22622586984245216\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9496208017334777\n",
      "Average Personal Trainning Loss:  0.18126428562107824\n",
      "-------------Round number:  120  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9341820151679306\n",
      "Average Global Trainning Loss:  0.22598181738669196\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.18016398861417704\n",
      "-------------Round number:  121  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9349945828819068\n",
      "Average Global Trainning Loss:  0.22839135045650505\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9520585048754063\n",
      "Average Personal Trainning Loss:  0.17794322588677094\n",
      "-------------Round number:  122  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9313831708197905\n",
      "Average Global Trainning Loss:  0.22913812187528215\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9502527988443481\n",
      "Average Personal Trainning Loss:  0.18157769420509434\n",
      "-------------Round number:  123  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9103671706263499\n",
      "Average Global Trainning Accurancy:  0.9321957385337667\n",
      "Average Global Trainning Loss:  0.23053875637639942\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.17967863899140032\n",
      "-------------Round number:  124  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9344528710725893\n",
      "Average Global Trainning Loss:  0.22244105092796362\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.951426507764536\n",
      "Average Personal Trainning Loss:  0.17690873619622383\n",
      "-------------Round number:  125  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9331888768508487\n",
      "Average Global Trainning Loss:  0.2244437931676598\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17552854593758463\n",
      "-------------Round number:  126  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9365294330083063\n",
      "Average Global Trainning Loss:  0.22036788350797895\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.17443175365796543\n",
      "-------------Round number:  127  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.22426196615288688\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17908938191952195\n",
      "-------------Round number:  128  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9327374503430842\n",
      "Average Global Trainning Loss:  0.22635997525618454\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.17829948472132878\n",
      "-------------Round number:  129  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.936800288912965\n",
      "Average Global Trainning Loss:  0.22185834042214023\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.17843994934148158\n",
      "-------------Round number:  130  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9343625857710365\n",
      "Average Global Trainning Loss:  0.2237369624145111\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.18074752570662356\n",
      "-------------Round number:  131  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9368905742145178\n",
      "Average Global Trainning Loss:  0.22032265268796272\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.17830265881396148\n",
      "-------------Round number:  132  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.2226520178764897\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9515167930660888\n",
      "Average Personal Trainning Loss:  0.18226838998736006\n",
      "-------------Round number:  133  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9395088479595521\n",
      "Average Global Trainning Loss:  0.21831854382504964\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.1781383884990633\n",
      "-------------Round number:  134  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.2282231455892809\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.18558630869249954\n",
      "-------------Round number:  135  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9379739978331527\n",
      "Average Global Trainning Loss:  0.22254066012662513\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.1813736816053573\n",
      "-------------Round number:  136  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9335500180570603\n",
      "Average Global Trainning Loss:  0.22632435488330624\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.18167731442491084\n",
      "-------------Round number:  137  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9327374503430842\n",
      "Average Global Trainning Loss:  0.23046742746140303\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.18235417865768327\n",
      "-------------Round number:  138  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.933911159263272\n",
      "Average Global Trainning Loss:  0.2323453661421655\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9501625135427952\n",
      "Average Personal Trainning Loss:  0.18332356638579472\n",
      "-------------Round number:  139  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9361682918020946\n",
      "Average Global Trainning Loss:  0.22639215702871074\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9506139400505598\n",
      "Average Personal Trainning Loss:  0.18101271673762528\n",
      "-------------Round number:  140  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9363488624052004\n",
      "Average Global Trainning Loss:  0.22215734435660436\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.1757253947865881\n",
      "-------------Round number:  141  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.938696280245576\n",
      "Average Global Trainning Loss:  0.21933268846351345\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17530375846072024\n",
      "-------------Round number:  142  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.22363318721926914\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.1768495305516996\n",
      "-------------Round number:  143  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.22204836717621435\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.174540047526747\n",
      "-------------Round number:  144  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9347237269772481\n",
      "Average Global Trainning Loss:  0.22862497689965916\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.17565537738903372\n",
      "-------------Round number:  145  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9337305886601661\n",
      "Average Global Trainning Loss:  0.23272638951195151\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.18158098953043178\n",
      "-------------Round number:  146  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.23449164790425245\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.18136676032003318\n",
      "-------------Round number:  147  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9320151679306609\n",
      "Average Global Trainning Loss:  0.23897370916706168\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.18123524487771983\n",
      "-------------Round number:  148  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9374322860238353\n",
      "Average Global Trainning Loss:  0.2177637609259322\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9517876489707475\n",
      "Average Personal Trainning Loss:  0.17646376808527447\n",
      "-------------Round number:  149  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9373420007222825\n",
      "Average Global Trainning Loss:  0.2172024094184498\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.17335371938411318\n",
      "-------------Round number:  150  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9371614301191766\n",
      "Average Global Trainning Loss:  0.21814568803042614\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.17471420381765754\n",
      "-------------Round number:  151  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9364391477067533\n",
      "Average Global Trainning Loss:  0.2208156509922919\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9517876489707475\n",
      "Average Personal Trainning Loss:  0.17750453983415718\n",
      "-------------Round number:  152  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9365294330083063\n",
      "Average Global Trainning Loss:  0.21968807662682827\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17594729472084913\n",
      "-------------Round number:  153  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9382448537378115\n",
      "Average Global Trainning Loss:  0.21425186989323763\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17564325411856152\n",
      "-------------Round number:  154  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9400505597688696\n",
      "Average Global Trainning Loss:  0.2116545804272752\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.17407103125564283\n",
      "-------------Round number:  155  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9381545684362586\n",
      "Average Global Trainning Loss:  0.2118908299053133\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17354863953099608\n",
      "-------------Round number:  156  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.2149024707137053\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9520585048754063\n",
      "Average Personal Trainning Loss:  0.17669003239690548\n",
      "-------------Round number:  157  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9342723004694836\n",
      "Average Global Trainning Loss:  0.2260103842203864\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.18666442011443662\n",
      "-------------Round number:  158  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9372517154207295\n",
      "Average Global Trainning Loss:  0.22227533684176373\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9503430841459011\n",
      "Average Personal Trainning Loss:  0.18057395353692668\n",
      "-------------Round number:  159  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9375225713253882\n",
      "Average Global Trainning Loss:  0.222055486842328\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9507042253521126\n",
      "Average Personal Trainning Loss:  0.17991262913266862\n",
      "-------------Round number:  160  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9378837125315999\n",
      "Average Global Trainning Loss:  0.22144861796480003\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9507042253521126\n",
      "Average Personal Trainning Loss:  0.18180985483463682\n",
      "-------------Round number:  161  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.21563802259671813\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9511556518598772\n",
      "Average Personal Trainning Loss:  0.17884767696977136\n",
      "-------------Round number:  162  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9380642831347057\n",
      "Average Global Trainning Loss:  0.21707723114024693\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17824958093160323\n",
      "-------------Round number:  163  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.2152733546209146\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.1784160554774964\n",
      "-------------Round number:  164  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9394185626579993\n",
      "Average Global Trainning Loss:  0.2143297894589089\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.17783135014262255\n",
      "-------------Round number:  165  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.2137102021685401\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9518779342723005\n",
      "Average Personal Trainning Loss:  0.17603161757756072\n",
      "-------------Round number:  166  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.21101129765371074\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17463532541150348\n",
      "-------------Round number:  167  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20790053257747607\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.17266294645376265\n",
      "-------------Round number:  168  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.20507413534189914\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16957368365088366\n",
      "-------------Round number:  169  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.20562733119470025\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16769734303759254\n",
      "-------------Round number:  170  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.20854291161633262\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9517876489707475\n",
      "Average Personal Trainning Loss:  0.17283802852169106\n",
      "-------------Round number:  171  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9420368364030336\n",
      "Average Global Trainning Loss:  0.2044040711617461\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16985729103184813\n",
      "-------------Round number:  172  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.20957032572538598\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.17359226126238603\n",
      "-------------Round number:  173  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.21164113461820602\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.1764699509532153\n",
      "-------------Round number:  174  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9382448537378115\n",
      "Average Global Trainning Loss:  0.2186760921347395\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9511556518598772\n",
      "Average Personal Trainning Loss:  0.18205942888903937\n",
      "-------------Round number:  175  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.21232812729240025\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.17698658963496525\n",
      "-------------Round number:  176  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.2092130860080354\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.17505239897921182\n",
      "-------------Round number:  177  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9409534127843987\n",
      "Average Global Trainning Loss:  0.21320199467034578\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17521092727236817\n",
      "-------------Round number:  178  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.21170302942454405\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9512459371614301\n",
      "Average Personal Trainning Loss:  0.17851951105924407\n",
      "-------------Round number:  179  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9404117009750813\n",
      "Average Global Trainning Loss:  0.21186682582977834\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9501625135427952\n",
      "Average Personal Trainning Loss:  0.17856958016629423\n",
      "-------------Round number:  180  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.2089128256619041\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17436942902658337\n",
      "-------------Round number:  181  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.20503655320343536\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.1724381369345883\n",
      "-------------Round number:  182  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.20807817155335862\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.17610350857146082\n",
      "-------------Round number:  183  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.21082931634276814\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.17407156027108162\n",
      "-------------Round number:  184  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.20897196517949845\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.17082901524481423\n",
      "-------------Round number:  185  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.2049654667538484\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.17170521910761444\n",
      "-------------Round number:  186  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.20259367011866874\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16743723275903416\n",
      "-------------Round number:  187  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.20393538552529117\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.1670869694327826\n",
      "-------------Round number:  188  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.20547682630236547\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.1689446181672366\n",
      "-------------Round number:  189  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9372517154207295\n",
      "Average Global Trainning Loss:  0.21807535101937747\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9511556518598772\n",
      "Average Personal Trainning Loss:  0.17875119777912266\n",
      "-------------Round number:  190  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.938696280245576\n",
      "Average Global Trainning Loss:  0.21581453741479326\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17591480435598367\n",
      "-------------Round number:  191  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9400505597688696\n",
      "Average Global Trainning Loss:  0.2097679350340827\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.1742861421584394\n",
      "-------------Round number:  192  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9401408450704225\n",
      "Average Global Trainning Loss:  0.20917642964658947\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.17181009641835387\n",
      "-------------Round number:  193  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.2048144989730047\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.17079326261807626\n",
      "-------------Round number:  194  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.1990655559458514\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16876417981799047\n",
      "-------------Round number:  195  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.20037738198018237\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16726476270483479\n",
      "-------------Round number:  196  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20730206182003882\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9515167930660888\n",
      "Average Personal Trainning Loss:  0.17198587281904568\n",
      "-------------Round number:  197  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.20418139974663688\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.1695884079139299\n",
      "-------------Round number:  198  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.20907428558228378\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.17100192614521262\n",
      "-------------Round number:  199  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20647472575839654\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16685112773747857\n",
      "-------------Round number:  200  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9394185626579993\n",
      "Average Global Trainning Loss:  0.20705895718360645\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.1697310437016127\n",
      "-------------Round number:  201  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9402311303719755\n",
      "Average Global Trainning Loss:  0.20198739638350938\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.16706475078435357\n",
      "-------------Round number:  202  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.19675662397864752\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.1624809973245926\n",
      "-------------Round number:  203  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.19676153941376626\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16318942614521262\n",
      "-------------Round number:  204  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19704634810062296\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16092229741882788\n",
      "-------------Round number:  205  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.19895095797642426\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.1620480422725657\n",
      "-------------Round number:  206  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.19845427860633352\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.16089104142331956\n",
      "-------------Round number:  207  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.20175756121766658\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16313619396668472\n",
      "-------------Round number:  208  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.2005409359200072\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16234132622759795\n",
      "-------------Round number:  209  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.1987582861451562\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16208882054597215\n",
      "-------------Round number:  210  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.20026849296903215\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16670613342263113\n",
      "-------------Round number:  211  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.19806781078598998\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16406567409263273\n",
      "-------------Round number:  212  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19928086522943753\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16552164581287807\n",
      "-------------Round number:  213  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.2006830206499413\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.16260580088352633\n",
      "-------------Round number:  214  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19766379728692668\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.16161508722053877\n",
      "-------------Round number:  215  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19714062306027672\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16180674510554915\n",
      "-------------Round number:  216  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.19561212111914275\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16127707941861907\n",
      "-------------Round number:  217  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.19651290215753656\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16022654292642877\n",
      "-------------Round number:  218  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.19689480721972058\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16034111885354596\n",
      "-------------Round number:  219  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.2026422954544172\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16700853187282752\n",
      "-------------Round number:  220  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.20030741968840285\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.1661884477311586\n",
      "-------------Round number:  221  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.19980699312562072\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.1644264956853501\n",
      "-------------Round number:  222  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.1994575343436823\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16607063158447882\n",
      "-------------Round number:  223  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.20110006115418472\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16535873110004176\n",
      "-------------Round number:  224  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19647135240328187\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16197532469204248\n",
      "-------------Round number:  225  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.2014923481443549\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16515979925274807\n",
      "-------------Round number:  226  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.20846986340116017\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.1692784709937308\n",
      "-------------Round number:  227  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.20983866880671045\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.1701687268291238\n",
      "-------------Round number:  228  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9402311303719755\n",
      "Average Global Trainning Loss:  0.20359831452154434\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.1643879436852485\n",
      "-------------Round number:  229  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.19708642102011106\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.16524934613691766\n",
      "-------------Round number:  230  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.20364224484527357\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17083891224198153\n",
      "-------------Round number:  231  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.19874104905877574\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.16726220579688064\n",
      "-------------Round number:  232  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9440231130371975\n",
      "Average Global Trainning Loss:  0.20018629719523068\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16496928756785506\n",
      "-------------Round number:  233  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.20205921022932466\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16861317897368183\n",
      "-------------Round number:  234  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9395088479595521\n",
      "Average Global Trainning Loss:  0.20825655996777942\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9515167930660888\n",
      "Average Personal Trainning Loss:  0.17311743684261016\n",
      "-------------Round number:  235  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.2027947621123375\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16701163983853037\n",
      "-------------Round number:  236  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.19967771497776723\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.1636406212087227\n",
      "-------------Round number:  237  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.20556276926885833\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16874024186938538\n",
      "-------------Round number:  238  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9385157096424702\n",
      "Average Global Trainning Loss:  0.2093380659054487\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.1716035269106627\n",
      "-------------Round number:  239  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.2005672323957769\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16665138032471674\n",
      "-------------Round number:  240  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.1972583951223366\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.1647084278507584\n",
      "-------------Round number:  241  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.19957356506325613\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16587260347189306\n",
      "-------------Round number:  242  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19471559424656915\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16302588322654274\n",
      "-------------Round number:  243  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.19224769314000992\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.1604315253878036\n",
      "-------------Round number:  244  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9449259660527266\n",
      "Average Global Trainning Loss:  0.19292260662835184\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16249892874373645\n",
      "-------------Round number:  245  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.19496531157598637\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16390327737408023\n",
      "-------------Round number:  246  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.19276606214309092\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.15979551657652244\n",
      "-------------Round number:  247  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19396115210392967\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.15947895594218356\n",
      "-------------Round number:  248  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.1949491325204835\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16229846495590128\n",
      "-------------Round number:  249  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.2005060649856672\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1673056071051711\n",
      "-------------Round number:  250  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.20155686598557693\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16623771229389558\n",
      "-------------Round number:  251  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.201985831379503\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16437127969892673\n",
      "-------------Round number:  252  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.20725334831505057\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.16923807846074845\n",
      "-------------Round number:  253  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.19774577263762866\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16292369507761714\n",
      "-------------Round number:  254  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.2002913508444497\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16506069702721538\n",
      "-------------Round number:  255  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.2032827347699982\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.16807985426330016\n",
      "-------------Round number:  256  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.20227365986282278\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.1688541124425842\n",
      "-------------Round number:  257  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.20109600536915404\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.16723631710384504\n",
      "-------------Round number:  258  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19587612186540718\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16130661611395133\n",
      "-------------Round number:  259  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19376191166429668\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16406061538249933\n",
      "-------------Round number:  260  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.20179287299820559\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.1690881356473174\n",
      "-------------Round number:  261  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.19564981346915628\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16361126085187003\n",
      "-------------Round number:  262  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.20336823689029207\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.16978630377265597\n",
      "-------------Round number:  263  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9375225713253882\n",
      "Average Global Trainning Loss:  0.21317532347530696\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9511556518598772\n",
      "Average Personal Trainning Loss:  0.1764982863426553\n",
      "-------------Round number:  264  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.20568922600103828\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.1711012487938448\n",
      "-------------Round number:  265  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.20264423517769276\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.17100879232476188\n",
      "-------------Round number:  266  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.939689418562658\n",
      "Average Global Trainning Loss:  0.2042928236234313\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17174201874407502\n",
      "-------------Round number:  267  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.19920373918692444\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16702107394718874\n",
      "-------------Round number:  268  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.19554092445800605\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16603551818472936\n",
      "-------------Round number:  269  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9414951245937161\n",
      "Average Global Trainning Loss:  0.19682788676671406\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16447920986959416\n",
      "-------------Round number:  270  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.19646928042614661\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16620507865401543\n",
      "-------------Round number:  271  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.19244904964139806\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.1641334321534173\n",
      "-------------Round number:  272  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.19413698361039636\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.16510679851847462\n",
      "-------------Round number:  273  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19467600625789996\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.16287517995341844\n",
      "-------------Round number:  274  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.19491809694807466\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.16453634353698313\n",
      "-------------Round number:  275  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.19317571847350126\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.16140596080489347\n",
      "-------------Round number:  276  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.19525148688605995\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.16160070461329676\n",
      "-------------Round number:  277  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.19122669334315187\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15950353311777718\n",
      "-------------Round number:  278  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.19362051024597102\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15878197810158226\n",
      "-------------Round number:  279  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.2030642734360893\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16714375042321236\n",
      "-------------Round number:  280  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.20378020766324711\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16501472778981582\n",
      "-------------Round number:  281  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.19522962091459012\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16565836324033947\n",
      "-------------Round number:  282  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.19613745549216774\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16236126349694724\n",
      "-------------Round number:  283  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.1899918831397842\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.1596067131706505\n",
      "-------------Round number:  284  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.19247613964032592\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.16201216841312296\n",
      "-------------Round number:  285  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9454676778620441\n",
      "Average Global Trainning Loss:  0.19500743443029975\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.16423024197871525\n",
      "-------------Round number:  286  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.19758735455602203\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16509633944240362\n",
      "-------------Round number:  287  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.1923829447538597\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16093424435082046\n",
      "-------------Round number:  288  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.19523962812330714\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16294615619145564\n",
      "-------------Round number:  289  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19414291299177275\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.16474864404526116\n",
      "-------------Round number:  290  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19353518446415674\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.1635488370300932\n",
      "-------------Round number:  291  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.19885291378176914\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16525107645824869\n",
      "-------------Round number:  292  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.19974102049194203\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.16657458491685287\n",
      "-------------Round number:  293  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.2017051005199869\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.16963011196435424\n",
      "-------------Round number:  294  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9384254243409172\n",
      "Average Global Trainning Loss:  0.20600802392983703\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.1692898117621998\n",
      "-------------Round number:  295  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19592439452419647\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16296284222008736\n",
      "-------------Round number:  296  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9402311303719755\n",
      "Average Global Trainning Loss:  0.20145088655934001\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9525099313831709\n",
      "Average Personal Trainning Loss:  0.16786605487794556\n",
      "-------------Round number:  297  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19218070656007358\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.16069469954744492\n",
      "-------------Round number:  298  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18809628856875227\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15766585471613737\n",
      "-------------Round number:  299  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18786810657615566\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.15870768449589767\n",
      "-------------Round number:  300  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18472886283546633\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.1562624318628115\n",
      "-------------Round number:  301  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.18232098293889942\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15315360650985238\n",
      "-------------Round number:  302  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.18225902200563154\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15269157765100216\n",
      "-------------Round number:  303  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.1912047832870621\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.16142697814743026\n",
      "-------------Round number:  304  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.19230797885772166\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16179410384079315\n",
      "-------------Round number:  305  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19135224634062387\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16191963479595523\n",
      "-------------Round number:  306  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.1922733503887911\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16153882082811372\n",
      "-------------Round number:  307  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18810087336922174\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.1598227718927749\n",
      "-------------Round number:  308  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.1891961116659895\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.16057476733901002\n",
      "-------------Round number:  309  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.18670054746044376\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15737039959357507\n",
      "-------------Round number:  310  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18798947153473727\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.1570053017927275\n",
      "-------------Round number:  311  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.18424840660549838\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15568265298421136\n",
      "-------------Round number:  312  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18439267352411745\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.1554872368853546\n",
      "-------------Round number:  313  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.18336135792620306\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.15464921030338682\n",
      "-------------Round number:  314  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.185698592219382\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15568881380984223\n",
      "-------------Round number:  315  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.18416288244289455\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15232895961002393\n",
      "-------------Round number:  316  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18466982250826675\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15407699193709937\n",
      "-------------Round number:  317  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.18535385049177275\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15276547449510766\n",
      "-------------Round number:  318  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.18098525201942828\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.15214866453579248\n",
      "-------------Round number:  319  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18297793194463255\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.15564229351469394\n",
      "-------------Round number:  320  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.18365158902130732\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.1564442258141195\n",
      "-------------Round number:  321  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.18221571988773588\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15360866999875858\n",
      "-------------Round number:  322  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17999963013003906\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15246962261096628\n",
      "-------------Round number:  323  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.18103634609389108\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15306625283552275\n",
      "-------------Round number:  324  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.18441003184320265\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15368313994292276\n",
      "-------------Round number:  325  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.182658605000395\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15146346830985916\n",
      "-------------Round number:  326  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.18608091608545504\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.1543905217538202\n",
      "-------------Round number:  327  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9470025279884435\n",
      "Average Global Trainning Loss:  0.18336523737275415\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15265409470293315\n",
      "-------------Round number:  328  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18415253357837327\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.15358985688721674\n",
      "-------------Round number:  329  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.19093218603991738\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.15768538420275258\n",
      "-------------Round number:  330  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.19812058007600894\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.1615100556136297\n",
      "-------------Round number:  331  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.19343564139242506\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16079535575582904\n",
      "-------------Round number:  332  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9404117009750813\n",
      "Average Global Trainning Loss:  0.19974368761144592\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16423146532691743\n",
      "-------------Round number:  333  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19275127175311485\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15909377759697205\n",
      "-------------Round number:  334  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19126645767030065\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16158328016728174\n",
      "-------------Round number:  335  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.19640317553860825\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16442253909071416\n",
      "-------------Round number:  336  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.19730430925396128\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16419837981968333\n",
      "-------------Round number:  337  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19566167223190908\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.16258742861818345\n",
      "-------------Round number:  338  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.2027994571243567\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16718384538501038\n",
      "-------------Round number:  339  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19460095219252213\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.16151579763537152\n",
      "-------------Round number:  340  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.20128512838852022\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.1659771721902932\n",
      "-------------Round number:  341  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19567115042518735\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.1641091084643881\n",
      "-------------Round number:  342  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19275036801840692\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.16041044191833695\n",
      "-------------Round number:  343  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.18765557462362314\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15509166559100193\n",
      "-------------Round number:  344  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.18371467411238263\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15598760834236186\n",
      "-------------Round number:  345  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.1818943099452081\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15258132201663507\n",
      "-------------Round number:  346  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.1797325324392267\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.15110636084636828\n",
      "-------------Round number:  347  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18203669224632651\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.15048715929642356\n",
      "-------------Round number:  348  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.18450719434545979\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15614234535820692\n",
      "-------------Round number:  349  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.18085563221577058\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15132618880349405\n",
      "-------------Round number:  350  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17922807213372383\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15199931686473006\n",
      "-------------Round number:  351  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.1779490450565976\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.14997337509381206\n",
      "-------------Round number:  352  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17831576296722643\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.1509777880524332\n",
      "-------------Round number:  353  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17773283203830353\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.1502689073644592\n",
      "-------------Round number:  354  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.18185085353114278\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.15033915620626806\n",
      "-------------Round number:  355  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.1802745748831934\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15172268587486457\n",
      "-------------Round number:  356  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.18087334321181495\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15134586156512392\n",
      "-------------Round number:  357  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.1800620870152808\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15177320684926868\n",
      "-------------Round number:  358  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.17867093070744178\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14970769913199147\n",
      "-------------Round number:  359  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.18052521798962848\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.15298386970208672\n",
      "-------------Round number:  360  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17587034501681564\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14861657172602924\n",
      "-------------Round number:  361  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17548899101238039\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14821207329614708\n",
      "-------------Round number:  362  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17612052523474178\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14929873713434452\n",
      "-------------Round number:  363  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.174836075749368\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14910994474962758\n",
      "-------------Round number:  364  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.1765974987797377\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14869282709729933\n",
      "-------------Round number:  365  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.176262114012702\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14702915069040043\n",
      "-------------Round number:  366  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17640431997534084\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.1470339008081945\n",
      "-------------Round number:  367  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17585979777150482\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.14743173143931698\n",
      "-------------Round number:  368  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17392599285617552\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14530741483909465\n",
      "-------------Round number:  369  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17372798678589968\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14501022939520133\n",
      "-------------Round number:  370  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.1735056790689046\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14466869482368974\n",
      "-------------Round number:  371  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.1729833093865678\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14392075516248534\n",
      "-------------Round number:  372  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.174052647969145\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1449081404366705\n",
      "-------------Round number:  373  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17486095049614594\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1453318487396736\n",
      "-------------Round number:  374  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.1734600404661543\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1446204552283654\n",
      "-------------Round number:  375  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17473582732371795\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14475100080904094\n",
      "-------------Round number:  376  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.17743224105752303\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14946234617994425\n",
      "-------------Round number:  377  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18292217592161544\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.15312724390715285\n",
      "-------------Round number:  378  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.18504907147210184\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15466216016048212\n",
      "-------------Round number:  379  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9475442397977609\n",
      "Average Global Trainning Loss:  0.18513047372274513\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.15343202292682376\n",
      "-------------Round number:  380  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18370714666353488\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1514991878731322\n",
      "-------------Round number:  381  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.18029329982549544\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14949212534068596\n",
      "-------------Round number:  382  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.18557901268790628\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.15194965554041395\n",
      "-------------Round number:  383  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.18374955606787763\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15187625464828233\n",
      "-------------Round number:  384  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.1844716511206663\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.148958910841854\n",
      "-------------Round number:  385  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.18574521170492506\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14948605268429488\n",
      "-------------Round number:  386  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.18454160239129086\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.1503939864522673\n",
      "-------------Round number:  387  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.1846579857878239\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14917833101624572\n",
      "-------------Round number:  388  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9451968219573853\n",
      "Average Global Trainning Loss:  0.1846262448614967\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14789269124613466\n",
      "-------------Round number:  389  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17445201054080894\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.1454547125753318\n",
      "-------------Round number:  390  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.17633469933936552\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14536504445845747\n",
      "-------------Round number:  391  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17251743414463142\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14598943697239528\n",
      "-------------Round number:  392  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.1777855131590827\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14740703303101865\n",
      "-------------Round number:  393  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.17914065233246435\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.14746788082763407\n",
      "-------------Round number:  394  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.18400501541903666\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.15224104385679058\n",
      "-------------Round number:  395  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.18860969805209463\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15169954144941766\n",
      "-------------Round number:  396  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.18316256935392403\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.14999743427512188\n",
      "-------------Round number:  397  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9451968219573853\n",
      "Average Global Trainning Loss:  0.1819539123513114\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.1482416099914793\n",
      "-------------Round number:  398  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17401525319031577\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.144655502501185\n",
      "-------------Round number:  399  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.1734626965645032\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.14325006277649874\n",
      "-------------Round number:  400  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.1719459762380372\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14222549212542884\n",
      "-------------Round number:  401  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17160202803358612\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14335657121817444\n",
      "-------------Round number:  402  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17185191068032796\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14119474962757314\n",
      "-------------Round number:  403  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.17318545941111413\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14444703735483816\n",
      "-------------Round number:  404  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.17538471986516455\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14497409102803924\n",
      "-------------Round number:  405  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.173779731108506\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14420036186419397\n",
      "-------------Round number:  406  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.1711269721695558\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1433072295073526\n",
      "-------------Round number:  407  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17163457350422648\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.1431501890701178\n",
      "-------------Round number:  408  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.16945078675176056\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14179457598707226\n",
      "-------------Round number:  409  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.1692483942618048\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14051665102544353\n",
      "-------------Round number:  410  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1694415730662017\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14233294838643237\n",
      "-------------Round number:  411  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.1718062941198876\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14178945115000902\n",
      "-------------Round number:  412  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17161800870829946\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.1416742800805232\n",
      "-------------Round number:  413  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17163468371577623\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.1425194483709146\n",
      "-------------Round number:  414  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17130618717059973\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.1412815191806891\n",
      "-------------Round number:  415  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.1733527164590105\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.1428599689961685\n",
      "-------------Round number:  416  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.1758249378583198\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14288413838902808\n",
      "-------------Round number:  417  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.1758094531355803\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.1421814846536148\n",
      "-------------Round number:  418  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.173265726482795\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.1430160065083006\n",
      "-------------Round number:  419  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.17416030261093807\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14448976637267516\n",
      "-------------Round number:  420  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.1731466208609832\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14105345842079722\n",
      "-------------Round number:  421  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17492835587997133\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.144838607969935\n",
      "-------------Round number:  422  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.17723831281458785\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1466938981772244\n",
      "-------------Round number:  423  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.17777860289491354\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14608370091089404\n",
      "-------------Round number:  424  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17055682578040357\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14284974136435197\n",
      "-------------Round number:  425  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17230360169581188\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.1437252839578537\n",
      "-------------Round number:  426  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.1721450403391906\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14399596352403282\n",
      "-------------Round number:  427  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17005792013700793\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14270854934797084\n",
      "-------------Round number:  428  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17691605424312704\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.1504592537320276\n",
      "-------------Round number:  429  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.1775152634179476\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.14974001315837734\n",
      "-------------Round number:  430  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1745500326931541\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14803920648036858\n",
      "-------------Round number:  431  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17132723757660143\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14642585266708424\n",
      "-------------Round number:  432  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17186259017949845\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.1451011980083627\n",
      "-------------Round number:  433  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17255043148262572\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14688605201420865\n",
      "-------------Round number:  434  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17631385833530833\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14751491911706618\n",
      "-------------Round number:  435  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17216582623747292\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14475061506861683\n",
      "-------------Round number:  436  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17204913424860058\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14463636977614888\n",
      "-------------Round number:  437  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17593599803700005\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.1469932768309577\n",
      "-------------Round number:  438  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.1771718883135552\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14784808863195198\n",
      "-------------Round number:  439  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.17920577633720997\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.1467588568646454\n",
      "-------------Round number:  440  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.1734591697949113\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14469503538407932\n",
      "-------------Round number:  441  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17194998793844798\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14368841819446326\n",
      "-------------Round number:  442  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17348434211287356\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14346790692572906\n",
      "-------------Round number:  443  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16750560800449735\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1405079332918585\n",
      "-------------Round number:  444  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1660900398383893\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.13909095441791372\n",
      "-------------Round number:  445  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16737769647986073\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14196595494692918\n",
      "-------------Round number:  446  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16735553293720656\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1420569676447104\n",
      "-------------Round number:  447  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.1649931924529952\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13893231591320762\n",
      "-------------Round number:  448  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1684105991240915\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14316669876026994\n",
      "-------------Round number:  449  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16863519924132134\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14280553551174838\n",
      "-------------Round number:  450  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.1679920266793066\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14148109025497133\n",
      "-------------Round number:  451  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16766532658239097\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.14059442731610014\n",
      "-------------Round number:  452  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16710620134821347\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14158447970978918\n",
      "-------------Round number:  453  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1668691583470172\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14094324687105003\n",
      "-------------Round number:  454  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17000707954910957\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14079505642125992\n",
      "-------------Round number:  455  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16684124176146622\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14159918193052545\n",
      "-------------Round number:  456  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16581496283137528\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13926279626627958\n",
      "-------------Round number:  457  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16732327401659558\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14070699739301193\n",
      "-------------Round number:  458  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.16543936186983682\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13962893005569474\n",
      "-------------Round number:  459  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16492194068608365\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13979582340547694\n",
      "-------------Round number:  460  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.16573414470194564\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.14037032315084416\n",
      "-------------Round number:  461  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16673042404819544\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13946137543661408\n",
      "-------------Round number:  462  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16699542771956258\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14046466423742776\n",
      "-------------Round number:  463  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.16879897360424567\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1420704465172445\n",
      "-------------Round number:  464  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.17282467088186168\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14355617535592158\n",
      "-------------Round number:  465  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.17439611124277718\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.14450722388215512\n",
      "-------------Round number:  466  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9470025279884435\n",
      "Average Global Trainning Loss:  0.1741744978585455\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14400309421130147\n",
      "-------------Round number:  467  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.1668144052491028\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14133054127801667\n",
      "-------------Round number:  468  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.16954596544612224\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14197083731858298\n",
      "-------------Round number:  469  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.1719768024085015\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14355344210948787\n",
      "-------------Round number:  470  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.17581498575537763\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14563950428079292\n",
      "-------------Round number:  471  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.17402556899137211\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14327387949239911\n",
      "-------------Round number:  472  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.1746105939397402\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14599493652872766\n",
      "-------------Round number:  473  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1710587401991073\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14335830153950546\n",
      "-------------Round number:  474  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17488610077179825\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14765012664629604\n",
      "-------------Round number:  475  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.17965129550590805\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.1495639502076562\n",
      "-------------Round number:  476  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.17714458891268284\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14772901607360509\n",
      "-------------Round number:  477  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.17886760321796566\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.1501571197895506\n",
      "-------------Round number:  478  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.17981592951892042\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14768451264981716\n",
      "-------------Round number:  479  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9475442397977609\n",
      "Average Global Trainning Loss:  0.17844570238437837\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14876445358348006\n",
      "-------------Round number:  480  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.18490297504175696\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.15616979905524897\n",
      "-------------Round number:  481  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17700433369447455\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.15081750739563585\n",
      "-------------Round number:  482  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.1742563740188527\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14923558591633937\n",
      "-------------Round number:  483  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.173759242781408\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14690452346994629\n",
      "-------------Round number:  484  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17351003242511961\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14788671778013837\n",
      "-------------Round number:  485  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.17429541094977316\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.14704271773217428\n",
      "-------------Round number:  486  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.1732314617119786\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14779634430934566\n",
      "-------------Round number:  487  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.17657576506212758\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.14902151100211042\n",
      "-------------Round number:  488  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17583254245525234\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15064443117791282\n",
      "-------------Round number:  489  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.18047989900037242\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.15231844542817805\n",
      "-------------Round number:  490  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.18053555583299477\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15181973816557195\n",
      "-------------Round number:  491  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.18190921054673392\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15133076258280856\n",
      "-------------Round number:  492  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.18299441959247473\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15221829619292276\n",
      "-------------Round number:  493  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17584813738954158\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14683606005524333\n",
      "-------------Round number:  494  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17415435118725173\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14633197446900956\n",
      "-------------Round number:  495  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.1755582148867766\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14547050589041058\n",
      "-------------Round number:  496  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16934329742729212\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14138051119467204\n",
      "-------------Round number:  497  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.16407595683022413\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1401312191936676\n",
      "-------------Round number:  498  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16323721387318302\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13841828924518668\n",
      "-------------Round number:  499  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.1650618652696427\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1399351308043574\n",
      "-------------Round number:  500  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.1662220071480566\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1409779084034455\n",
      "-------------Round number:  501  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.16733727088341346\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.1411027340046892\n",
      "-------------Round number:  502  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.16664697186272684\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.1406608738594427\n",
      "-------------Round number:  503  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16742114187277107\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14080262795472756\n",
      "-------------Round number:  504  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1679384859084394\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.1403012535726176\n",
      "-------------Round number:  505  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.16707119816001376\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14013011707817014\n",
      "-------------Round number:  506  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17141038116973073\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14421401707520765\n",
      "-------------Round number:  507  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.17052745440239594\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14351734782694564\n",
      "-------------Round number:  508  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.18048620310101796\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.14996934135109133\n",
      "-------------Round number:  509  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17424940864890867\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.1467634306439599\n",
      "-------------Round number:  510  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.1750316461443944\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14663115474195332\n",
      "-------------Round number:  511  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.17036557567812727\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.1446027111688561\n",
      "-------------Round number:  512  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17123977369072205\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14469521172255892\n",
      "-------------Round number:  513  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16854603809757585\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14180478157657886\n",
      "-------------Round number:  514  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.1667277679498465\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14241122062906283\n",
      "-------------Round number:  515  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16454408038777538\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14093276575266905\n",
      "-------------Round number:  516  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1637933303320524\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13884561248702149\n",
      "-------------Round number:  517  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.1658024868839439\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13960988549989842\n",
      "-------------Round number:  518  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16381615514400505\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13781447322758666\n",
      "-------------Round number:  519  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16632725917806518\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.1391607183289037\n",
      "-------------Round number:  520  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16480107167947589\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13661661695684926\n",
      "-------------Round number:  521  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16229058483009434\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13858956901464878\n",
      "-------------Round number:  522  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16406320535391838\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13781209265811215\n",
      "-------------Round number:  523  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16242761084989504\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1375070711730318\n",
      "-------------Round number:  524  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16084377168963299\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13659111400423776\n",
      "-------------Round number:  525  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.164133564407277\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13836315040684813\n",
      "-------------Round number:  526  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.16163344846472666\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13656252512823333\n",
      "-------------Round number:  527  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1644545224824508\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13819231148358502\n",
      "-------------Round number:  528  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16166067071751422\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1368659705881523\n",
      "-------------Round number:  529  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.1606072136192556\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1381093001443154\n",
      "-------------Round number:  530  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16152300547072498\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1370545756132347\n",
      "-------------Round number:  531  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16099080491815074\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13575912701519616\n",
      "-------------Round number:  532  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16054226595298957\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.1360985014403327\n",
      "-------------Round number:  533  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16273971893762415\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.13971389213939486\n",
      "-------------Round number:  534  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1646733695567838\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1403266683559893\n",
      "-------------Round number:  535  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16533424209368794\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.1390322447253634\n",
      "-------------Round number:  536  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16296727272438719\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13892501990861433\n",
      "-------------Round number:  537  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16282408587895564\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13666078974598794\n",
      "-------------Round number:  538  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16341954786108479\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13775485980032842\n",
      "-------------Round number:  539  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.16280751006187363\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1369191586820603\n",
      "-------------Round number:  540  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.1651913528194407\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13892004936772076\n",
      "-------------Round number:  541  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16385217227846244\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14033200259499706\n",
      "-------------Round number:  542  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16130591076003295\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.1373360338689791\n",
      "-------------Round number:  543  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.1621853107577758\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13738744755693616\n",
      "-------------Round number:  544  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16176515126667457\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13615350802481152\n",
      "-------------Round number:  545  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.16235649133684318\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13659752831643304\n",
      "-------------Round number:  546  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.1632536904998702\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13557732204273315\n",
      "-------------Round number:  547  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15975312921448967\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13346940492111323\n",
      "-------------Round number:  548  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15849675061083648\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13559250919428834\n",
      "-------------Round number:  549  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15886658750832316\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13443915634733883\n",
      "-------------Round number:  550  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15846913159646983\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13365577265173573\n",
      "-------------Round number:  551  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1629101170146883\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13816133101695108\n",
      "-------------Round number:  552  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16394938988649443\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.1370006380807884\n",
      "-------------Round number:  553  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1621948660991389\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13784216939003816\n",
      "-------------Round number:  554  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.1640552150165617\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13921472198827983\n",
      "-------------Round number:  555  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.16758220503157165\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14099828651899377\n",
      "-------------Round number:  556  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.16879629546358682\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14131627990347936\n",
      "-------------Round number:  557  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.16857089080204382\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14227658619989167\n",
      "-------------Round number:  558  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16126468061927252\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13545408348780585\n",
      "-------------Round number:  559  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16567609627869379\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14037282495302342\n",
      "-------------Round number:  560  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.1678700555572014\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14376753906602677\n",
      "-------------Round number:  561  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.16484520038399467\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.13989058329594958\n",
      "-------------Round number:  562  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.1643626170711166\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.1391956443690186\n",
      "-------------Round number:  563  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.16706453036125407\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14062336886906374\n",
      "-------------Round number:  564  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16477302284006523\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13739207644202556\n",
      "-------------Round number:  565  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16517605545633576\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13777070822118206\n",
      "-------------Round number:  566  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.16991284867407572\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1411437547435051\n",
      "-------------Round number:  567  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.16367853398183574\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13704279399856673\n",
      "-------------Round number:  568  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.16106979353585454\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13457220373019366\n",
      "-------------Round number:  569  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16705613224116334\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.14170456621439373\n",
      "-------------Round number:  570  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16648789251182172\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.1404133828033304\n",
      "-------------Round number:  571  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.1753512927021262\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.1459239823330004\n",
      "-------------Round number:  572  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17082256786915404\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14299653212746027\n",
      "-------------Round number:  573  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16825483714083378\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14165055153386263\n",
      "-------------Round number:  574  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16752125804456144\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13971154463338525\n",
      "-------------Round number:  575  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.16631838714831054\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14047787860224245\n",
      "-------------Round number:  576  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17008029308160663\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.13980003348667727\n",
      "-------------Round number:  577  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.17107013607335117\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14126464579242282\n",
      "-------------Round number:  578  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17164671881700863\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.13986682168582407\n",
      "-------------Round number:  579  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17337478081126986\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14069313278005371\n",
      "-------------Round number:  580  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1631874202950072\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13634614679261467\n",
      "-------------Round number:  581  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16148186349920435\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13564873912696934\n",
      "-------------Round number:  582  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.1639786290106424\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.1349820804837035\n",
      "-------------Round number:  583  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16546260548567848\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13503354927743544\n",
      "-------------Round number:  584  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.16934676909110916\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13797705730577375\n",
      "-------------Round number:  585  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.16822028581998805\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1372036697977327\n",
      "-------------Round number:  586  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16377987350182827\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13516827187584643\n",
      "-------------Round number:  587  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16327549034441022\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13538192798618634\n",
      "-------------Round number:  588  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16344132566331482\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13552143376585635\n",
      "-------------Round number:  589  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.16545246602310176\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13456057641169533\n",
      "-------------Round number:  590  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.16450588106463299\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.1371419403087193\n",
      "-------------Round number:  591  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.16403759218975714\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13214396776038845\n",
      "-------------Round number:  592  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.16326632074347125\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13391696300348163\n",
      "-------------Round number:  593  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.1598277424336685\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.1328920617177625\n",
      "-------------Round number:  594  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.15913531633007177\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1320005164072375\n",
      "-------------Round number:  595  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1648193778178889\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.1375258512211087\n",
      "-------------Round number:  596  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16256113214241377\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13681904251026994\n",
      "-------------Round number:  597  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16334426235145247\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13840112930689102\n",
      "-------------Round number:  598  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16355988022737789\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1355390676138159\n",
      "-------------Round number:  599  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16450510958378475\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13778345969748781\n",
      "-------------Round number:  600  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16465679373970182\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13757804741106897\n",
      "-------------Round number:  601  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.1656917904033778\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13760774942372586\n",
      "-------------Round number:  602  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16430010508009998\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.1361698303553291\n",
      "-------------Round number:  603  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17061395944779253\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14006437588874593\n",
      "-------------Round number:  604  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17023273769721695\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.13788339953079856\n",
      "-------------Round number:  605  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16562320575597012\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1371437257358252\n",
      "-------------Round number:  606  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16740624127124526\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13923852768302525\n",
      "-------------Round number:  607  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16976136289894816\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14046875308592338\n",
      "-------------Round number:  608  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16256392049462237\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13778052807026453\n",
      "-------------Round number:  609  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.1622465222525054\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13625320539271285\n",
      "-------------Round number:  610  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15898909866702216\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13462514935869221\n",
      "-------------Round number:  611  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15694868611962237\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13342545255507404\n",
      "-------------Round number:  612  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15666816466205083\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.1338941712549939\n",
      "-------------Round number:  613  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15968342040927455\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.1336872600914985\n",
      "-------------Round number:  614  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15925540283467632\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13535477186032863\n",
      "-------------Round number:  615  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16274387391304962\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13683108863265733\n",
      "-------------Round number:  616  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16010137566938087\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1347232927437421\n",
      "-------------Round number:  617  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.16704703978830918\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13847982035341053\n",
      "-------------Round number:  618  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.1659842808352519\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13682892848628228\n",
      "-------------Round number:  619  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.1580616574547445\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13423729287282188\n",
      "-------------Round number:  620  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1590300202154433\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13557888704673957\n",
      "-------------Round number:  621  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15878409416333739\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13473374079865813\n",
      "-------------Round number:  622  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15643151842243364\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.1330128645974404\n",
      "-------------Round number:  623  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.1558893657669172\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13160490102826494\n",
      "-------------Round number:  624  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.15571374366239504\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13068353247237835\n",
      "-------------Round number:  625  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15536949788675966\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.12996151456767446\n",
      "-------------Round number:  626  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16008716940061846\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13349035613672017\n",
      "-------------Round number:  627  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16009427804557716\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13227411657948493\n",
      "-------------Round number:  628  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.15864024604860735\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13097641966583154\n",
      "-------------Round number:  629  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.1642531439387527\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.1358792576044206\n",
      "-------------Round number:  630  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.1619034226769874\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13276748960308324\n",
      "-------------Round number:  631  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15664569252705737\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.1314054181232225\n",
      "-------------Round number:  632  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.15647031288794466\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1310670686654986\n",
      "-------------Round number:  633  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.15610047599045798\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12908526662025438\n",
      "-------------Round number:  634  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.15593142249430075\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13080696940809522\n",
      "-------------Round number:  635  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.15626637743629243\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13064498047227677\n",
      "-------------Round number:  636  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15537924058775732\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.12942249192017086\n",
      "-------------Round number:  637  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15590051917575162\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.12927552481858298\n",
      "-------------Round number:  638  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1552506788149772\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.12988336355774874\n",
      "-------------Round number:  639  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.15561787063526994\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12888749199423302\n",
      "-------------Round number:  640  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.15673093013963185\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13059900021372223\n",
      "-------------Round number:  641  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.1576164027937658\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13076146305920458\n",
      "-------------Round number:  642  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.15725282591230474\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.12953843447050492\n",
      "-------------Round number:  643  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.15743178742678426\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12940227912194724\n",
      "-------------Round number:  644  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15668127983647076\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.131212944672744\n",
      "-------------Round number:  645  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15653151336151927\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13037625165052816\n",
      "-------------Round number:  646  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15441613491798145\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13031669332904477\n",
      "-------------Round number:  647  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15637923406323356\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13021483581476842\n",
      "-------------Round number:  648  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15557225407482958\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12988038784590555\n",
      "-------------Round number:  649  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1552729195057162\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12901021255487655\n",
      "-------------Round number:  650  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15566796178463005\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12908278686038507\n",
      "-------------Round number:  651  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15697648147246862\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12906331247954472\n",
      "-------------Round number:  652  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1579581577883769\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1301017587647278\n",
      "-------------Round number:  653  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15641109622226548\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12987970453429712\n",
      "-------------Round number:  654  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1548733475321077\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.1275102554051271\n",
      "-------------Round number:  655  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15558735305714494\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.12817877662358365\n",
      "-------------Round number:  656  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.1578959433685446\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13024363409271736\n",
      "-------------Round number:  657  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.1577630502818594\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.12855620709684792\n",
      "-------------Round number:  658  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.15725911899179532\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.12907347398443142\n",
      "-------------Round number:  659  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.1582054284213897\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13263918131686755\n",
      "-------------Round number:  660  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1579004730632392\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.12984809586182963\n",
      "-------------Round number:  661  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16107341949584122\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13081057332577195\n",
      "-------------Round number:  662  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.15889566131514649\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13197006495604235\n",
      "-------------Round number:  663  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16166560819494288\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13323326565462487\n",
      "-------------Round number:  664  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.15929113341910436\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13240120151749843\n",
      "-------------Round number:  665  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.15893971287158046\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13161592218323967\n",
      "-------------Round number:  666  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1554846689562455\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.1306716957519355\n",
      "-------------Round number:  667  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1585239067366942\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13520205171584393\n",
      "-------------Round number:  668  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.15766318759663348\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.1355491850340827\n",
      "-------------Round number:  669  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16170277152951765\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13601896176488015\n",
      "-------------Round number:  670  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17048185988426554\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14385341590558978\n",
      "-------------Round number:  671  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16758424394524196\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14388398858948967\n",
      "-------------Round number:  672  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16317837192677298\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13917878200190728\n",
      "-------------Round number:  673  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15970052524179532\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13504902297901994\n",
      "-------------Round number:  674  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16606495568966684\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14213142656771963\n",
      "-------------Round number:  675  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.1670203906355803\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.1414418329009514\n",
      "-------------Round number:  676  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16377663328226572\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1391172508936834\n",
      "-------------Round number:  677  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.16068139701339043\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13846113949572839\n",
      "-------------Round number:  678  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.1589686434033891\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13550547513345296\n",
      "-------------Round number:  679  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15793232420111616\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13540004676496478\n",
      "-------------Round number:  680  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15540098532652244\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13274568975854326\n",
      "-------------Round number:  681  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15465630792719054\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.1313776448126862\n",
      "-------------Round number:  682  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15474093937624142\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.13148093507710928\n",
      "-------------Round number:  683  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.1553599425453966\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1330572467885236\n",
      "-------------Round number:  684  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.1545947657978117\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13138291292476412\n",
      "-------------Round number:  685  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.15353853136849946\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13034198687971177\n",
      "-------------Round number:  686  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.1534372028696619\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13159876224494402\n",
      "-------------Round number:  687  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15332106193853828\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.1295242833075174\n",
      "-------------Round number:  688  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.155027114686315\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13172039171124503\n",
      "-------------Round number:  689  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15320066684159445\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.1309274747165888\n",
      "-------------Round number:  690  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.1528321524827047\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.1295390075705636\n",
      "-------------Round number:  691  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15348695236321777\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12966514468924928\n",
      "-------------Round number:  692  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15273942048474742\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12901608683047805\n",
      "-------------Round number:  693  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15342222512005124\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13039174739442264\n",
      "-------------Round number:  694  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15329369641073606\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.1291197077295504\n",
      "-------------Round number:  695  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.1521766031636534\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13014270235545888\n",
      "-------------Round number:  696  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.1531880806826133\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12882928927481152\n",
      "-------------Round number:  697  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15300036837108388\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12932902150483028\n",
      "-------------Round number:  698  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15260841201556294\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.1285174567159568\n",
      "-------------Round number:  699  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15179954740965826\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12819296085003612\n",
      "-------------Round number:  700  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15189738220236887\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12858455350744288\n",
      "-------------Round number:  701  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15310781361093243\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.1299411805367461\n",
      "-------------Round number:  702  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15349066649244425\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12882706300150665\n",
      "-------------Round number:  703  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15455863845180456\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.1303936760965432\n",
      "-------------Round number:  704  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15571436084707363\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.1331125289018768\n",
      "-------------Round number:  705  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.1544849950942635\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1322762216200851\n",
      "-------------Round number:  706  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15445032254071303\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.1307393546223253\n",
      "-------------Round number:  707  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15347566670052365\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.131479314967328\n",
      "-------------Round number:  708  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.15239914232490295\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12952417309596764\n",
      "-------------Round number:  709  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.15156744188589066\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12776594620054058\n",
      "-------------Round number:  710  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.151871162874684\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.1290391761501501\n",
      "-------------Round number:  711  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.15164819388839043\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.12842144041381703\n",
      "-------------Round number:  712  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15261536636435197\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.12882034009697205\n",
      "-------------Round number:  713  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.1543957016966583\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.12888467057855948\n",
      "-------------Round number:  714  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.1570651246219303\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.1315739756674059\n",
      "-------------Round number:  715  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15598770753275665\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.13049946816314553\n",
      "-------------Round number:  716  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15273643375174928\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.1280179669513475\n",
      "-------------Round number:  717  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15250522094153462\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12921241768519773\n",
      "-------------Round number:  718  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15440238051657298\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.12979359625047965\n",
      "-------------Round number:  719  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15305871436552004\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12980419860156533\n",
      "-------------Round number:  720  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.1521201968924928\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12703381087556992\n",
      "-------------Round number:  721  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.1526353256760112\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.1267648836730318\n",
      "-------------Round number:  722  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15176269266742282\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.1281606578448052\n",
      "-------------Round number:  723  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15454094949807015\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1320938104840985\n",
      "-------------Round number:  724  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.15270903516048212\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12896363715395337\n",
      "-------------Round number:  725  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1582768455056259\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1347021872319655\n",
      "-------------Round number:  726  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15662879709648114\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13445493864126265\n",
      "-------------Round number:  727  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.1602612265011342\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13706993910326945\n",
      "-------------Round number:  728  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1585511179683268\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13537295676603692\n",
      "-------------Round number:  729  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15959499768291238\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13612807119912987\n",
      "-------------Round number:  730  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15758460676166372\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13334758809517763\n",
      "-------------Round number:  731  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15445249370824304\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13197359172563425\n",
      "-------------Round number:  732  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15430007113494268\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13070795535180232\n",
      "-------------Round number:  733  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15406079083928653\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13140526382705287\n",
      "-------------Round number:  734  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1593450158457758\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13640566102947815\n",
      "-------------Round number:  735  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15683490371566336\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13277227278434228\n",
      "-------------Round number:  736  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15687545054481536\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13265641840324802\n",
      "-------------Round number:  737  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15472384556487564\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1332648963694023\n",
      "-------------Round number:  738  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.1533500034915019\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13112046616135112\n",
      "-------------Round number:  739  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.15198174914370036\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12983862868970636\n",
      "-------------Round number:  740  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.15068927625750497\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.1290761080404704\n",
      "-------------Round number:  741  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.15135896571838886\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.13030292790648135\n",
      "-------------Round number:  742  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.15443767025480204\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13108155046313538\n",
      "-------------Round number:  743  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15622395701079472\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.1311420125193267\n",
      "-------------Round number:  744  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15795315418401837\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13126508575692938\n",
      "-------------Round number:  745  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.1549958586908067\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13142602768302525\n",
      "-------------Round number:  746  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15042826224423866\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.1286133297430819\n",
      "-------------Round number:  747  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15028205560234403\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9664138678223185\n",
      "Average Personal Trainning Loss:  0.12614039196869922\n",
      "-------------Round number:  748  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15182327595631884\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.1279247610437263\n",
      "-------------Round number:  749  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15058621743733636\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12777837806335207\n",
      "-------------Round number:  750  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15113392475496004\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.12832444322888453\n",
      "-------------Round number:  751  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15155463530381005\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12883118491346718\n",
      "-------------Round number:  752  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15052069667101164\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.12798928990610328\n",
      "-------------Round number:  753  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15416928308885766\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12774788252753702\n",
      "-------------Round number:  754  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15542741405615182\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1306123137689317\n",
      "-------------Round number:  755  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15692621398462892\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13185527962698063\n",
      "-------------Round number:  756  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.1546919062577589\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12850020860842137\n",
      "-------------Round number:  757  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1518762656694373\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.1266129901151702\n",
      "-------------Round number:  758  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.1540875722458751\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13161662753715805\n",
      "-------------Round number:  759  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15259518662959326\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1294324219808031\n",
      "-------------Round number:  760  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15301216100690682\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13010697177103084\n",
      "-------------Round number:  761  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15204326923076922\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1277900935510902\n",
      "-------------Round number:  762  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15821223949516408\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13395218661478084\n",
      "-------------Round number:  763  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15791884532858208\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13334556020266228\n",
      "-------------Round number:  764  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15705856703472035\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13444781897514896\n",
      "-------------Round number:  765  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15645288844192962\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13110468386742732\n",
      "-------------Round number:  766  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15461099995908947\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13192817354598343\n",
      "-------------Round number:  767  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15472280957630802\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13113027498927862\n",
      "-------------Round number:  768  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15729659091870937\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13186643303581505\n",
      "-------------Round number:  769  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.1541567079510315\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13067998366047648\n",
      "-------------Round number:  770  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15224802024788958\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.1290917580805345\n",
      "-------------Round number:  771  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.1520518216470296\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.12922989723698763\n",
      "-------------Round number:  772  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15118414815817985\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12860498672876602\n",
      "-------------Round number:  773  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15168636014806788\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12922329556515777\n",
      "-------------Round number:  774  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.1483888526219416\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12679000088521916\n",
      "-------------Round number:  775  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.14965464329194317\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12780396918520337\n",
      "-------------Round number:  776  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1515633309950851\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.1302212501269637\n",
      "-------------Round number:  777  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.15126629984736142\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12892040116298753\n",
      "-------------Round number:  778  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9576561935716865\n",
      "Average Global Trainning Loss:  0.14908975399371388\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12762768581138273\n",
      "-------------Round number:  779  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.14807947778064623\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12670477429379964\n",
      "-------------Round number:  780  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.15034391734521713\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12823401465231696\n",
      "-------------Round number:  781  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9580173347778982\n",
      "Average Global Trainning Loss:  0.1492001308607857\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.1286392184361175\n",
      "-------------Round number:  782  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9577464788732394\n",
      "Average Global Trainning Loss:  0.1507138424119436\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13054463285623194\n",
      "-------------Round number:  783  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.15003301056338028\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12900454768121952\n",
      "-------------Round number:  784  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.958197905381004\n",
      "Average Global Trainning Loss:  0.14876724193568866\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.1271202718363466\n",
      "-------------Round number:  785  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.14870990988751015\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.12736926176953547\n",
      "-------------Round number:  786  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9590104730949801\n",
      "Average Global Trainning Loss:  0.147479254659568\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12651557412634865\n",
      "-------------Round number:  787  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9587396171903214\n",
      "Average Global Trainning Loss:  0.14691270116693753\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9669555796316359\n",
      "Average Personal Trainning Loss:  0.12446776638396082\n",
      "-------------Round number:  788  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.14848967414765032\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12752682020105408\n",
      "-------------Round number:  789  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9574756229685807\n",
      "Average Global Trainning Loss:  0.14806142512879764\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.1258035634303618\n",
      "-------------Round number:  790  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15100370980893374\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12824634732473367\n",
      "-------------Round number:  791  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15357971742464\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.1302687292625948\n",
      "-------------Round number:  792  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15337466883633533\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.12833019627178133\n",
      "-------------Round number:  793  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.15719497586984246\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.12985414647591076\n",
      "-------------Round number:  794  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15577190229719665\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13215634451742506\n",
      "-------------Round number:  795  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15276634516635068\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1305425608790967\n",
      "-------------Round number:  796  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.14967207875911318\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12813501161717902\n",
      "-------------Round number:  797  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.14888667819214968\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.1293130959358918\n",
      "-------------Round number:  798  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.14864041048423957\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9662332972192127\n",
      "Average Personal Trainning Loss:  0.12670625112856626\n",
      "-------------Round number:  799  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15497359595775775\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13337527323647413\n",
      "---------------Running time:------------ 3\n",
      "Number of users / total users: 5  /  20\n",
      "Finished creating pFedMe server.\n",
      "-------------Round number:  0  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.06398488120950324\n",
      "Average Global Trainning Accurancy:  0.06780426146623329\n",
      "Average Global Trainning Loss:  2.57709606497156\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9378837125315999\n",
      "Average Personal Trainning Loss:  0.6573768469692353\n",
      "-------------Round number:  1  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.3539416846652268\n",
      "Average Global Trainning Accurancy:  0.3532863849765258\n",
      "Average Global Trainning Loss:  1.913668030821145\n",
      "Average Personal Accurancy:  0.8887688984881209\n",
      "Average Personal Trainning Accurancy:  0.900776453593355\n",
      "Average Personal Trainning Loss:  0.5717182262747156\n",
      "-------------Round number:  2  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7122030237580994\n",
      "Average Global Trainning Accurancy:  0.7163235825207657\n",
      "Average Global Trainning Loss:  0.999370912474043\n",
      "Average Personal Accurancy:  0.9203563714902808\n",
      "Average Personal Trainning Accurancy:  0.9321054532322138\n",
      "Average Personal Trainning Loss:  0.442410277218197\n",
      "-------------Round number:  3  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7945464362850972\n",
      "Average Global Trainning Accurancy:  0.8012820512820513\n",
      "Average Global Trainning Loss:  0.8058741697984381\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9346334416756952\n",
      "Average Personal Trainning Loss:  0.3791759156199215\n",
      "-------------Round number:  4  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8166846652267818\n",
      "Average Global Trainning Accurancy:  0.8187071144817624\n",
      "Average Global Trainning Loss:  0.7053083789697319\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9363488624052004\n",
      "Average Personal Trainning Loss:  0.3570670819790538\n",
      "-------------Round number:  5  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8139848812095032\n",
      "Average Global Trainning Accurancy:  0.8159985554351752\n",
      "Average Global Trainning Loss:  0.6413420363426553\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9332791621524016\n",
      "Average Personal Trainning Loss:  0.3334047945021894\n",
      "-------------Round number:  6  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8342332613390929\n",
      "Average Global Trainning Accurancy:  0.8330624774286746\n",
      "Average Global Trainning Loss:  0.5905345559938154\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9354460093896714\n",
      "Average Personal Trainning Loss:  0.3122548674710523\n",
      "-------------Round number:  7  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8226241900647948\n",
      "Average Global Trainning Accurancy:  0.8207836764174792\n",
      "Average Global Trainning Loss:  0.5849940009649242\n",
      "Average Personal Accurancy:  0.9227861771058316\n",
      "Average Personal Trainning Accurancy:  0.9326471650415312\n",
      "Average Personal Trainning Loss:  0.3075869674930593\n",
      "-------------Round number:  8  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8002159827213823\n",
      "Average Global Trainning Accurancy:  0.7970386421090646\n",
      "Average Global Trainning Loss:  0.6305823031639355\n",
      "Average Personal Accurancy:  0.9173866090712743\n",
      "Average Personal Trainning Accurancy:  0.9253340556157458\n",
      "Average Personal Trainning Loss:  0.3147113947456776\n",
      "-------------Round number:  9  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8053455723542117\n",
      "Average Global Trainning Accurancy:  0.8030877573131094\n",
      "Average Global Trainning Loss:  0.6039906367794105\n",
      "Average Personal Accurancy:  0.9163066954643628\n",
      "Average Personal Trainning Accurancy:  0.9239797760924522\n",
      "Average Personal Trainning Loss:  0.3188466863883622\n",
      "-------------Round number:  10  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8272138228941684\n",
      "Average Global Trainning Accurancy:  0.8341459010473095\n",
      "Average Global Trainning Loss:  0.5726668391256997\n",
      "Average Personal Accurancy:  0.9208963282937365\n",
      "Average Personal Trainning Accurancy:  0.9283134705669916\n",
      "Average Personal Trainning Loss:  0.32286707146928045\n",
      "-------------Round number:  11  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7926565874730022\n",
      "Average Global Trainning Accurancy:  0.7960455037919827\n",
      "Average Global Trainning Loss:  0.6362258398649107\n",
      "Average Personal Accurancy:  0.9154967602591793\n",
      "Average Personal Trainning Accurancy:  0.9216323582520766\n",
      "Average Personal Trainning Loss:  0.3385634885535166\n",
      "-------------Round number:  12  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8093952483801296\n",
      "Average Global Trainning Accurancy:  0.8120260021668473\n",
      "Average Global Trainning Loss:  0.5896494249954858\n",
      "Average Personal Accurancy:  0.9111771058315334\n",
      "Average Personal Trainning Accurancy:  0.9195557963163596\n",
      "Average Personal Trainning Loss:  0.32015236261821733\n",
      "-------------Round number:  13  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8415226781857451\n",
      "Average Global Trainning Accurancy:  0.8478692668833514\n",
      "Average Global Trainning Loss:  0.49665000973388407\n",
      "Average Personal Accurancy:  0.92170626349892\n",
      "Average Personal Trainning Accurancy:  0.9281328999638859\n",
      "Average Personal Trainning Loss:  0.2892493967460613\n",
      "-------------Round number:  14  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8420626349892009\n",
      "Average Global Trainning Accurancy:  0.8452509931383171\n",
      "Average Global Trainning Loss:  0.4877181571500316\n",
      "Average Personal Accurancy:  0.9214362850971922\n",
      "Average Personal Trainning Accurancy:  0.9288551823763092\n",
      "Average Personal Trainning Loss:  0.2836554552424725\n",
      "-------------Round number:  15  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8776997840172787\n",
      "Average Global Trainning Accurancy:  0.8856085229324666\n",
      "Average Global Trainning Loss:  0.3953604817002979\n",
      "Average Personal Accurancy:  0.9235961123110151\n",
      "Average Personal Trainning Accurancy:  0.9333694474539544\n",
      "Average Personal Trainning Loss:  0.27026087250163644\n",
      "-------------Round number:  16  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8822894168466523\n",
      "Average Global Trainning Accurancy:  0.8887685084868183\n",
      "Average Global Trainning Loss:  0.3933766738048483\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.933820873961719\n",
      "Average Personal Trainning Loss:  0.26604036528868724\n",
      "-------------Round number:  17  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8820194384449244\n",
      "Average Global Trainning Accurancy:  0.8875947995666306\n",
      "Average Global Trainning Loss:  0.39523554588750454\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9347237269772481\n",
      "Average Personal Trainning Loss:  0.2640749627220454\n",
      "-------------Round number:  18  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8866090712742981\n",
      "Average Global Trainning Accurancy:  0.894998194293969\n",
      "Average Global Trainning Loss:  0.38296260813075567\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9378837125315999\n",
      "Average Personal Trainning Loss:  0.2609394661740475\n",
      "-------------Round number:  19  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8830993520518359\n",
      "Average Global Trainning Accurancy:  0.8919284940411701\n",
      "Average Global Trainning Loss:  0.3709573962706528\n",
      "Average Personal Accurancy:  0.9195464362850972\n",
      "Average Personal Trainning Accurancy:  0.9330985915492958\n",
      "Average Personal Trainning Loss:  0.2634061108689396\n",
      "-------------Round number:  20  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8909287257019438\n",
      "Average Global Trainning Accurancy:  0.9010473094980137\n",
      "Average Global Trainning Loss:  0.3427877209168472\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9399602744673167\n",
      "Average Personal Trainning Loss:  0.2462108167081415\n",
      "-------------Round number:  21  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8957883369330454\n",
      "Average Global Trainning Accurancy:  0.903665583243048\n",
      "Average Global Trainning Loss:  0.3378962457890371\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9413145539906104\n",
      "Average Personal Trainning Loss:  0.23963330324998872\n",
      "-------------Round number:  22  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.896328293736501\n",
      "Average Global Trainning Accurancy:  0.9045684362585771\n",
      "Average Global Trainning Loss:  0.34171187985283497\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9415854098952691\n",
      "Average Personal Trainning Loss:  0.2419353800587983\n",
      "-------------Round number:  23  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8936285097192225\n",
      "Average Global Trainning Accurancy:  0.9016793066088841\n",
      "Average Global Trainning Loss:  0.3465023130318369\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9416756951968219\n",
      "Average Personal Trainning Loss:  0.23752228918382087\n",
      "-------------Round number:  24  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8903887688984882\n",
      "Average Global Trainning Accurancy:  0.9014084507042254\n",
      "Average Global Trainning Loss:  0.3486994243606672\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9413145539906104\n",
      "Average Personal Trainning Loss:  0.23836406295848006\n",
      "-------------Round number:  25  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8984881209503239\n",
      "Average Global Trainning Accurancy:  0.9047490068616829\n",
      "Average Global Trainning Loss:  0.3299470393827307\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.942668833513904\n",
      "Average Personal Trainning Loss:  0.23285172208632404\n",
      "-------------Round number:  26  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8863390928725702\n",
      "Average Global Trainning Accurancy:  0.8923799205489347\n",
      "Average Global Trainning Loss:  0.354298193130135\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9386059949440231\n",
      "Average Personal Trainning Loss:  0.23893643562093717\n",
      "-------------Round number:  27  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8801295896328294\n",
      "Average Global Trainning Accurancy:  0.8912964969302998\n",
      "Average Global Trainning Loss:  0.3503864325526476\n",
      "Average Personal Accurancy:  0.9225161987041036\n",
      "Average Personal Trainning Accurancy:  0.9369808595160708\n",
      "Average Personal Trainning Loss:  0.2393215147757539\n",
      "-------------Round number:  28  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8828293736501079\n",
      "Average Global Trainning Accurancy:  0.8957204767063922\n",
      "Average Global Trainning Loss:  0.3398840433425876\n",
      "Average Personal Accurancy:  0.9187365010799136\n",
      "Average Personal Trainning Accurancy:  0.9367100036114121\n",
      "Average Personal Trainning Loss:  0.23984155899439102\n",
      "-------------Round number:  29  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8960583153347732\n",
      "Average Global Trainning Accurancy:  0.9059227157818707\n",
      "Average Global Trainning Loss:  0.3170765346032525\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9417659804983749\n",
      "Average Personal Trainning Loss:  0.22870739309656013\n",
      "-------------Round number:  30  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.896328293736501\n",
      "Average Global Trainning Accurancy:  0.905651859877212\n",
      "Average Global Trainning Loss:  0.3275296592505756\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9417659804983749\n",
      "Average Personal Trainning Loss:  0.23427770524388317\n",
      "-------------Round number:  31  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9028077753779697\n",
      "Average Global Trainning Accurancy:  0.9089924160346695\n",
      "Average Global Trainning Loss:  0.3299737546623894\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9369808595160708\n",
      "Average Personal Trainning Loss:  0.24655681484741784\n",
      "-------------Round number:  32  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8995680345572354\n",
      "Average Global Trainning Accurancy:  0.9050198627663416\n",
      "Average Global Trainning Loss:  0.3298847257725036\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9386059949440231\n",
      "Average Personal Trainning Loss:  0.23884950075049657\n",
      "-------------Round number:  33  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8890388768898488\n",
      "Average Global Trainning Accurancy:  0.895901047309498\n",
      "Average Global Trainning Loss:  0.35332489289200747\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.9350848681834597\n",
      "Average Personal Trainning Loss:  0.2530469966735509\n",
      "-------------Round number:  34  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8817494600431965\n",
      "Average Global Trainning Accurancy:  0.890032502708559\n",
      "Average Global Trainning Loss:  0.37348988134536387\n",
      "Average Personal Accurancy:  0.92170626349892\n",
      "Average Personal Trainning Accurancy:  0.9321957385337667\n",
      "Average Personal Trainning Loss:  0.25825700522244044\n",
      "-------------Round number:  35  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8803995680345572\n",
      "Average Global Trainning Accurancy:  0.8887685084868183\n",
      "Average Global Trainning Loss:  0.376426049284489\n",
      "Average Personal Accurancy:  0.9230561555075594\n",
      "Average Personal Trainning Accurancy:  0.9341820151679306\n",
      "Average Personal Trainning Loss:  0.2543798951561936\n",
      "-------------Round number:  36  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8941684665226782\n",
      "Average Global Trainning Accurancy:  0.9077284218129289\n",
      "Average Global Trainning Loss:  0.32251282950608295\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9427591188154568\n",
      "Average Personal Trainning Loss:  0.2301987978300492\n",
      "-------------Round number:  37  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8930885529157667\n",
      "Average Global Trainning Accurancy:  0.9061935716865295\n",
      "Average Global Trainning Loss:  0.32017328077035934\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9419465511014807\n",
      "Average Personal Trainning Loss:  0.22640637431862812\n",
      "-------------Round number:  38  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8928185745140389\n",
      "Average Global Trainning Accurancy:  0.9051101480678946\n",
      "Average Global Trainning Loss:  0.3181269167992732\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9428494041170098\n",
      "Average Personal Trainning Loss:  0.22200289389078864\n",
      "-------------Round number:  39  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8971382289416847\n",
      "Average Global Trainning Accurancy:  0.9128746840014446\n",
      "Average Global Trainning Loss:  0.32432876316895765\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9416756951968219\n",
      "Average Personal Trainning Loss:  0.23337729892475848\n",
      "-------------Round number:  40  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8941684665226782\n",
      "Average Global Trainning Accurancy:  0.9063741422896352\n",
      "Average Global Trainning Loss:  0.3352092220792705\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.94068255687974\n",
      "Average Personal Trainning Loss:  0.23776426966244582\n",
      "-------------Round number:  41  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8785097192224622\n",
      "Average Global Trainning Accurancy:  0.8971650415312387\n",
      "Average Global Trainning Loss:  0.347784866878555\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9389671361502347\n",
      "Average Personal Trainning Loss:  0.23868665216459012\n",
      "-------------Round number:  42  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8782397408207343\n",
      "Average Global Trainning Accurancy:  0.8971650415312387\n",
      "Average Global Trainning Loss:  0.34424035322713525\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.94068255687974\n",
      "Average Personal Trainning Loss:  0.23093681845177635\n",
      "-------------Round number:  43  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8901187904967602\n",
      "Average Global Trainning Accurancy:  0.9072769953051644\n",
      "Average Global Trainning Loss:  0.3260259989927546\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9436619718309859\n",
      "Average Personal Trainning Loss:  0.22237922224855544\n",
      "-------------Round number:  44  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8895788336933045\n",
      "Average Global Trainning Accurancy:  0.9030335861321777\n",
      "Average Global Trainning Loss:  0.3315061360500745\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9433911159263272\n",
      "Average Personal Trainning Loss:  0.22423417080004063\n",
      "-------------Round number:  45  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8911987041036717\n",
      "Average Global Trainning Accurancy:  0.9041170097508126\n",
      "Average Global Trainning Loss:  0.32129598378532415\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9443842542434092\n",
      "Average Personal Trainning Loss:  0.2182845986677275\n",
      "-------------Round number:  46  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8895788336933045\n",
      "Average Global Trainning Accurancy:  0.9020404478150957\n",
      "Average Global Trainning Loss:  0.3297530229705557\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.943571686529433\n",
      "Average Personal Trainning Loss:  0.22162224524027177\n",
      "-------------Round number:  47  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8830993520518359\n",
      "Average Global Trainning Accurancy:  0.8977067533405562\n",
      "Average Global Trainning Loss:  0.3356531762439622\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9423979776092453\n",
      "Average Personal Trainning Loss:  0.2251838857665222\n",
      "-------------Round number:  48  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8930885529157667\n",
      "Average Global Trainning Accurancy:  0.905651859877212\n",
      "Average Global Trainning Loss:  0.3243255009070851\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9440231130371975\n",
      "Average Personal Trainning Loss:  0.22029351275420955\n",
      "-------------Round number:  49  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8828293736501079\n",
      "Average Global Trainning Accurancy:  0.8947273383893102\n",
      "Average Global Trainning Loss:  0.35777014349720115\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9372517154207295\n",
      "Average Personal Trainning Loss:  0.23979180950083515\n",
      "-------------Round number:  50  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8801295896328294\n",
      "Average Global Trainning Accurancy:  0.8929216323582521\n",
      "Average Global Trainning Loss:  0.36547415124763\n",
      "Average Personal Accurancy:  0.9235961123110151\n",
      "Average Personal Trainning Accurancy:  0.9345431563741423\n",
      "Average Personal Trainning Loss:  0.24860703622274513\n",
      "-------------Round number:  51  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8855291576673866\n",
      "Average Global Trainning Accurancy:  0.8974358974358975\n",
      "Average Global Trainning Loss:  0.3552868127736773\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9387865655471289\n",
      "Average Personal Trainning Loss:  0.240013334715827\n",
      "-------------Round number:  52  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8901187904967602\n",
      "Average Global Trainning Accurancy:  0.9068255687973997\n",
      "Average Global Trainning Loss:  0.3302567779221402\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.942578548212351\n",
      "Average Personal Trainning Loss:  0.22479541209597328\n",
      "-------------Round number:  53  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9103671706263499\n",
      "Average Global Trainning Accurancy:  0.9259660527266161\n",
      "Average Global Trainning Loss:  0.27844529239741334\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9446551101480679\n",
      "Average Personal Trainning Loss:  0.21563879407756636\n",
      "-------------Round number:  54  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9068574514038877\n",
      "Average Global Trainning Accurancy:  0.9212712170458649\n",
      "Average Global Trainning Loss:  0.28779023991202823\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9422174070061394\n",
      "Average Personal Trainning Loss:  0.22095517881427185\n",
      "-------------Round number:  55  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9098272138228942\n",
      "Average Global Trainning Accurancy:  0.926056338028169\n",
      "Average Global Trainning Loss:  0.27317442503075345\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.943571686529433\n",
      "Average Personal Trainning Loss:  0.21429855550571056\n",
      "-------------Round number:  56  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9071274298056156\n",
      "Average Global Trainning Accurancy:  0.9232574936800289\n",
      "Average Global Trainning Loss:  0.2746938896248081\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9451968219573853\n",
      "Average Personal Trainning Loss:  0.21391711333203547\n",
      "-------------Round number:  57  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.918291802094619\n",
      "Average Global Trainning Loss:  0.29344733263362227\n",
      "Average Personal Accurancy:  0.9252159827213823\n",
      "Average Personal Trainning Accurancy:  0.9424882629107981\n",
      "Average Personal Trainning Loss:  0.22185210244842452\n",
      "-------------Round number:  58  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9068574514038877\n",
      "Average Global Trainning Accurancy:  0.9218129288551824\n",
      "Average Global Trainning Loss:  0.28421217786486547\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9449259660527266\n",
      "Average Personal Trainning Loss:  0.21581381001856492\n",
      "-------------Round number:  59  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9282231852654388\n",
      "Average Global Trainning Loss:  0.26543049865700613\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9442036836403034\n",
      "Average Personal Trainning Loss:  0.2133869737354415\n",
      "-------------Round number:  60  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9300288912964969\n",
      "Average Global Trainning Loss:  0.2635010250555819\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9454676778620441\n",
      "Average Personal Trainning Loss:  0.20835722719731853\n",
      "-------------Round number:  61  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9303900325027086\n",
      "Average Global Trainning Loss:  0.25963621459828684\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9458288190682557\n",
      "Average Personal Trainning Loss:  0.205894682372077\n",
      "-------------Round number:  62  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.928945467677862\n",
      "Average Global Trainning Loss:  0.25793320368928313\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9460996749729144\n",
      "Average Personal Trainning Loss:  0.20501453293579586\n",
      "-------------Round number:  63  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9288551823763092\n",
      "Average Global Trainning Loss:  0.2597737365700614\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9466413867822319\n",
      "Average Personal Trainning Loss:  0.20648089760518237\n",
      "-------------Round number:  64  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9291260382809678\n",
      "Average Global Trainning Loss:  0.26086119393141705\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9474539544962081\n",
      "Average Personal Trainning Loss:  0.20439223444130328\n",
      "-------------Round number:  65  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9114470842332614\n",
      "Average Global Trainning Accurancy:  0.9293968941856265\n",
      "Average Global Trainning Loss:  0.2583771578539748\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9461899602744673\n",
      "Average Personal Trainning Loss:  0.20272158164330534\n",
      "-------------Round number:  66  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.24906351041948807\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.19472566758221604\n",
      "-------------Round number:  67  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9283134705669916\n",
      "Average Global Trainning Loss:  0.2566940731931654\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.20016694404709506\n",
      "-------------Round number:  68  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9271397616468039\n",
      "Average Global Trainning Loss:  0.2584233364933189\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9467316720837847\n",
      "Average Personal Trainning Loss:  0.20199616922286925\n",
      "-------------Round number:  69  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9248826291079812\n",
      "Average Global Trainning Loss:  0.2669597059520585\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.20184196122246298\n",
      "-------------Round number:  70  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9095572354211663\n",
      "Average Global Trainning Accurancy:  0.9209100758396533\n",
      "Average Global Trainning Loss:  0.2762091441376625\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9456482484651498\n",
      "Average Personal Trainning Loss:  0.207796801466854\n",
      "-------------Round number:  71  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9028077753779697\n",
      "Average Global Trainning Accurancy:  0.9164860960635609\n",
      "Average Global Trainning Loss:  0.2865591328167321\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9442036836403034\n",
      "Average Personal Trainning Loss:  0.21022119105357304\n",
      "-------------Round number:  72  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9073974082073434\n",
      "Average Global Trainning Accurancy:  0.9232574936800289\n",
      "Average Global Trainning Loss:  0.2752118398240001\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9473636691946551\n",
      "Average Personal Trainning Loss:  0.20497635565496344\n",
      "-------------Round number:  73  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9065874730021598\n",
      "Average Global Trainning Accurancy:  0.9236186348862405\n",
      "Average Global Trainning Loss:  0.2698510839173664\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9483568075117371\n",
      "Average Personal Trainning Loss:  0.19923726554035753\n",
      "-------------Round number:  74  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9284940411700975\n",
      "Average Global Trainning Loss:  0.2507619806126422\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.1986003750366784\n",
      "-------------Round number:  75  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9308414590104731\n",
      "Average Global Trainning Loss:  0.24781893547281283\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.949440231130372\n",
      "Average Personal Trainning Loss:  0.19405655122139084\n",
      "-------------Round number:  76  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.24192462341154297\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9495305164319249\n",
      "Average Personal Trainning Loss:  0.19166319720708064\n",
      "-------------Round number:  77  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9322860238353196\n",
      "Average Global Trainning Loss:  0.2425919543452623\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9499819429396894\n",
      "Average Personal Trainning Loss:  0.19045922419533226\n",
      "-------------Round number:  78  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.2403431537996005\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9486276634163958\n",
      "Average Personal Trainning Loss:  0.19106144214546092\n",
      "-------------Round number:  79  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9311123149151318\n",
      "Average Global Trainning Loss:  0.24139086887611727\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.949349945828819\n",
      "Average Personal Trainning Loss:  0.19161719490621615\n",
      "-------------Round number:  80  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.934814012278801\n",
      "Average Global Trainning Loss:  0.23618928048962848\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9491693752257132\n",
      "Average Personal Trainning Loss:  0.18918663347271128\n",
      "-------------Round number:  81  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9331888768508487\n",
      "Average Global Trainning Loss:  0.238703272066292\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9487179487179487\n",
      "Average Personal Trainning Loss:  0.19007194080952058\n",
      "-------------Round number:  82  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9300288912964969\n",
      "Average Global Trainning Loss:  0.24376173973427906\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.19239116653547084\n",
      "-------------Round number:  83  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9301191765980499\n",
      "Average Global Trainning Loss:  0.24681180028891297\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.19513748405900144\n",
      "-------------Round number:  84  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9307511737089202\n",
      "Average Global Trainning Loss:  0.248096139562737\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9496208017334777\n",
      "Average Personal Trainning Loss:  0.192848434255372\n",
      "-------------Round number:  85  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9313831708197905\n",
      "Average Global Trainning Loss:  0.24867003314458064\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9505236547490069\n",
      "Average Personal Trainning Loss:  0.19026359869453097\n",
      "-------------Round number:  86  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9114470842332614\n",
      "Average Global Trainning Accurancy:  0.9278620440592271\n",
      "Average Global Trainning Loss:  0.2558638936735396\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.1979012150073921\n",
      "-------------Round number:  87  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9065874730021598\n",
      "Average Global Trainning Accurancy:  0.9239797760924522\n",
      "Average Global Trainning Loss:  0.26405031941952195\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9479053810039726\n",
      "Average Personal Trainning Loss:  0.19758772927529117\n",
      "-------------Round number:  88  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.910097192224622\n",
      "Average Global Trainning Accurancy:  0.9250631997110871\n",
      "Average Global Trainning Loss:  0.2532138349175582\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9482665222101841\n",
      "Average Personal Trainning Loss:  0.19229263740999683\n",
      "-------------Round number:  89  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.928945467677862\n",
      "Average Global Trainning Loss:  0.25112023427625046\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.19139886582616694\n",
      "-------------Round number:  90  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9326471650415312\n",
      "Average Global Trainning Loss:  0.23565288087700884\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.948537378114843\n",
      "Average Personal Trainning Loss:  0.19064786228387956\n",
      "-------------Round number:  91  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9323763091368725\n",
      "Average Global Trainning Loss:  0.2345703609930819\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9474539544962081\n",
      "Average Personal Trainning Loss:  0.18956018449942444\n",
      "-------------Round number:  92  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9273203322499097\n",
      "Average Global Trainning Loss:  0.24184507271493544\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9481762369086313\n",
      "Average Personal Trainning Loss:  0.19155040670706933\n",
      "-------------Round number:  93  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9266883351390394\n",
      "Average Global Trainning Loss:  0.24798910210562253\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9460093896713615\n",
      "Average Personal Trainning Loss:  0.19336373937736998\n",
      "-------------Round number:  94  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.910097192224622\n",
      "Average Global Trainning Accurancy:  0.9251534850126399\n",
      "Average Global Trainning Loss:  0.2543234007157932\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9461899602744673\n",
      "Average Personal Trainning Loss:  0.19663067421959643\n",
      "-------------Round number:  95  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9241603466955579\n",
      "Average Global Trainning Loss:  0.2580828489315299\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9462802455760202\n",
      "Average Personal Trainning Loss:  0.19871091722107484\n",
      "-------------Round number:  96  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.929938605994944\n",
      "Average Global Trainning Loss:  0.24833911194530967\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9470025279884435\n",
      "Average Personal Trainning Loss:  0.19610943971622202\n",
      "-------------Round number:  97  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9292163235825208\n",
      "Average Global Trainning Loss:  0.24511064093394502\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.1926777826917434\n",
      "-------------Round number:  98  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9071274298056156\n",
      "Average Global Trainning Accurancy:  0.9229866377753702\n",
      "Average Global Trainning Loss:  0.255955721936789\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9450162513542795\n",
      "Average Personal Trainning Loss:  0.19794997259700028\n",
      "-------------Round number:  99  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9095572354211663\n",
      "Average Global Trainning Accurancy:  0.9268689057421452\n",
      "Average Global Trainning Loss:  0.2537229681927704\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9456482484651498\n",
      "Average Personal Trainning Loss:  0.19938768226345252\n",
      "-------------Round number:  100  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9052375809935205\n",
      "Average Global Trainning Accurancy:  0.9256049115204045\n",
      "Average Global Trainning Loss:  0.25178317879028983\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9448356807511737\n",
      "Average Personal Trainning Loss:  0.19898311770664048\n",
      "-------------Round number:  101  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.902267818574514\n",
      "Average Global Trainning Accurancy:  0.9244312026002167\n",
      "Average Global Trainning Loss:  0.25595730898310537\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.943571686529433\n",
      "Average Personal Trainning Loss:  0.19963786248137866\n",
      "-------------Round number:  102  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9038876889848813\n",
      "Average Global Trainning Accurancy:  0.9235283495846877\n",
      "Average Global Trainning Loss:  0.25477932385478735\n",
      "Average Personal Accurancy:  0.9233261339092873\n",
      "Average Personal Trainning Accurancy:  0.9429396894185627\n",
      "Average Personal Trainning Loss:  0.20208101007386467\n",
      "-------------Round number:  103  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.931834597327555\n",
      "Average Global Trainning Loss:  0.23421781628775054\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.18789043543613443\n",
      "-------------Round number:  104  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9323763091368725\n",
      "Average Global Trainning Loss:  0.23421781628775054\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.18663968864267336\n",
      "-------------Round number:  105  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9325568797399784\n",
      "Average Global Trainning Loss:  0.2328331183767267\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.18844224262340872\n",
      "-------------Round number:  106  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9292163235825208\n",
      "Average Global Trainning Loss:  0.23979302182788237\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.1895729249545752\n",
      "-------------Round number:  107  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.930931744312026\n",
      "Average Global Trainning Loss:  0.23755918801067624\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9472733838931022\n",
      "Average Personal Trainning Loss:  0.1912310356782119\n",
      "-------------Round number:  108  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.910097192224622\n",
      "Average Global Trainning Accurancy:  0.9293968941856265\n",
      "Average Global Trainning Loss:  0.2427824219455354\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9463705308775732\n",
      "Average Personal Trainning Loss:  0.1947398628298235\n",
      "-------------Round number:  109  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9312928855182376\n",
      "Average Global Trainning Loss:  0.24100373978647527\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.1925020834391364\n",
      "-------------Round number:  110  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9320151679306609\n",
      "Average Global Trainning Loss:  0.23688753678420685\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.19173110956403486\n",
      "-------------Round number:  111  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.9295774647887324\n",
      "Average Global Trainning Loss:  0.2395966468885428\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9466413867822319\n",
      "Average Personal Trainning Loss:  0.1936490770796655\n",
      "-------------Round number:  112  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9321957385337667\n",
      "Average Global Trainning Loss:  0.23045997716064012\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9499819429396894\n",
      "Average Personal Trainning Loss:  0.18495354010078097\n",
      "-------------Round number:  113  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9304803178042614\n",
      "Average Global Trainning Loss:  0.23170794662304758\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.1854976986065028\n",
      "-------------Round number:  114  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.933911159263272\n",
      "Average Global Trainning Loss:  0.22426882131128115\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9502527988443481\n",
      "Average Personal Trainning Loss:  0.1801630518160042\n",
      "-------------Round number:  115  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9353557240881184\n",
      "Average Global Trainning Loss:  0.2257356047845567\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9502527988443481\n",
      "Average Personal Trainning Loss:  0.18019480376348637\n",
      "-------------Round number:  116  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9356265799927772\n",
      "Average Global Trainning Loss:  0.2255705078830354\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.17920747359507608\n",
      "-------------Round number:  117  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9355362946912242\n",
      "Average Global Trainning Loss:  0.22474118801349766\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.176859383464247\n",
      "-------------Round number:  118  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.935807150595883\n",
      "Average Global Trainning Loss:  0.22362481114148836\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.1776992836425605\n",
      "-------------Round number:  119  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9335500180570603\n",
      "Average Global Trainning Loss:  0.22677430455630418\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17830011292716233\n",
      "-------------Round number:  120  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9369808595160708\n",
      "Average Global Trainning Loss:  0.2223104502415132\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.1788838924850183\n",
      "-------------Round number:  121  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.22222109071697815\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.17626296264163507\n",
      "-------------Round number:  122  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9373420007222825\n",
      "Average Global Trainning Loss:  0.21810810589196236\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.1762188670005812\n",
      "-------------Round number:  123  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9351751534850127\n",
      "Average Global Trainning Loss:  0.22008223721334416\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9511556518598772\n",
      "Average Personal Trainning Loss:  0.17700798169677118\n",
      "-------------Round number:  124  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.22466798550215555\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9507042253521126\n",
      "Average Personal Trainning Loss:  0.1797923883318944\n",
      "-------------Round number:  125  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9333694474539544\n",
      "Average Global Trainning Loss:  0.23069201655747787\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9491693752257132\n",
      "Average Personal Trainning Loss:  0.18407939719396105\n",
      "-------------Round number:  126  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.935807150595883\n",
      "Average Global Trainning Loss:  0.22686172435756366\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9506139400505598\n",
      "Average Personal Trainning Loss:  0.18015916134829812\n",
      "-------------Round number:  127  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.931834597327555\n",
      "Average Global Trainning Loss:  0.23575976403795368\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.1882717894405697\n",
      "-------------Round number:  128  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9320151679306609\n",
      "Average Global Trainning Loss:  0.2339002747706189\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9496208017334777\n",
      "Average Personal Trainning Loss:  0.18556638244430526\n",
      "-------------Round number:  129  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9313831708197905\n",
      "Average Global Trainning Loss:  0.23560161046406644\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.18599832355007448\n",
      "-------------Round number:  130  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9343625857710365\n",
      "Average Global Trainning Loss:  0.22869194143728558\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9496208017334777\n",
      "Average Personal Trainning Loss:  0.1823398180927512\n",
      "-------------Round number:  131  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9349042975803539\n",
      "Average Global Trainning Loss:  0.22590486768265844\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.17816972164265643\n",
      "-------------Round number:  132  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9342723004694836\n",
      "Average Global Trainning Loss:  0.22738875598845476\n",
      "Average Personal Accurancy:  0.9357451403887689\n",
      "Average Personal Trainning Accurancy:  0.9507042253521126\n",
      "Average Personal Trainning Loss:  0.17987323952478895\n",
      "-------------Round number:  133  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.2267683531326178\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.1780937418002607\n",
      "-------------Round number:  134  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9329180209461899\n",
      "Average Global Trainning Loss:  0.23516933872364798\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9496208017334777\n",
      "Average Personal Trainning Loss:  0.18382877612983592\n",
      "-------------Round number:  135  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9384254243409172\n",
      "Average Global Trainning Loss:  0.2198637538371253\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17685846870838412\n",
      "-------------Round number:  136  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9370711448176237\n",
      "Average Global Trainning Loss:  0.22076524022943753\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.17536610513441225\n",
      "-------------Round number:  137  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9362585771036476\n",
      "Average Global Trainning Loss:  0.22601695282875137\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.1798529495784805\n",
      "-------------Round number:  138  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.935807150595883\n",
      "Average Global Trainning Loss:  0.22561844990717542\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17822614995612698\n",
      "-------------Round number:  139  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9379739978331527\n",
      "Average Global Trainning Loss:  0.21866275653722012\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17844571340553336\n",
      "-------------Round number:  140  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9362585771036476\n",
      "Average Global Trainning Loss:  0.22120258170114437\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17532670450537763\n",
      "-------------Round number:  141  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9369808595160708\n",
      "Average Global Trainning Loss:  0.21616461338141027\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.17450915522935287\n",
      "-------------Round number:  142  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9360780065005417\n",
      "Average Global Trainning Loss:  0.22077965590014445\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.1814019398467125\n",
      "-------------Round number:  143  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9389671361502347\n",
      "Average Global Trainning Loss:  0.21767980176733479\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.17706283398508035\n",
      "-------------Round number:  144  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9371614301191766\n",
      "Average Global Trainning Loss:  0.22546503542992732\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.18328481600490362\n",
      "-------------Round number:  145  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9321054532322138\n",
      "Average Global Trainning Loss:  0.2363874628983839\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9469122426868906\n",
      "Average Personal Trainning Loss:  0.1926547264355363\n",
      "-------------Round number:  146  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.933911159263272\n",
      "Average Global Trainning Loss:  0.22926118409172985\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.18803276263147797\n",
      "-------------Round number:  147  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.931924882629108\n",
      "Average Global Trainning Loss:  0.2320673024021533\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.18926201817273836\n",
      "-------------Round number:  148  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9351751534850127\n",
      "Average Global Trainning Loss:  0.22232603415464744\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.1843699479025596\n",
      "-------------Round number:  149  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9332791621524016\n",
      "Average Global Trainning Loss:  0.22951857214500948\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9482665222101841\n",
      "Average Personal Trainning Loss:  0.1878029495079451\n",
      "-------------Round number:  150  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9314734561213435\n",
      "Average Global Trainning Loss:  0.2318212440961877\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9473636691946551\n",
      "Average Personal Trainning Loss:  0.18857180732129153\n",
      "-------------Round number:  151  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9092872570194385\n",
      "Average Global Trainning Accurancy:  0.928945467677862\n",
      "Average Global Trainning Loss:  0.24007262852959102\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9440231130371975\n",
      "Average Personal Trainning Loss:  0.19448221026882448\n",
      "-------------Round number:  152  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9079373650107991\n",
      "Average Global Trainning Accurancy:  0.9272300469483568\n",
      "Average Global Trainning Loss:  0.24463316041582026\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9457385337667028\n",
      "Average Personal Trainning Loss:  0.19528860613601481\n",
      "-------------Round number:  153  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906047516198704\n",
      "Average Global Trainning Accurancy:  0.9252437703141928\n",
      "Average Global Trainning Loss:  0.24836670891736637\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9433911159263272\n",
      "Average Personal Trainning Loss:  0.19813481940823627\n",
      "-------------Round number:  154  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9046976241900648\n",
      "Average Global Trainning Accurancy:  0.9233477789815818\n",
      "Average Global Trainning Loss:  0.2529848373594935\n",
      "Average Personal Accurancy:  0.9200863930885529\n",
      "Average Personal Trainning Accurancy:  0.9408631274828458\n",
      "Average Personal Trainning Loss:  0.20499143259496885\n",
      "-------------Round number:  155  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9036177105831533\n",
      "Average Global Trainning Accurancy:  0.9216323582520766\n",
      "Average Global Trainning Loss:  0.26290577247539726\n",
      "Average Personal Accurancy:  0.92170626349892\n",
      "Average Personal Trainning Accurancy:  0.9403214156735283\n",
      "Average Personal Trainning Loss:  0.20830533959969755\n",
      "-------------Round number:  156  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9266883351390394\n",
      "Average Global Trainning Loss:  0.24478199009259885\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9430299747201155\n",
      "Average Personal Trainning Loss:  0.19935195167902447\n",
      "-------------Round number:  157  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9279523293607801\n",
      "Average Global Trainning Loss:  0.24047498885540808\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9438425424340917\n",
      "Average Personal Trainning Loss:  0.19606916841594438\n",
      "-------------Round number:  158  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.2268141790950027\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.18659917487698627\n",
      "-------------Round number:  159  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9310220296135789\n",
      "Average Global Trainning Loss:  0.23564895734583785\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9457385337667028\n",
      "Average Personal Trainning Loss:  0.19230454025736954\n",
      "-------------Round number:  160  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9369808595160708\n",
      "Average Global Trainning Loss:  0.2217714937209394\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.18456705023812747\n",
      "-------------Round number:  161  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9392379920548934\n",
      "Average Global Trainning Loss:  0.2160750554760857\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.1799980430837227\n",
      "-------------Round number:  162  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9368905742145178\n",
      "Average Global Trainning Loss:  0.21859565974573403\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9501625135427952\n",
      "Average Personal Trainning Loss:  0.1811138468556733\n",
      "-------------Round number:  163  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9344528710725893\n",
      "Average Global Trainning Loss:  0.22419802141172354\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.18496550907508352\n",
      "-------------Round number:  164  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9365294330083063\n",
      "Average Global Trainning Loss:  0.2203470314827668\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9487179487179487\n",
      "Average Personal Trainning Loss:  0.18272009202399897\n",
      "-------------Round number:  165  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9380642831347057\n",
      "Average Global Trainning Loss:  0.21728041715336088\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.1786346049806451\n",
      "-------------Round number:  166  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9365294330083063\n",
      "Average Global Trainning Loss:  0.22105242948576878\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9492596605272662\n",
      "Average Personal Trainning Loss:  0.18314302884615385\n",
      "-------------Round number:  167  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9389671361502347\n",
      "Average Global Trainning Loss:  0.21401736175768554\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9503430841459011\n",
      "Average Personal Trainning Loss:  0.17876541506904003\n",
      "-------------Round number:  168  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9394185626579993\n",
      "Average Global Trainning Loss:  0.20985542096227203\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9520585048754063\n",
      "Average Personal Trainning Loss:  0.1731082672416712\n",
      "-------------Round number:  169  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.20970656924318345\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.1726909512085534\n",
      "-------------Round number:  170  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.20615976319152898\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.17197651585847215\n",
      "-------------Round number:  171  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20775816129751265\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.17106583782291102\n",
      "-------------Round number:  172  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.21073387314068706\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.17043430360054962\n",
      "-------------Round number:  173  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9409534127843987\n",
      "Average Global Trainning Loss:  0.20699831878893554\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.1677541240280223\n",
      "-------------Round number:  174  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.20581495533698987\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16882107101997\n",
      "-------------Round number:  175  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9401408450704225\n",
      "Average Global Trainning Loss:  0.20780114380191406\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.1688214126757742\n",
      "-------------Round number:  176  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.20762233658360418\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.1719278795015687\n",
      "-------------Round number:  177  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.20560379000767426\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16841227433964767\n",
      "-------------Round number:  178  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.20547517312911925\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.17159263800954766\n",
      "-------------Round number:  179  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.2033156439387527\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.17118167016169533\n",
      "-------------Round number:  180  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.20452239428155472\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.16843288389945038\n",
      "-------------Round number:  181  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.20393750158704632\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16781826714997516\n",
      "-------------Round number:  182  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.20039755069378612\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16841493043799657\n",
      "-------------Round number:  183  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.1996579430257426\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16543096374974608\n",
      "-------------Round number:  184  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.20019844250801283\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16489017771744652\n",
      "-------------Round number:  185  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.942578548212351\n",
      "Average Global Trainning Loss:  0.2014711213998736\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.166871858529986\n",
      "-------------Round number:  186  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.20531757061298078\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.16874587367957747\n",
      "-------------Round number:  187  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.2122958353083243\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.17048263136511377\n",
      "-------------Round number:  188  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.20687735059193302\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16819952196401566\n",
      "-------------Round number:  189  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.20493176406193572\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16692288647751896\n",
      "-------------Round number:  190  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.20053189857292794\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16471748724014762\n",
      "-------------Round number:  191  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.20084977072470883\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16364403776676484\n",
      "-------------Round number:  192  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20169784860001355\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16224385513300155\n",
      "-------------Round number:  193  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.20295534034031915\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16452586241860215\n",
      "-------------Round number:  194  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9395991332611051\n",
      "Average Global Trainning Loss:  0.2058732352044962\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.1656362107188403\n",
      "-------------Round number:  195  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9404117009750813\n",
      "Average Global Trainning Loss:  0.20714478993854957\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.1618243789535087\n",
      "-------------Round number:  196  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.20113709223489978\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16227636754017696\n",
      "-------------Round number:  197  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.19952511606598727\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.1632037316043698\n",
      "-------------Round number:  198  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.2015128474926079\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16314965079690885\n",
      "-------------Round number:  199  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.20145619875603782\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.16176392791847238\n",
      "-------------Round number:  200  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9395088479595521\n",
      "Average Global Trainning Loss:  0.20324083233878432\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16271100882891498\n",
      "-------------Round number:  201  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.19811319590217588\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16342675569643825\n",
      "-------------Round number:  202  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.2011969811910324\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.1641848348202194\n",
      "-------------Round number:  203  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19610869027768374\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.16283281463369562\n",
      "-------------Round number:  204  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19685524127336132\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.1602915346773147\n",
      "-------------Round number:  205  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.19940223018801914\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16478650171259931\n",
      "-------------Round number:  206  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.20560515663089113\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.16900045133833852\n",
      "-------------Round number:  207  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.20931580317239978\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9517876489707475\n",
      "Average Personal Trainning Loss:  0.17158600327425289\n",
      "-------------Round number:  208  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.20593660684560086\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.1688561513562545\n",
      "-------------Round number:  209  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.2033154676002731\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.1670553497391601\n",
      "-------------Round number:  210  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9402311303719755\n",
      "Average Global Trainning Loss:  0.20234525328553854\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.1653444917678144\n",
      "-------------Round number:  211  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.20093725665289816\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.16342692101376285\n",
      "-------------Round number:  212  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.20412334030223006\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.1658759098183855\n",
      "-------------Round number:  213  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.2001854595874526\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.1624582276184148\n",
      "-------------Round number:  214  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.20325833393288417\n",
      "Average Personal Accurancy:  0.9360151187904968\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16245135041771058\n",
      "-------------Round number:  215  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.2036620608819181\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16389611362334666\n",
      "-------------Round number:  216  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.2071985290902063\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.17194604236496705\n",
      "-------------Round number:  217  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.20508777953175786\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16869405220888634\n",
      "-------------Round number:  218  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.2070686117153643\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.16916242925300198\n",
      "-------------Round number:  219  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.1989695176014017\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.1655055879900799\n",
      "-------------Round number:  220  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.1978732653583762\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16412603695842926\n",
      "-------------Round number:  221  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.20593746649568886\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.1676769208374244\n",
      "-------------Round number:  222  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.20945222302867686\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.17138454758247\n",
      "-------------Round number:  223  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.20469231844895494\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.1663701975978467\n",
      "-------------Round number:  224  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20803419714500948\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16813308644182806\n",
      "-------------Round number:  225  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.21257872631421543\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17415914538966573\n",
      "-------------Round number:  226  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9393282773564464\n",
      "Average Global Trainning Loss:  0.2098054290033067\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.17327769545709756\n",
      "-------------Round number:  227  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.2089899076197973\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.1719183792659805\n",
      "-------------Round number:  228  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.2082795060124368\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.17084940438151747\n",
      "-------------Round number:  229  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9342723004694836\n",
      "Average Global Trainning Loss:  0.22489120797501355\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.18220875451779184\n",
      "-------------Round number:  230  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9355362946912242\n",
      "Average Global Trainning Loss:  0.2228138525161385\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.18139262697075884\n",
      "-------------Round number:  231  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9373420007222825\n",
      "Average Global Trainning Loss:  0.21954870310101796\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9499819429396894\n",
      "Average Personal Trainning Loss:  0.17836631700509548\n",
      "-------------Round number:  232  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9385157096424702\n",
      "Average Global Trainning Loss:  0.2155274363277018\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.17190545145119515\n",
      "-------------Round number:  233  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.20222417487698627\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17133398252344598\n",
      "-------------Round number:  234  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.19921372435333154\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17046714664237428\n",
      "-------------Round number:  235  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.19579745286119762\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16528632211185784\n",
      "-------------Round number:  236  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.20009376357806294\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16732647015153823\n",
      "-------------Round number:  237  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.1946885483322612\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.165120597004503\n",
      "-------------Round number:  238  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.19209388190118273\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.16274094228582633\n",
      "-------------Round number:  239  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.19215537994594167\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.16105245725907932\n",
      "-------------Round number:  240  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.1976491832354302\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16724261018333558\n",
      "-------------Round number:  241  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.1963650423423957\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16448311135845523\n",
      "-------------Round number:  242  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.19583869402311305\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16506326495632448\n",
      "-------------Round number:  243  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19746521811659218\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16634175199685694\n",
      "-------------Round number:  244  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.19600103563589066\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16631967662344257\n",
      "-------------Round number:  245  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.19217235252460274\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16367192128885089\n",
      "-------------Round number:  246  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9449259660527266\n",
      "Average Global Trainning Loss:  0.19502839666706168\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16384427011034558\n",
      "-------------Round number:  247  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19389454024326247\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.1620122896458277\n",
      "-------------Round number:  248  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.193123081437342\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16169592739227834\n",
      "-------------Round number:  249  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9449259660527266\n",
      "Average Global Trainning Loss:  0.19094148789471604\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9561213434452871\n",
      "Average Personal Trainning Loss:  0.16015386943052545\n",
      "-------------Round number:  250  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.1885510214230092\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.15906173909946056\n",
      "-------------Round number:  251  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.1949182953288642\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.1641116323088773\n",
      "-------------Round number:  252  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.1935618777015055\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16435008601791035\n",
      "-------------Round number:  253  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.1948476717677862\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16542786680519816\n",
      "-------------Round number:  254  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9468219573853377\n",
      "Average Global Trainning Loss:  0.19162144907203638\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.16161406225312613\n",
      "-------------Round number:  255  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.1945594465228873\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.1630912166332329\n",
      "-------------Round number:  256  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19811180723664906\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.1673733100601808\n",
      "-------------Round number:  257  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.20071601798793562\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.1692538497335173\n",
      "-------------Round number:  258  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.20459469305818886\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.16677435437192464\n",
      "-------------Round number:  259  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20271047231909084\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.16754112918698086\n",
      "-------------Round number:  260  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.2028241004268802\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.1678621093044646\n",
      "-------------Round number:  261  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.19292683875186215\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.1613551973650799\n",
      "-------------Round number:  262  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.18943668143677772\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.15992299827611503\n",
      "-------------Round number:  263  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.1929040910879943\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16196443579092745\n",
      "-------------Round number:  264  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.19101202328655426\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16149776702583288\n",
      "-------------Round number:  265  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.18889893724325119\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.15994211997999616\n",
      "-------------Round number:  266  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.1951453531636534\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.1640273204733207\n",
      "-------------Round number:  267  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9454676778620441\n",
      "Average Global Trainning Loss:  0.1910498478904275\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.16062148601494786\n",
      "-------------Round number:  268  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.19258529315919556\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16151546700072228\n",
      "-------------Round number:  269  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.19277064694356041\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.1592483933801124\n",
      "-------------Round number:  270  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.1952056388813651\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16085128811732574\n",
      "-------------Round number:  271  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.1980082965491265\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1626519354382505\n",
      "-------------Round number:  272  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19289090978664455\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.15964340259556134\n",
      "-------------Round number:  273  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.1961116659895269\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.1583193100157435\n",
      "-------------Round number:  274  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.1895680536040764\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.1577553354733771\n",
      "-------------Round number:  275  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.1941803408340669\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16003952494766274\n",
      "-------------Round number:  276  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.1938636589670233\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.1591580199093197\n",
      "-------------Round number:  277  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9432105453232213\n",
      "Average Global Trainning Loss:  0.1945009021476616\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16136798190485058\n",
      "-------------Round number:  278  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.19373695976943392\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.15796658897193255\n",
      "-------------Round number:  279  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.19791276517780562\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16053773625829496\n",
      "-------------Round number:  280  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20195215072990025\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16261821070402785\n",
      "-------------Round number:  281  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.19695884013012369\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.1632360015461358\n",
      "-------------Round number:  282  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.939779703864211\n",
      "Average Global Trainning Loss:  0.20167565199389445\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16387528364044443\n",
      "-------------Round number:  283  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19339345241118183\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.15824466373309973\n",
      "-------------Round number:  284  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.1959506248730363\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.1598970765196145\n",
      "-------------Round number:  285  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.19770164393310988\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16341856697829202\n",
      "-------------Round number:  286  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.1980239465891906\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.1635968451811631\n",
      "-------------Round number:  287  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.19296519237117415\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15873423445823176\n",
      "-------------Round number:  288  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19636916425435627\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9561213434452871\n",
      "Average Personal Trainning Loss:  0.16232686647227113\n",
      "-------------Round number:  289  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.19748770127274062\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9561213434452871\n",
      "Average Personal Trainning Loss:  0.1648857361919917\n",
      "-------------Round number:  290  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.1979702294798438\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16279599295492506\n",
      "-------------Round number:  291  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19893808526741377\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.16228588981807512\n",
      "-------------Round number:  292  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.18925492054893464\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15914091507679892\n",
      "-------------Round number:  293  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18718062897114257\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.15996815194804645\n",
      "-------------Round number:  294  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9475442397977609\n",
      "Average Global Trainning Loss:  0.18636100771798259\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.15643880340587193\n",
      "-------------Round number:  295  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.1891276262089766\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15664575865398722\n",
      "-------------Round number:  296  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18531675328412783\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.1563412441420357\n",
      "-------------Round number:  297  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9481762369086313\n",
      "Average Global Trainning Loss:  0.18358787572439847\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.1528501720710884\n",
      "-------------Round number:  298  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.18757562716543652\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.1574687413594145\n",
      "-------------Round number:  299  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.1896849660160482\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.1568053780414861\n",
      "-------------Round number:  300  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.19358268564209777\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.1603854900234742\n",
      "-------------Round number:  301  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19442476800909625\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16127221908927525\n",
      "-------------Round number:  302  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9420368364030336\n",
      "Average Global Trainning Loss:  0.19806536408958558\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16306321187844214\n",
      "-------------Round number:  303  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19717983632967678\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.16109859181380348\n",
      "-------------Round number:  304  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.1934258546068075\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.15819651230701517\n",
      "-------------Round number:  305  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19772203306981312\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.1641006883019874\n",
      "-------------Round number:  306  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.190302393160042\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.15880733777917908\n",
      "-------------Round number:  307  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.1949012125386534\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.16279983933801123\n",
      "-------------Round number:  308  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.19229019071359246\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16231059924752844\n",
      "-------------Round number:  309  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.18875050432805165\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15885456342824575\n",
      "-------------Round number:  310  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.19834470628357484\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.16605445252897594\n",
      "-------------Round number:  311  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.19493859629632765\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.1655536732892346\n",
      "-------------Round number:  312  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.19228194688967137\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16213460242373715\n",
      "-------------Round number:  313  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19335961746540944\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.1642480962497743\n",
      "-------------Round number:  314  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18767911581064914\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16075576776715986\n",
      "-------------Round number:  315  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.18727796781187928\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9568436258577103\n",
      "Average Personal Trainning Loss:  0.15708497372203978\n",
      "-------------Round number:  316  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.1883721039931496\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.1600086216291136\n",
      "-------------Round number:  317  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.1894175927963615\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16041379234944925\n",
      "-------------Round number:  318  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.18582496078232213\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.15721866033188311\n",
      "-------------Round number:  319  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9451968219573853\n",
      "Average Global Trainning Loss:  0.18857983072211312\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.16015360492280606\n",
      "-------------Round number:  320  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.18490478251117282\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.15881298061052615\n",
      "-------------Round number:  321  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.18701670031204856\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.15646219029672828\n",
      "-------------Round number:  322  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.18940888608393147\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.15924644263568188\n",
      "-------------Round number:  323  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.19861399718422715\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16568335921982213\n",
      "-------------Round number:  324  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.2032164315016703\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.16585370219111142\n",
      "-------------Round number:  325  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9379739978331527\n",
      "Average Global Trainning Loss:  0.20808357191929622\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.16573712041378882\n",
      "-------------Round number:  326  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.19854813476209823\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16504244599457724\n",
      "-------------Round number:  327  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.18830685875569925\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.15782716034034738\n",
      "-------------Round number:  328  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.19061125000705353\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.15795464203993995\n",
      "-------------Round number:  329  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.18562946753538057\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.1536558405420504\n",
      "-------------Round number:  330  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.1819195594112552\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15141709128972553\n",
      "-------------Round number:  331  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.1829200488387053\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.958107620079451\n",
      "Average Personal Trainning Loss:  0.151141364034568\n",
      "-------------Round number:  332  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.1835837758547479\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9575659082701337\n",
      "Average Personal Trainning Loss:  0.15111980665543742\n",
      "-------------Round number:  333  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.18480235189683775\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.14903979509821347\n",
      "-------------Round number:  334  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18366780114027514\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.14889898882225647\n",
      "-------------Round number:  335  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.18267470690781307\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15007295122900866\n",
      "-------------Round number:  336  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.18566914369328955\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15000190886404163\n",
      "-------------Round number:  337  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.18264930314559633\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.14941287221526273\n",
      "-------------Round number:  338  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.18675331675046272\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.15399035463784308\n",
      "-------------Round number:  339  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9424882629107981\n",
      "Average Global Trainning Loss:  0.19792561584450613\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16111860623123758\n",
      "-------------Round number:  340  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19665392885659308\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16126576069246004\n",
      "-------------Round number:  341  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19685989220076067\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.1617157434289229\n",
      "-------------Round number:  342  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9400505597688696\n",
      "Average Global Trainning Loss:  0.20339814830489347\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.16414710940674093\n",
      "-------------Round number:  343  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9402311303719755\n",
      "Average Global Trainning Loss:  0.2033632553282435\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.1607001109345375\n",
      "-------------Round number:  344  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.1984586429837035\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16214458759014422\n",
      "-------------Round number:  345  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.188822714935446\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.15828076903679691\n",
      "-------------Round number:  346  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.18375497847612518\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.1541523105101966\n",
      "-------------Round number:  347  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9453773925604911\n",
      "Average Global Trainning Loss:  0.1880568989608726\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.1540112287053652\n",
      "-------------Round number:  348  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9432105453232213\n",
      "Average Global Trainning Loss:  0.19489638527277447\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.160117885359533\n",
      "-------------Round number:  349  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19297416359132358\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15648680053578684\n",
      "-------------Round number:  350  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9462802455760202\n",
      "Average Global Trainning Loss:  0.18448975887828978\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.1520082660425695\n",
      "-------------Round number:  351  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18526045722451698\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15152460265650392\n",
      "-------------Round number:  352  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.17964714053048259\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.1484300496992371\n",
      "-------------Round number:  353  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.179656111750632\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.15019450354722486\n",
      "-------------Round number:  354  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.18105748466913257\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15045416195842926\n",
      "-------------Round number:  355  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.18373533877796022\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15220262411054872\n",
      "-------------Round number:  356  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.18378516541960094\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.1507124978310367\n",
      "-------------Round number:  357  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.18744582000214427\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.1544470161942206\n",
      "-------------Round number:  358  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.184916464935446\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15023129216253048\n",
      "-------------Round number:  359  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.1812671290790617\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.1489456193289545\n",
      "-------------Round number:  360  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.17853276950867866\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14706007605125948\n",
      "-------------Round number:  361  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.17821337643751128\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.1449312958832724\n",
      "-------------Round number:  362  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.1811014149928618\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14662545680483138\n",
      "-------------Round number:  363  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9451968219573853\n",
      "Average Global Trainning Loss:  0.1817398925428573\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.14657525544392155\n",
      "-------------Round number:  364  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.18252701240999683\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14677482651820378\n",
      "-------------Round number:  365  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9445648248465149\n",
      "Average Global Trainning Loss:  0.1861875347386805\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14756409551056338\n",
      "-------------Round number:  366  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9440231130371975\n",
      "Average Global Trainning Loss:  0.18441442928403756\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.14539399703257608\n",
      "-------------Round number:  367  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.1890945407017425\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.1502047642425063\n",
      "-------------Round number:  368  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.1871316950430548\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.14832355227871638\n",
      "-------------Round number:  369  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.18480051136395698\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.14711215100851505\n",
      "-------------Round number:  370  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.18334801130752867\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.1459015763249368\n",
      "-------------Round number:  371  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.17893656258464247\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1451317155864877\n",
      "-------------Round number:  372  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.17906555418246659\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14700589605340375\n",
      "-------------Round number:  373  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.178027350362693\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1445319884173833\n",
      "-------------Round number:  374  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.1783368354155381\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14479355348839834\n",
      "-------------Round number:  375  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.181648912908541\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.1454037507547287\n",
      "-------------Round number:  376  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.17677601944801824\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14315313171849608\n",
      "-------------Round number:  377  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.17298981186800289\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.1428881831529038\n",
      "-------------Round number:  378  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17294884623496184\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14298374758768959\n",
      "-------------Round number:  379  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.1720229259420707\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.14351032735122676\n",
      "-------------Round number:  380  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.17268324742122607\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.1433098525422366\n",
      "-------------Round number:  381  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.17398107658873915\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.1443600914632426\n",
      "-------------Round number:  382  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.17243594372474833\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1439634511168574\n",
      "-------------Round number:  383  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17333079538176577\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14390889639973253\n",
      "-------------Round number:  384  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.17593735363906193\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14516277320120644\n",
      "-------------Round number:  385  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.1780695503650912\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.1478574015079056\n",
      "-------------Round number:  386  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.1794771943207724\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.958107620079451\n",
      "Average Personal Trainning Loss:  0.14955581659528486\n",
      "-------------Round number:  387  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.18141595875584032\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15024376810996184\n",
      "-------------Round number:  388  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18308103484942104\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.957204767063922\n",
      "Average Personal Trainning Loss:  0.15522655350673753\n",
      "-------------Round number:  389  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18401800936075186\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.1540118458900438\n",
      "-------------Round number:  390  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.1840448017884954\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.15393161188182783\n",
      "-------------Round number:  391  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9472733838931022\n",
      "Average Global Trainning Loss:  0.18170789812996568\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.1519616685993364\n",
      "-------------Round number:  392  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.17812326747443796\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.14983888393965555\n",
      "-------------Round number:  393  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17724402177286475\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.14929867100741467\n",
      "-------------Round number:  394  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17623533260611343\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15070735095166352\n",
      "-------------Round number:  395  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17354168518220703\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14697358202701788\n",
      "-------------Round number:  396  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.1745533169973366\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14775483863971087\n",
      "-------------Round number:  397  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17492031043683978\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.14882853057850307\n",
      "-------------Round number:  398  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.17881372079129423\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15100099860480995\n",
      "-------------Round number:  399  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.1730313506011026\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14683646783797738\n",
      "-------------Round number:  400  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17324565695958605\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.1482483328960139\n",
      "-------------Round number:  401  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.17221329435194904\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.14691143373411544\n",
      "-------------Round number:  402  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17276196051005552\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.1465650718967249\n",
      "-------------Round number:  403  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1729286885425131\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.14695745807728985\n",
      "-------------Round number:  404  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1740088719415854\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.1476593403318549\n",
      "-------------Round number:  405  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17174663660800943\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.14577551635433594\n",
      "-------------Round number:  406  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.17052267122113693\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.1440631044001388\n",
      "-------------Round number:  407  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.1714556450532119\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14617775544744832\n",
      "-------------Round number:  408  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17240707931986954\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14639627188713208\n",
      "-------------Round number:  409  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1724089639373702\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.1453964657712904\n",
      "-------------Round number:  410  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17033930124466753\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1445951286142335\n",
      "-------------Round number:  411  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.1721491402088412\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14582320489191156\n",
      "-------------Round number:  412  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.1707027679145788\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14464683987337487\n",
      "-------------Round number:  413  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.1699194723882155\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14243372582752123\n",
      "-------------Round number:  414  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.1692471709136026\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14217512544719438\n",
      "-------------Round number:  415  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.16889993840496909\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14148139884731062\n",
      "-------------Round number:  416  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.16954904034836019\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14369531743747743\n",
      "-------------Round number:  417  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.17285310546169647\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14366733472499663\n",
      "-------------Round number:  418  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17241073834332116\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.14584824495601412\n",
      "-------------Round number:  419  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.16889019570397143\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14469359161277762\n",
      "-------------Round number:  420  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.16879500598845476\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.1414997711126535\n",
      "-------------Round number:  421  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.17570644942118657\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14462256026896556\n",
      "-------------Round number:  422  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.17691578973540764\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14680052785160483\n",
      "-------------Round number:  423  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.17195180642901883\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14397904605114661\n",
      "-------------Round number:  424  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17340244391025642\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.14551878957035483\n",
      "-------------Round number:  425  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9475442397977609\n",
      "Average Global Trainning Loss:  0.17403036319378612\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14355014678415043\n",
      "-------------Round number:  426  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17349087765777357\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14480113604302094\n",
      "-------------Round number:  427  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.1741003475278756\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14379877301922514\n",
      "-------------Round number:  428  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.1767173648612428\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.1470796826859595\n",
      "-------------Round number:  429  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17186520219322748\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.1446076817097497\n",
      "-------------Round number:  430  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16889496786407548\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14190192203652605\n",
      "-------------Round number:  431  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16840239938479032\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14355317760176847\n",
      "-------------Round number:  432  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.1694842579994188\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.1416061362793145\n",
      "-------------Round number:  433  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1678646772335737\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14114504421863713\n",
      "-------------Round number:  434  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16720068570981175\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14194678915842812\n",
      "-------------Round number:  435  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1672566070501535\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.13988954730738196\n",
      "-------------Round number:  436  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1677480183081663\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13933016858664005\n",
      "-------------Round number:  437  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17013845171640823\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.14075318705351098\n",
      "-------------Round number:  438  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17022363422320783\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14195357818989257\n",
      "-------------Round number:  439  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.1721390227885744\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.14282011649977994\n",
      "-------------Round number:  440  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16928443343857213\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14173220727107033\n",
      "-------------Round number:  441  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16828590577670752\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14201953980241627\n",
      "-------------Round number:  442  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.16654782555257425\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14156713241185898\n",
      "-------------Round number:  443  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16670112981827262\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14031885435711222\n",
      "-------------Round number:  444  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16662152401589023\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13839536524283924\n",
      "-------------Round number:  445  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.1654796441912694\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.1405737736716775\n",
      "-------------Round number:  446  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.1681516791302704\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14204494356463299\n",
      "-------------Round number:  447  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17082123430940208\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14123342286037943\n",
      "-------------Round number:  448  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.16782205842728648\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14016834946477744\n",
      "-------------Round number:  449  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16765529733136397\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.13976231909435377\n",
      "-------------Round number:  450  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.1733166442187782\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14145703107366153\n",
      "-------------Round number:  451  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.17535519419098727\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14267219055770924\n",
      "-------------Round number:  452  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.1747971380088423\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14391237908470453\n",
      "-------------Round number:  453  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.1697008016523621\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1424016873300097\n",
      "-------------Round number:  454  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1681595372137674\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.14009476121301123\n",
      "-------------Round number:  455  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1661475812885123\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.14020579934938154\n",
      "-------------Round number:  456  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16623580563408497\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13918079887326765\n",
      "-------------Round number:  457  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.1725700160750158\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14671873986053743\n",
      "-------------Round number:  458  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.17100453815894162\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14433612045117258\n",
      "-------------Round number:  459  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.1706855969551282\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14490571578257608\n",
      "-------------Round number:  460  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17032172250248284\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14383096581290628\n",
      "-------------Round number:  461  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16756365642774917\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.1415229155381004\n",
      "-------------Round number:  462  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16911907202933144\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14288658508543248\n",
      "-------------Round number:  463  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17174603044448583\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14404445660592158\n",
      "-------------Round number:  464  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.17303837107682152\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14436678130431224\n",
      "-------------Round number:  465  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17402327659113737\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14550564133247\n",
      "-------------Round number:  466  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.1697987135931575\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1417773829853117\n",
      "-------------Round number:  467  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.16950237677819724\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14167739906738105\n",
      "-------------Round number:  468  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16644722444996501\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1385379018401273\n",
      "-------------Round number:  469  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16457004622889582\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13870393553982147\n",
      "-------------Round number:  470  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.164130941372393\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13913906175937837\n",
      "-------------Round number:  471  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.164270458173218\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13848766741575252\n",
      "-------------Round number:  472  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16510157449101662\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1394404352421621\n",
      "-------------Round number:  473  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16653419238387054\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.1406759287571382\n",
      "-------------Round number:  474  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16482013827758216\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1393838416113669\n",
      "-------------Round number:  475  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16448945954372066\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13799555080382134\n",
      "-------------Round number:  476  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16420114612958198\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13651146411723547\n",
      "-------------Round number:  477  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1656100464969303\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.1374889744365633\n",
      "-------------Round number:  478  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16788331400663598\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13761846198636127\n",
      "-------------Round number:  479  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1651923888080083\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13893826733689396\n",
      "-------------Round number:  480  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.1639586476566732\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1380211198833627\n",
      "-------------Round number:  481  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16357324888836222\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13692484559802726\n",
      "-------------Round number:  482  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16489767210282932\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.13868204752604166\n",
      "-------------Round number:  483  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.1649330830737631\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13752859548869742\n",
      "-------------Round number:  484  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.17066599032042817\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14324003352547174\n",
      "-------------Round number:  485  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.1696097669122709\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14082937629785122\n",
      "-------------Round number:  486  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17245920938289996\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.1423773636409805\n",
      "-------------Round number:  487  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.1715644569162773\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14112402687610034\n",
      "-------------Round number:  488  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17438017465268374\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14442507219297354\n",
      "-------------Round number:  489  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17524400175844732\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14435872484002574\n",
      "-------------Round number:  490  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.17283500872522797\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14332721086132177\n",
      "-------------Round number:  491  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16839472866092792\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.14108427357010653\n",
      "-------------Round number:  492  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16590927085449395\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14128822004291372\n",
      "-------------Round number:  493  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.1648332093673822\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13907543663170932\n",
      "-------------Round number:  494  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16611351489848547\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14113044118829565\n",
      "-------------Round number:  495  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.1667074669823831\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14012059480027197\n",
      "-------------Round number:  496  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.166190442560209\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13937509081431698\n",
      "-------------Round number:  497  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16805170623349472\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.1424610582918585\n",
      "-------------Round number:  498  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.1726991950324745\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14526778276580557\n",
      "-------------Round number:  499  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.1723331163488342\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14390413526078344\n",
      "-------------Round number:  500  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17468682726870036\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14692638944141612\n",
      "-------------Round number:  501  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.17247849640410573\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.14559842843620216\n",
      "-------------Round number:  502  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.1736121434259604\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14452994950371298\n",
      "-------------Round number:  503  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9281857451403888\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.1649550592567827\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13962888597107484\n",
      "-------------Round number:  504  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16467939812855498\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.140642005642126\n",
      "-------------Round number:  505  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16378459055615746\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.14031635255493297\n",
      "-------------Round number:  506  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1681952016712656\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.14248042246114911\n",
      "-------------Round number:  507  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16769092872539726\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.1422654989179871\n",
      "-------------Round number:  508  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.17222374240686508\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14532480622164476\n",
      "-------------Round number:  509  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16852241976246501\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14218076827854145\n",
      "-------------Round number:  510  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.1731821200011568\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1456016245711448\n",
      "-------------Round number:  511  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16992247014236864\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14482677124949214\n",
      "-------------Round number:  512  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16921054761562163\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.1443923503838536\n",
      "-------------Round number:  513  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.17325521230094912\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1450783401329451\n",
      "-------------Round number:  514  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.17019004174284488\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14586964803897504\n",
      "-------------Round number:  515  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16868036393440772\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14208401355901837\n",
      "-------------Round number:  516  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16853787142173957\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.1424611905457182\n",
      "-------------Round number:  517  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16422260431831776\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1386571838004187\n",
      "-------------Round number:  518  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1662960362460218\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13888311747740045\n",
      "-------------Round number:  519  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16735631543920979\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.1403372156013001\n",
      "-------------Round number:  520  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16786165743711065\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.1405440496167107\n",
      "-------------Round number:  521  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17131497103111457\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14196867717220793\n",
      "-------------Round number:  522  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17610135944624075\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14413549134601278\n",
      "-------------Round number:  523  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.1777036480199305\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.1465345984032198\n",
      "-------------Round number:  524  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17080001858607574\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14128276457120126\n",
      "-------------Round number:  525  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.1737104521283349\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14351802011739911\n",
      "-------------Round number:  526  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9482665222101841\n",
      "Average Global Trainning Loss:  0.17656478799177275\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14792592002838345\n",
      "-------------Round number:  527  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17283323431927705\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1458946550396127\n",
      "-------------Round number:  528  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1696321288357146\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14352596637013587\n",
      "-------------Round number:  529  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16839911508060784\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14537614276151703\n",
      "-------------Round number:  530  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16583600221622202\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14105471483246435\n",
      "-------------Round number:  531  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.1695871845657277\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14466554277336696\n",
      "-------------Round number:  532  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17059135505893938\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14493417240472078\n",
      "-------------Round number:  533  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16703175344635923\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.143974075510253\n",
      "-------------Round number:  534  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9502527988443481\n",
      "Average Global Trainning Loss:  0.16961462724161475\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14481165022486683\n",
      "-------------Round number:  535  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17095915304275575\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14621814798043067\n",
      "-------------Round number:  536  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17305828630386083\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.14688759497590512\n",
      "-------------Round number:  537  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.1739528954954688\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.14750304933315841\n",
      "-------------Round number:  538  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16780867874514716\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14352044477149353\n",
      "-------------Round number:  539  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16509093907646602\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14167247261110735\n",
      "-------------Round number:  540  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.1645580552122833\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14035373631260722\n",
      "-------------Round number:  541  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1672462581856322\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.1446750319878002\n",
      "-------------Round number:  542  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16801887421282502\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14427784058366627\n",
      "-------------Round number:  543  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.1697319253940107\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14383642128461877\n",
      "-------------Round number:  544  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16374030755546903\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.14004077959594508\n",
      "-------------Round number:  545  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16848246807568165\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14482633040329315\n",
      "-------------Round number:  546  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16814384308908337\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14356400037595363\n",
      "-------------Round number:  547  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16520326668796836\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.14054755434399263\n",
      "-------------Round number:  548  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.16352174703116537\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14104150046764966\n",
      "-------------Round number:  549  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1625493064431259\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13939433375090285\n",
      "-------------Round number:  550  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.16676013708200726\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.1417695469441247\n",
      "-------------Round number:  551  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17232974387541192\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14663453823653055\n",
      "-------------Round number:  552  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.16891351646789793\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14318871902790944\n",
      "-------------Round number:  553  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16893102908315277\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14466398879051554\n",
      "-------------Round number:  554  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16807310931645564\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14352052191957837\n",
      "-------------Round number:  555  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.1645768573026702\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14095845606491514\n",
      "-------------Round number:  556  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16405133557001061\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13969715100498825\n",
      "-------------Round number:  557  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1646834428924307\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14016507618174995\n",
      "-------------Round number:  558  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.16331470361381026\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13689695105478625\n",
      "-------------Round number:  559  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.16103754563639852\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13618112703917817\n",
      "-------------Round number:  560  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1614279259667581\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1373873814300063\n",
      "-------------Round number:  561  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16133532622266047\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13643506547095072\n",
      "-------------Round number:  562  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16024360367432963\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13533253116958965\n",
      "-------------Round number:  563  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.1634632687828695\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13759332273186395\n",
      "-------------Round number:  564  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15921773252697274\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13542256298457814\n",
      "-------------Round number:  565  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.1594890513201404\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13566712241346718\n",
      "-------------Round number:  566  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16349311407054104\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13909272882386467\n",
      "-------------Round number:  567  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.161808122749921\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13557371812505642\n",
      "-------------Round number:  568  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.16767664530855003\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.1399886605540696\n",
      "-------------Round number:  569  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.1715238660025054\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14168098094274784\n",
      "-------------Round number:  570  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1668695440874413\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13729333791460704\n",
      "-------------Round number:  571  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16438867108147684\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13644799328573606\n",
      "-------------Round number:  572  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16094100031881997\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13593241263486366\n",
      "-------------Round number:  573  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16471307877815772\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1372638783673596\n",
      "-------------Round number:  574  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16296846300912446\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13547305089551734\n",
      "-------------Round number:  575  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16333194070019072\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13606938354888948\n",
      "-------------Round number:  576  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16338991197535777\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13541334929901927\n",
      "-------------Round number:  577  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.16048774429932963\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13382050585514288\n",
      "-------------Round number:  578  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.1595282425472305\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13358639448116988\n",
      "-------------Round number:  579  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.15917063913176577\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13288581272289185\n",
      "-------------Round number:  580  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.15839471675808053\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.1335066343826178\n",
      "-------------Round number:  581  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16251504167230948\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1368985381011026\n",
      "-------------Round number:  582  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16349005018945806\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.13757950220352563\n",
      "-------------Round number:  583  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1638316949725194\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13851282871255982\n",
      "-------------Round number:  584  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16028579265557286\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13677168460734357\n",
      "-------------Round number:  585  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16017215352662853\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13732642342184115\n",
      "-------------Round number:  586  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16028767727307353\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13598696735198854\n",
      "-------------Round number:  587  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15998076014933754\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13483489295901613\n",
      "-------------Round number:  588  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16057323539846854\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13554332177963616\n",
      "-------------Round number:  589  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.15836113529887255\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.1329809583537886\n",
      "-------------Round number:  590  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1572118272157988\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13449176032003318\n",
      "-------------Round number:  591  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.1577714814654151\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13200265451130258\n",
      "-------------Round number:  592  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.1592946932521612\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13378225142622563\n",
      "-------------Round number:  593  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.1591935080283383\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1335508071717565\n",
      "-------------Round number:  594  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16399659349325119\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.13896518099734223\n",
      "-------------Round number:  595  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16063790753586019\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1353096622730171\n",
      "-------------Round number:  596  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16250966334868183\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.1358378841886455\n",
      "-------------Round number:  597  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.15930837050548483\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13661307916610238\n",
      "-------------Round number:  598  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1598406922907638\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13508012467835862\n",
      "-------------Round number:  599  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15948125936357327\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13487267347826945\n",
      "-------------Round number:  600  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16248152634003138\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13742206500471177\n",
      "-------------Round number:  601  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.16360635643790628\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13643799709817397\n",
      "-------------Round number:  602  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.16991042401998127\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14214600755575119\n",
      "-------------Round number:  603  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1687110688721673\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14272684446522887\n",
      "-------------Round number:  604  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.16472574208522367\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13861259220739097\n",
      "-------------Round number:  605  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.1624220561877878\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1368212467412649\n",
      "-------------Round number:  606  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.161989916701229\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13481758974570582\n",
      "-------------Round number:  607  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.16067606277438268\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13541749325328978\n",
      "-------------Round number:  608  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16921781055674995\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14141604339831054\n",
      "-------------Round number:  609  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1672436461719032\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14185770516276747\n",
      "-------------Round number:  610  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16526126000544533\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.13986037431016388\n",
      "-------------Round number:  611  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16820555053578684\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14210916383467068\n",
      "-------------Round number:  612  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1646049722690107\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14163388754754086\n",
      "-------------Round number:  613  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.16357287416909308\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13981308253416735\n",
      "-------------Round number:  614  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16200027658690525\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13932022750485284\n",
      "-------------Round number:  615  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1598184295577149\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13611364450726796\n",
      "-------------Round number:  616  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16221386657031533\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.1368450083513904\n",
      "-------------Round number:  617  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1623030387352158\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13802483401258916\n",
      "-------------Round number:  618  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.1601007144000824\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13467667325819904\n",
      "-------------Round number:  619  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.15781758295667433\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13409040291931879\n",
      "-------------Round number:  620  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15672605878913304\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13371728171764966\n",
      "-------------Round number:  621  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16223947973447658\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13677535465195018\n",
      "-------------Round number:  622  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.1584987564610419\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13502482052269546\n",
      "-------------Round number:  623  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.15649001871303944\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13292540071156103\n",
      "-------------Round number:  624  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15598468773629356\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.1324711858515879\n",
      "-------------Round number:  625  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15837264138466617\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13409273940417343\n",
      "-------------Round number:  626  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1596757386642572\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13451186290670708\n",
      "-------------Round number:  627  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.15878811688490316\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.1325325626636421\n",
      "-------------Round number:  628  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15684660818224652\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13242241724082476\n",
      "-------------Round number:  629  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.1570309039357338\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13393335146092902\n",
      "-------------Round number:  630  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15761798984008216\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13337647454236637\n",
      "-------------Round number:  631  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1609165333547761\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13728831226793856\n",
      "-------------Round number:  632  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.15933608871024627\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13515787892670528\n",
      "-------------Round number:  633  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16149865973938585\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13606090828071393\n",
      "-------------Round number:  634  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.1651893800327002\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14002709132146646\n",
      "-------------Round number:  635  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16206470625888747\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13799056924177275\n",
      "-------------Round number:  636  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16556253429783427\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.1403788976094145\n",
      "-------------Round number:  637  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16816904847051056\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14216486475191292\n",
      "-------------Round number:  638  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1612220177283654\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.1363732478126975\n",
      "-------------Round number:  639  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16064852090810086\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13670145780784465\n",
      "-------------Round number:  640  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15732005495765056\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1357833074292107\n",
      "-------------Round number:  641  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15608822046612608\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13381372784483342\n",
      "-------------Round number:  642  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15941565042800876\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13455747946714744\n",
      "-------------Round number:  643  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15867591050610555\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13384749666367596\n",
      "-------------Round number:  644  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16132178122319654\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13749133296372787\n",
      "-------------Round number:  645  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16478752668001195\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13892624325681655\n",
      "-------------Round number:  646  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.1640574523110216\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.1377586620987947\n",
      "-------------Round number:  647  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.1570331742936586\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13389973693825613\n",
      "-------------Round number:  648  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.1595159539594337\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13554845763785436\n",
      "-------------Round number:  649  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.158462518903485\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13457134408010563\n",
      "-------------Round number:  650  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.1581166640392233\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.1347779576724167\n",
      "-------------Round number:  651  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16185848942815548\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13781628069700252\n",
      "-------------Round number:  652  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16644669543452623\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14312349583276904\n",
      "-------------Round number:  653  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16811027265103037\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14310719554456144\n",
      "-------------Round number:  654  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17087930477496388\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9589201877934272\n",
      "Average Personal Trainning Loss:  0.14565034909728805\n",
      "-------------Round number:  655  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17031526410566766\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.1446636471347113\n",
      "-------------Round number:  656  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16729053016516568\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1435954988368714\n",
      "-------------Round number:  657  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16434090539581642\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14009886108266184\n",
      "-------------Round number:  658  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.16826902136728625\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14301545545055186\n",
      "-------------Round number:  659  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.16932127715965262\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.1436790281704248\n",
      "-------------Round number:  660  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.17420232627485668\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.14453066587878635\n",
      "-------------Round number:  661  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.16230036059455694\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.13753585842982574\n",
      "-------------Round number:  662  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16013948682328344\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.13769826616953323\n",
      "-------------Round number:  663  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.15997254938888136\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13697368033572024\n",
      "-------------Round number:  664  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.16433051244667524\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.13945109269902267\n",
      "-------------Round number:  665  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.16934831205280562\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14140831756867325\n",
      "-------------Round number:  666  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.16661456966710117\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1400647395868601\n",
      "-------------Round number:  667  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9504333694474539\n",
      "Average Global Trainning Loss:  0.16565080272802682\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14083710212748848\n",
      "-------------Round number:  668  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16309898654749008\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14015714095016815\n",
      "-------------Round number:  669  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1625358826763667\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1371110369901702\n",
      "-------------Round number:  670  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15810152097228805\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13467514131765754\n",
      "-------------Round number:  671  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.1567279103431688\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.1352721242191732\n",
      "-------------Round number:  672  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1554920200666136\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13329409140893034\n",
      "-------------Round number:  673  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15624613157460387\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.1323496335333717\n",
      "-------------Round number:  674  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1557394009111762\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.1335150986296384\n",
      "-------------Round number:  675  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15280304561241648\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13071143803677432\n",
      "-------------Round number:  676  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15810117931648385\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.1357290723255801\n",
      "-------------Round number:  677  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15627832436828504\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13532866274419353\n",
      "-------------Round number:  678  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9279157667386609\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15537930671468717\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1326559004089642\n",
      "-------------Round number:  679  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15494382781817104\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13345723756602113\n",
      "-------------Round number:  680  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15873834534903733\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13697891538433324\n",
      "-------------Round number:  681  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.1594415170787344\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13552388046226074\n",
      "-------------Round number:  682  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.1579265491159094\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13588298275480204\n",
      "-------------Round number:  683  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9292656587473002\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15475846301265123\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13433276913836786\n",
      "-------------Round number:  684  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9292656587473002\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.15371796679264288\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1321565980039895\n",
      "-------------Round number:  685  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9284557235421166\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15321987671471538\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1311823279042242\n",
      "-------------Round number:  686  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9287257019438445\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15385031984273428\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13255936611254063\n",
      "-------------Round number:  687  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15689772429901927\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.1331282340477158\n",
      "-------------Round number:  688  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15803295836719033\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13593627003910483\n",
      "-------------Round number:  689  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15526693501856492\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13430025673119245\n",
      "-------------Round number:  690  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15470043663170932\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13221107557302952\n",
      "-------------Round number:  691  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.1527536818592847\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13051580151481806\n",
      "-------------Round number:  692  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.15337570482490295\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.1308267193178099\n",
      "-------------Round number:  693  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.15452883724875294\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1322330186925842\n",
      "-------------Round number:  694  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15546300136556518\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13207398342629897\n",
      "-------------Round number:  695  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.152890443371366\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13192794210172895\n",
      "-------------Round number:  696  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15316299653389084\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12991898393062704\n",
      "-------------Round number:  697  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15392779856220656\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12979561312184001\n",
      "-------------Round number:  698  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15727528702614324\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13061306320747\n",
      "-------------Round number:  699  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16008669549095453\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13396362657364458\n",
      "-------------Round number:  700  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15746147841828617\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.1318298758647639\n",
      "-------------Round number:  701  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15867027869591346\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13541845209377257\n",
      "-------------Round number:  702  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15846228745923055\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13301786820179892\n",
      "-------------Round number:  703  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15638194526735735\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.1324486806531295\n",
      "-------------Round number:  704  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.1600652152599088\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1342169147572736\n",
      "-------------Round number:  705  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16140283079688064\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13427401536119762\n",
      "-------------Round number:  706  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15776703993996027\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13061672223092158\n",
      "-------------Round number:  707  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15663409827202396\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.1319554398833909\n",
      "-------------Round number:  708  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15720468550737518\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13231638270881296\n",
      "-------------Round number:  709  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15985948335999572\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13492403206045164\n",
      "-------------Round number:  710  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16128892716021692\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13593071537699755\n",
      "-------------Round number:  711  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16372508734044894\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13651170658264491\n",
      "-------------Round number:  712  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.16974524997037513\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.1416546183400483\n",
      "-------------Round number:  713  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17036221422585995\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.13992421986093243\n",
      "-------------Round number:  714  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.17001123452453504\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1412499105082216\n",
      "-------------Round number:  715  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16557397425669804\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.1386689543939317\n",
      "-------------Round number:  716  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.1651483592938843\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13650673604175131\n",
      "-------------Round number:  717  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1654255082780336\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.137113307348095\n",
      "-------------Round number:  718  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.16499126375087464\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13643208975910753\n",
      "-------------Round number:  719  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.16586633243471244\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13813365689680954\n",
      "-------------Round number:  720  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16447109829953277\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13530118700484156\n",
      "-------------Round number:  721  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16568665454515957\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13620691654181902\n",
      "-------------Round number:  722  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16620302871919015\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13734947967804825\n",
      "-------------Round number:  723  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16778077318075119\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1398512487938448\n",
      "-------------Round number:  724  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.17000085259654885\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.13899111377499773\n",
      "-------------Round number:  725  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.1698943221125632\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13930907409601842\n",
      "-------------Round number:  726  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17219344525183955\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1400225836690818\n",
      "-------------Round number:  727  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.16022614616484968\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13466222452402718\n",
      "-------------Round number:  728  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16154298682469415\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13325429401831662\n",
      "-------------Round number:  729  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1627141829215477\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13283605220818098\n",
      "-------------Round number:  730  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16290400027367732\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.13585951871586088\n",
      "-------------Round number:  731  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16150332168794015\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13474220504567871\n",
      "-------------Round number:  732  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.15656947021925222\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.1326500151122077\n",
      "-------------Round number:  733  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1570812485716583\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13252388901467702\n",
      "-------------Round number:  734  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16321373881308684\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.1377008892044172\n",
      "-------------Round number:  735  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1585107915622743\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13431253429783427\n",
      "-------------Round number:  736  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.1583536629557997\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13368859365125046\n",
      "-------------Round number:  737  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.15812193215130124\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13455086677416261\n",
      "-------------Round number:  738  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.1577520732115046\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13263370380284512\n",
      "-------------Round number:  739  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1593473192671655\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13313880333533654\n",
      "-------------Round number:  740  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15791648680141748\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13360358748293044\n",
      "-------------Round number:  741  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.1586514766055266\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13469803225654003\n",
      "-------------Round number:  742  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15768979266474245\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1330993255582171\n",
      "-------------Round number:  743  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15284500314940525\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12990200033081098\n",
      "-------------Round number:  744  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15536065892046994\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13118066370982304\n",
      "-------------Round number:  745  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15802359038546182\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13236566931385993\n",
      "-------------Round number:  746  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.16087155602132425\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13523304320363286\n",
      "-------------Round number:  747  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.15964532027652695\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13343410416172918\n",
      "-------------Round number:  748  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16228549305649603\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13768685927413438\n",
      "-------------Round number:  749  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.1563928231473174\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13345274093479145\n",
      "-------------Round number:  750  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.1560979411248138\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13373585236378205\n",
      "-------------Round number:  751  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.1547470561172524\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13250399582994762\n",
      "-------------Round number:  752  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.1576698113107733\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13293891264756005\n",
      "-------------Round number:  753  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15385802363006162\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12960956500471177\n",
      "-------------Round number:  754  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.1586650326261455\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13375181099618544\n",
      "-------------Round number:  755  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15373584310601188\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.1308987425655697\n",
      "-------------Round number:  756  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15412858196353602\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13053341332046767\n",
      "-------------Round number:  757  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15185819097527875\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.1272910887172998\n",
      "-------------Round number:  758  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.14958406381548506\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12709125313529818\n",
      "-------------Round number:  759  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15334893443946934\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13092937035524443\n",
      "-------------Round number:  760  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.1527589169078977\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13081685538410753\n",
      "-------------Round number:  761  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15533378934464157\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13036330179343286\n",
      "-------------Round number:  762  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15240209599443616\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13044514489027514\n",
      "-------------Round number:  763  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15216433661816653\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.13030280667377664\n",
      "-------------Round number:  764  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15392387503103558\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.1316467703960139\n",
      "-------------Round number:  765  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15186464937209393\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12745042155476932\n",
      "-------------Round number:  766  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15073545489684903\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12912651880332476\n",
      "-------------Round number:  767  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9582881906825569\n",
      "Average Global Trainning Loss:  0.14923922289748104\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12777017832405088\n",
      "-------------Round number:  768  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15524687651651092\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13232485797698854\n",
      "-------------Round number:  769  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15297979187474608\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13150863123956077\n",
      "-------------Round number:  770  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.1525555435351492\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12988924885450523\n",
      "-------------Round number:  771  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15238703007558574\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.13004505492238286\n",
      "-------------Round number:  772  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9287257019438445\n",
      "Average Global Trainning Accurancy:  0.9577464788732394\n",
      "Average Global Trainning Loss:  0.15240956833750902\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.1297458305648192\n",
      "-------------Round number:  773  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9287257019438445\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.1527682077415414\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13008438942448763\n",
      "-------------Round number:  774  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15186173978718062\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12913551206578414\n",
      "-------------Round number:  775  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.14940969812263002\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.1280763900938685\n",
      "-------------Round number:  776  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.15159729819471718\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1295651277078537\n",
      "-------------Round number:  777  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15183138752638023\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.12901963564237992\n",
      "-------------Round number:  778  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15166060370889198\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.12945380302145404\n",
      "-------------Round number:  779  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15186782346472666\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.1291275107072725\n",
      "-------------Round number:  780  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15740272464111593\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13210499695639785\n",
      "-------------Round number:  781  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15468384979347238\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13193886406630892\n",
      "-------------Round number:  782  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9279157667386609\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15336933459732754\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13011561235653102\n",
      "-------------Round number:  783  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.1541672111117224\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13013887801468266\n",
      "-------------Round number:  784  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15451490650886487\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1292922990164545\n",
      "-------------Round number:  785  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.1545544834763791\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12913916006808077\n",
      "-------------Round number:  786  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.1489859898196269\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12776386320225036\n",
      "-------------Round number:  787  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.14900544215815728\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12625498993812637\n",
      "-------------Round number:  788  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.14712469308287626\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.1265366465746603\n",
      "-------------Round number:  789  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.14922410187285573\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.12696897342085364\n",
      "-------------Round number:  790  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.14854081230673302\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12706651064237992\n",
      "-------------Round number:  791  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.14813054981279908\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.12707338784308414\n",
      "-------------Round number:  792  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.14974004622184228\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.1269860451899095\n",
      "-------------Round number:  793  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.155273007674956\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13221007264792684\n",
      "-------------Round number:  794  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.1536945027537017\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13116757057771308\n",
      "-------------Round number:  795  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15391347106073944\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13133293198695378\n",
      "-------------Round number:  796  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15295944682266274\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.12980555420362722\n",
      "-------------Round number:  797  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.1511492441603749\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1299311072010992\n",
      "-------------Round number:  798  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15028907607806294\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12675241874675539\n",
      "-------------Round number:  799  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15277633033275775\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.1280108142217689\n",
      "---------------Running time:------------ 4\n",
      "Number of users / total users: 5  /  20\n",
      "Finished creating pFedMe server.\n",
      "-------------Round number:  0  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.10421166306695465\n",
      "Average Global Trainning Accurancy:  0.09714698447092814\n",
      "Average Global Trainning Loss:  2.4514942217407008\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9394185626579993\n",
      "Average Personal Trainning Loss:  0.6473844065998555\n",
      "-------------Round number:  1  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.39740820734341253\n",
      "Average Global Trainning Accurancy:  0.39544962080173346\n",
      "Average Global Trainning Loss:  1.7520726824891657\n",
      "Average Personal Accurancy:  0.9235961123110151\n",
      "Average Personal Trainning Accurancy:  0.9291260382809678\n",
      "Average Personal Trainning Loss:  0.5198595922490069\n",
      "-------------Round number:  2  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7024838012958964\n",
      "Average Global Trainning Accurancy:  0.7157818707114482\n",
      "Average Global Trainning Loss:  1.022508019874052\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9364391477067533\n",
      "Average Personal Trainning Loss:  0.4019566870372878\n",
      "-------------Round number:  3  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.7068034557235421\n",
      "Average Global Trainning Accurancy:  0.7180390032502708\n",
      "Average Global Trainning Loss:  0.9756014552862045\n",
      "Average Personal Accurancy:  0.9141468682505399\n",
      "Average Personal Trainning Accurancy:  0.9279523293607801\n",
      "Average Personal Trainning Loss:  0.3862069716475939\n",
      "-------------Round number:  4  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8110151187904968\n",
      "Average Global Trainning Accurancy:  0.8164499819429397\n",
      "Average Global Trainning Loss:  0.673760984123894\n",
      "Average Personal Accurancy:  0.9163066954643628\n",
      "Average Personal Trainning Accurancy:  0.9302997472011556\n",
      "Average Personal Trainning Loss:  0.34909312205867415\n",
      "-------------Round number:  5  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.826133909287257\n",
      "Average Global Trainning Accurancy:  0.8286384976525821\n",
      "Average Global Trainning Loss:  0.5903201724872472\n",
      "Average Personal Accurancy:  0.9146868250539957\n",
      "Average Personal Trainning Accurancy:  0.9286746117732033\n",
      "Average Personal Trainning Loss:  0.3288930202055683\n",
      "-------------Round number:  6  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8237041036717062\n",
      "Average Global Trainning Accurancy:  0.8269230769230769\n",
      "Average Global Trainning Loss:  0.5776242868871885\n",
      "Average Personal Accurancy:  0.9136069114470843\n",
      "Average Personal Trainning Accurancy:  0.927049476345251\n",
      "Average Personal Trainning Loss:  0.31553425621840014\n",
      "-------------Round number:  7  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8158747300215983\n",
      "Average Global Trainning Accurancy:  0.821957385337667\n",
      "Average Global Trainning Loss:  0.572572542123736\n",
      "Average Personal Accurancy:  0.9028077753779697\n",
      "Average Personal Trainning Accurancy:  0.9217226435536294\n",
      "Average Personal Trainning Loss:  0.31803574980532234\n",
      "-------------Round number:  8  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.802645788336933\n",
      "Average Global Trainning Accurancy:  0.8101300108342362\n",
      "Average Global Trainning Loss:  0.5960581825286656\n",
      "Average Personal Accurancy:  0.9025377969762419\n",
      "Average Personal Trainning Accurancy:  0.9227157818707115\n",
      "Average Personal Trainning Loss:  0.31363771382804034\n",
      "-------------Round number:  9  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8453023758099352\n",
      "Average Global Trainning Accurancy:  0.8512098230408089\n",
      "Average Global Trainning Loss:  0.5086949859211358\n",
      "Average Personal Accurancy:  0.9146868250539957\n",
      "Average Personal Trainning Accurancy:  0.9303900325027086\n",
      "Average Personal Trainning Loss:  0.2960046814339563\n",
      "-------------Round number:  10  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8698704103671706\n",
      "Average Global Trainning Accurancy:  0.8813651137594799\n",
      "Average Global Trainning Loss:  0.455972734191608\n",
      "Average Personal Accurancy:  0.923866090712743\n",
      "Average Personal Trainning Accurancy:  0.9385157096424702\n",
      "Average Personal Trainning Loss:  0.2830567640619357\n",
      "-------------Round number:  11  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8704103671706264\n",
      "Average Global Trainning Accurancy:  0.8794691224268689\n",
      "Average Global Trainning Loss:  0.44060902373374866\n",
      "Average Personal Accurancy:  0.9181965442764579\n",
      "Average Personal Trainning Accurancy:  0.9342723004694836\n",
      "Average Personal Trainning Loss:  0.2784644030801395\n",
      "-------------Round number:  12  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8590712742980562\n",
      "Average Global Trainning Accurancy:  0.8679126038280968\n",
      "Average Global Trainning Loss:  0.46477956279342725\n",
      "Average Personal Accurancy:  0.9144168466522679\n",
      "Average Personal Trainning Accurancy:  0.9303900325027086\n",
      "Average Personal Trainning Loss:  0.28299753637510155\n",
      "-------------Round number:  13  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8666306695464363\n",
      "Average Global Trainning Accurancy:  0.8762188515709642\n",
      "Average Global Trainning Loss:  0.4249626867777176\n",
      "Average Personal Accurancy:  0.9192764578833693\n",
      "Average Personal Trainning Accurancy:  0.9375225713253882\n",
      "Average Personal Trainning Loss:  0.26130404598061124\n",
      "-------------Round number:  14  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8731101511879049\n",
      "Average Global Trainning Accurancy:  0.8770314192849404\n",
      "Average Global Trainning Loss:  0.4248456421118861\n",
      "Average Personal Accurancy:  0.9227861771058316\n",
      "Average Personal Trainning Accurancy:  0.9378837125315999\n",
      "Average Personal Trainning Loss:  0.25814082020669693\n",
      "-------------Round number:  15  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8733801295896328\n",
      "Average Global Trainning Accurancy:  0.879378837125316\n",
      "Average Global Trainning Loss:  0.4200834451319294\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9391477067533406\n",
      "Average Personal Trainning Loss:  0.268789680566371\n",
      "-------------Round number:  16  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8857991360691144\n",
      "Average Global Trainning Accurancy:  0.890032502708559\n",
      "Average Global Trainning Loss:  0.4018820076911791\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9412242686890574\n",
      "Average Personal Trainning Loss:  0.262258037155223\n",
      "-------------Round number:  17  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8828293736501079\n",
      "Average Global Trainning Accurancy:  0.8928313470566992\n",
      "Average Global Trainning Loss:  0.4129633822566811\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9383351390393644\n",
      "Average Personal Trainning Loss:  0.2729488440307309\n",
      "-------------Round number:  18  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8852591792656588\n",
      "Average Global Trainning Accurancy:  0.8986096063560852\n",
      "Average Global Trainning Loss:  0.3951420864933189\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.938696280245576\n",
      "Average Personal Trainning Loss:  0.2629610766310604\n",
      "-------------Round number:  19  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8860691144708424\n",
      "Average Global Trainning Accurancy:  0.9043878656554712\n",
      "Average Global Trainning Loss:  0.35585393936636645\n",
      "Average Personal Accurancy:  0.9190064794816415\n",
      "Average Personal Trainning Accurancy:  0.9344528710725893\n",
      "Average Personal Trainning Loss:  0.2615623377685988\n",
      "-------------Round number:  20  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8890388768898488\n",
      "Average Global Trainning Accurancy:  0.9060130010834236\n",
      "Average Global Trainning Loss:  0.3414931319688967\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9376128566269412\n",
      "Average Personal Trainning Loss:  0.2493303105391161\n",
      "-------------Round number:  21  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8849892008639308\n",
      "Average Global Trainning Accurancy:  0.9008667388949079\n",
      "Average Global Trainning Loss:  0.3453167894335162\n",
      "Average Personal Accurancy:  0.921976241900648\n",
      "Average Personal Trainning Accurancy:  0.9347237269772481\n",
      "Average Personal Trainning Loss:  0.25034842279337083\n",
      "-------------Round number:  22  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8868790496760259\n",
      "Average Global Trainning Accurancy:  0.8971650415312387\n",
      "Average Global Trainning Loss:  0.3407796664804532\n",
      "Average Personal Accurancy:  0.9208963282937365\n",
      "Average Personal Trainning Accurancy:  0.9380642831347057\n",
      "Average Personal Trainning Loss:  0.24449486696319744\n",
      "-------------Round number:  23  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8766198704103672\n",
      "Average Global Trainning Accurancy:  0.8950884795955218\n",
      "Average Global Trainning Loss:  0.34553185625169286\n",
      "Average Personal Accurancy:  0.916036717062635\n",
      "Average Personal Trainning Accurancy:  0.9340917298663778\n",
      "Average Personal Trainning Loss:  0.24875685780347148\n",
      "-------------Round number:  24  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.875\n",
      "Average Global Trainning Accurancy:  0.8856988082340195\n",
      "Average Global Trainning Loss:  0.36606971242015396\n",
      "Average Personal Accurancy:  0.9138768898488121\n",
      "Average Personal Trainning Accurancy:  0.9293968941856265\n",
      "Average Personal Trainning Loss:  0.2559245981951404\n",
      "-------------Round number:  25  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8812095032397408\n",
      "Average Global Trainning Accurancy:  0.8919284940411701\n",
      "Average Global Trainning Loss:  0.35405698413235825\n",
      "Average Personal Accurancy:  0.9181965442764579\n",
      "Average Personal Trainning Accurancy:  0.9323763091368725\n",
      "Average Personal Trainning Loss:  0.24966552998882718\n",
      "-------------Round number:  26  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8922786177105831\n",
      "Average Global Trainning Accurancy:  0.9042072950523655\n",
      "Average Global Trainning Loss:  0.3199561860596673\n",
      "Average Personal Accurancy:  0.9230561555075594\n",
      "Average Personal Trainning Accurancy:  0.9401408450704225\n",
      "Average Personal Trainning Loss:  0.23182492516194925\n",
      "-------------Round number:  27  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8955183585313174\n",
      "Average Global Trainning Accurancy:  0.9092632719393283\n",
      "Average Global Trainning Loss:  0.31312304793303086\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9420368364030336\n",
      "Average Personal Trainning Loss:  0.2290243615136331\n",
      "-------------Round number:  28  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8955183585313174\n",
      "Average Global Trainning Accurancy:  0.905742145178765\n",
      "Average Global Trainning Loss:  0.3212646837051959\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9418562657999278\n",
      "Average Personal Trainning Loss:  0.22988676689040494\n",
      "-------------Round number:  29  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8914686825053996\n",
      "Average Global Trainning Accurancy:  0.9025821596244131\n",
      "Average Global Trainning Loss:  0.3338207108486254\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9402311303719755\n",
      "Average Personal Trainning Loss:  0.23419859539347462\n",
      "-------------Round number:  30  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8955183585313174\n",
      "Average Global Trainning Accurancy:  0.9050198627663416\n",
      "Average Global Trainning Loss:  0.32029003888616153\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9434814012278802\n",
      "Average Personal Trainning Loss:  0.22363043193052545\n",
      "-------------Round number:  31  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8936285097192225\n",
      "Average Global Trainning Accurancy:  0.9033044420368364\n",
      "Average Global Trainning Loss:  0.32621353496580446\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9417659804983749\n",
      "Average Personal Trainning Loss:  0.2279913707001625\n",
      "-------------Round number:  32  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8952483801295896\n",
      "Average Global Trainning Accurancy:  0.9048392921632358\n",
      "Average Global Trainning Loss:  0.3314470185747901\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9420368364030336\n",
      "Average Personal Trainning Loss:  0.22719767120350307\n",
      "-------------Round number:  33  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8968682505399568\n",
      "Average Global Trainning Accurancy:  0.9089924160346695\n",
      "Average Global Trainning Loss:  0.324557496219303\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.942668833513904\n",
      "Average Personal Trainning Loss:  0.2272355839766161\n",
      "-------------Round number:  34  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8903887688984882\n",
      "Average Global Trainning Accurancy:  0.9045684362585771\n",
      "Average Global Trainning Loss:  0.3356024348464586\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9421271217045865\n",
      "Average Personal Trainning Loss:  0.2285211576197973\n",
      "-------------Round number:  35  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8871490280777538\n",
      "Average Global Trainning Accurancy:  0.9014987360057782\n",
      "Average Global Trainning Loss:  0.3562778791136241\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9391477067533406\n",
      "Average Personal Trainning Loss:  0.24428464945320963\n",
      "-------------Round number:  36  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9001079913606912\n",
      "Average Global Trainning Accurancy:  0.9133261105092091\n",
      "Average Global Trainning Loss:  0.3128415896772865\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.938696280245576\n",
      "Average Personal Trainning Loss:  0.23630403275522527\n",
      "-------------Round number:  37  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9191043698085951\n",
      "Average Global Trainning Loss:  0.29503144732275866\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9411339833875045\n",
      "Average Personal Trainning Loss:  0.22847647785752978\n",
      "-------------Round number:  38  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9186529433008306\n",
      "Average Global Trainning Loss:  0.2927355644030449\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9418562657999278\n",
      "Average Personal Trainning Loss:  0.225826154593829\n",
      "-------------Round number:  39  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9084773218142549\n",
      "Average Global Trainning Accurancy:  0.9228963524738173\n",
      "Average Global Trainning Loss:  0.2795912941339947\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9443842542434092\n",
      "Average Personal Trainning Loss:  0.21414066643954272\n",
      "-------------Round number:  40  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9076673866090713\n",
      "Average Global Trainning Accurancy:  0.9234380642831347\n",
      "Average Global Trainning Loss:  0.2780170103150957\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9459191043698086\n",
      "Average Personal Trainning Loss:  0.21155413362083558\n",
      "-------------Round number:  41  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9033477321814255\n",
      "Average Global Trainning Accurancy:  0.9212712170458649\n",
      "Average Global Trainning Loss:  0.27582618104460094\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9427591188154568\n",
      "Average Personal Trainning Loss:  0.2157022538879108\n",
      "-------------Round number:  42  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906047516198704\n",
      "Average Global Trainning Accurancy:  0.9234380642831347\n",
      "Average Global Trainning Loss:  0.2744843333841188\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9456482484651498\n",
      "Average Personal Trainning Loss:  0.2112014346193346\n",
      "-------------Round number:  43  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9247923438064283\n",
      "Average Global Trainning Loss:  0.27048601265546\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9463705308775732\n",
      "Average Personal Trainning Loss:  0.20685713779370937\n",
      "-------------Round number:  44  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906047516198704\n",
      "Average Global Trainning Accurancy:  0.9212712170458649\n",
      "Average Global Trainning Loss:  0.27304318511731446\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9456482484651498\n",
      "Average Personal Trainning Loss:  0.20958011251100353\n",
      "-------------Round number:  45  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9256951968219573\n",
      "Average Global Trainning Loss:  0.2673121404458401\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9460996749729144\n",
      "Average Personal Trainning Loss:  0.20696538757787108\n",
      "-------------Round number:  46  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.906047516198704\n",
      "Average Global Trainning Accurancy:  0.9226254965691585\n",
      "Average Global Trainning Loss:  0.2688717661286227\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9445648248465149\n",
      "Average Personal Trainning Loss:  0.20879919755411475\n",
      "-------------Round number:  47  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9076673866090713\n",
      "Average Global Trainning Accurancy:  0.9244312026002167\n",
      "Average Global Trainning Loss:  0.2659008815513272\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9445648248465149\n",
      "Average Personal Trainning Loss:  0.20677326680435176\n",
      "-------------Round number:  48  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9114470842332614\n",
      "Average Global Trainning Accurancy:  0.9258757674250632\n",
      "Average Global Trainning Loss:  0.26624295615943255\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.946460816179126\n",
      "Average Personal Trainning Loss:  0.20719899197871525\n",
      "-------------Round number:  49  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9095572354211663\n",
      "Average Global Trainning Accurancy:  0.9247020585048754\n",
      "Average Global Trainning Loss:  0.2812201767546384\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9431202600216685\n",
      "Average Personal Trainning Loss:  0.21899098857467722\n",
      "-------------Round number:  50  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9046976241900648\n",
      "Average Global Trainning Accurancy:  0.9195557963163596\n",
      "Average Global Trainning Loss:  0.2940806743253995\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9401408450704225\n",
      "Average Personal Trainning Loss:  0.2273362512061552\n",
      "-------------Round number:  51  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9001079913606912\n",
      "Average Global Trainning Accurancy:  0.9152221018418202\n",
      "Average Global Trainning Loss:  0.3062644729807128\n",
      "Average Personal Accurancy:  0.9246760259179265\n",
      "Average Personal Trainning Accurancy:  0.9393282773564464\n",
      "Average Personal Trainning Loss:  0.23063285499757358\n",
      "-------------Round number:  52  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.902267818574514\n",
      "Average Global Trainning Accurancy:  0.9164860960635609\n",
      "Average Global Trainning Loss:  0.3042195638020833\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9402311303719755\n",
      "Average Personal Trainning Loss:  0.22830071247799297\n",
      "-------------Round number:  53  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9087473002159827\n",
      "Average Global Trainning Accurancy:  0.9232574936800289\n",
      "Average Global Trainning Loss:  0.2768187462616242\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9404117009750813\n",
      "Average Personal Trainning Loss:  0.21911823883001535\n",
      "-------------Round number:  54  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9052375809935205\n",
      "Average Global Trainning Accurancy:  0.9181112314915132\n",
      "Average Global Trainning Loss:  0.28489377017312206\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9411339833875045\n",
      "Average Personal Trainning Loss:  0.218137466248815\n",
      "-------------Round number:  55  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8974082073434125\n",
      "Average Global Trainning Accurancy:  0.9119718309859155\n",
      "Average Global Trainning Loss:  0.29873493011353375\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.939689418562658\n",
      "Average Personal Trainning Loss:  0.22302118248352293\n",
      "-------------Round number:  56  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.902267818574514\n",
      "Average Global Trainning Accurancy:  0.918201516793066\n",
      "Average Global Trainning Loss:  0.29254357588338525\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9400505597688696\n",
      "Average Personal Trainning Loss:  0.22469734585900822\n",
      "-------------Round number:  57  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8947084233261339\n",
      "Average Global Trainning Accurancy:  0.9074575659082701\n",
      "Average Global Trainning Loss:  0.3064301870669127\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.937793427230047\n",
      "Average Personal Trainning Loss:  0.22386026709636828\n",
      "-------------Round number:  58  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9073974082073434\n",
      "Average Global Trainning Accurancy:  0.9223546406644998\n",
      "Average Global Trainning Loss:  0.27133003474573403\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9456482484651498\n",
      "Average Personal Trainning Loss:  0.20532387471362631\n",
      "-------------Round number:  59  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9006479481641468\n",
      "Average Global Trainning Accurancy:  0.9181112314915132\n",
      "Average Global Trainning Loss:  0.2797997262168766\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9437522571325389\n",
      "Average Personal Trainning Loss:  0.2104007917950411\n",
      "-------------Round number:  60  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.900377969762419\n",
      "Average Global Trainning Accurancy:  0.9206392199349945\n",
      "Average Global Trainning Loss:  0.2651834704894028\n",
      "Average Personal Accurancy:  0.9244060475161987\n",
      "Average Personal Trainning Accurancy:  0.9436619718309859\n",
      "Average Personal Trainning Loss:  0.20661888246546586\n",
      "-------------Round number:  61  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.8995680345572354\n",
      "Average Global Trainning Accurancy:  0.9175695196821957\n",
      "Average Global Trainning Loss:  0.270055283876738\n",
      "Average Personal Accurancy:  0.9203563714902808\n",
      "Average Personal Trainning Accurancy:  0.94068255687974\n",
      "Average Personal Trainning Loss:  0.2103110575512369\n",
      "-------------Round number:  62  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9001079913606912\n",
      "Average Global Trainning Accurancy:  0.9183820873961719\n",
      "Average Global Trainning Loss:  0.271885875675729\n",
      "Average Personal Accurancy:  0.9230561555075594\n",
      "Average Personal Trainning Accurancy:  0.9395088479595521\n",
      "Average Personal Trainning Loss:  0.21361616967429578\n",
      "-------------Round number:  63  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9285843264716505\n",
      "Average Global Trainning Loss:  0.2502594379881049\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9453773925604911\n",
      "Average Personal Trainning Loss:  0.2011482015591143\n",
      "-------------Round number:  64  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9322860238353196\n",
      "Average Global Trainning Loss:  0.24512767963953594\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.948537378114843\n",
      "Average Personal Trainning Loss:  0.1960097423483207\n",
      "-------------Round number:  65  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9331888768508487\n",
      "Average Global Trainning Loss:  0.24415072037795685\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.1957775486553133\n",
      "-------------Round number:  66  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9315637414228963\n",
      "Average Global Trainning Loss:  0.24522072022983252\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.19118622366208468\n",
      "-------------Round number:  67  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9316540267244493\n",
      "Average Global Trainning Loss:  0.24502222922873781\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.1922834898513678\n",
      "-------------Round number:  68  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9312026002166848\n",
      "Average Global Trainning Loss:  0.24453745270601976\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.19411046671152718\n",
      "-------------Round number:  69  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9315637414228963\n",
      "Average Global Trainning Loss:  0.24340139205122563\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.1879884575884796\n",
      "-------------Round number:  70  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9307511737089202\n",
      "Average Global Trainning Loss:  0.2436064296183753\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.18908653934323086\n",
      "-------------Round number:  71  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9304803178042614\n",
      "Average Global Trainning Loss:  0.24148042678144185\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9498013723365836\n",
      "Average Personal Trainning Loss:  0.18785455055553674\n",
      "-------------Round number:  72  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9103671706263499\n",
      "Average Global Trainning Accurancy:  0.9297580353918382\n",
      "Average Global Trainning Loss:  0.2434354474200975\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.18937441191117055\n",
      "-------------Round number:  73  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.929938605994944\n",
      "Average Global Trainning Loss:  0.24169443556874098\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9487179487179487\n",
      "Average Personal Trainning Loss:  0.1894571367004108\n",
      "-------------Round number:  74  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.928945467677862\n",
      "Average Global Trainning Loss:  0.24644237117416035\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9467316720837847\n",
      "Average Personal Trainning Loss:  0.19617691122697725\n",
      "-------------Round number:  75  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9297580353918382\n",
      "Average Global Trainning Loss:  0.2409920353198921\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9480859516070783\n",
      "Average Personal Trainning Loss:  0.19160831185530652\n",
      "-------------Round number:  76  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9310220296135789\n",
      "Average Global Trainning Loss:  0.24139959763085725\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9480859516070783\n",
      "Average Personal Trainning Loss:  0.19140774887707657\n",
      "-------------Round number:  77  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9310220296135789\n",
      "Average Global Trainning Loss:  0.2442827097299341\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.19191051192471334\n",
      "-------------Round number:  78  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9298483206933911\n",
      "Average Global Trainning Loss:  0.2465284904791328\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.19185243043799657\n",
      "-------------Round number:  79  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9271397616468039\n",
      "Average Global Trainning Loss:  0.25612154623453864\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9461899602744673\n",
      "Average Personal Trainning Loss:  0.2005084235128318\n",
      "-------------Round number:  80  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9275009028530156\n",
      "Average Global Trainning Loss:  0.2560013054337644\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9460093896713615\n",
      "Average Personal Trainning Loss:  0.1996343577540967\n",
      "-------------Round number:  81  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9284037558685446\n",
      "Average Global Trainning Loss:  0.25555173048003565\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.19638481429442037\n",
      "-------------Round number:  82  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.930931744312026\n",
      "Average Global Trainning Loss:  0.24526308554955534\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.19445346709665043\n",
      "-------------Round number:  83  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9103671706263499\n",
      "Average Global Trainning Accurancy:  0.9258757674250632\n",
      "Average Global Trainning Loss:  0.2595971115404365\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9438425424340917\n",
      "Average Personal Trainning Loss:  0.20555582594122426\n",
      "-------------Round number:  84  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9286746117732033\n",
      "Average Global Trainning Loss:  0.25187392698035166\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9461899602744673\n",
      "Average Personal Trainning Loss:  0.19885622012826157\n",
      "-------------Round number:  85  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9109071274298056\n",
      "Average Global Trainning Accurancy:  0.9254243409172986\n",
      "Average Global Trainning Loss:  0.2582405175745982\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9470025279884435\n",
      "Average Personal Trainning Loss:  0.19928293720657278\n",
      "-------------Round number:  86  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9293066088840737\n",
      "Average Global Trainning Loss:  0.24634080020991334\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9470025279884435\n",
      "Average Personal Trainning Loss:  0.1960680663004469\n",
      "-------------Round number:  87  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9298483206933911\n",
      "Average Global Trainning Loss:  0.24591882222824124\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9463705308775732\n",
      "Average Personal Trainning Loss:  0.19496789052625046\n",
      "-------------Round number:  88  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9331888768508487\n",
      "Average Global Trainning Loss:  0.24375111534088345\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9454676778620441\n",
      "Average Personal Trainning Loss:  0.1977263092779433\n",
      "-------------Round number:  89  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9329180209461899\n",
      "Average Global Trainning Loss:  0.24177685176564193\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.946460816179126\n",
      "Average Personal Trainning Loss:  0.19611111493177816\n",
      "-------------Round number:  90  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9138768898488121\n",
      "Average Global Trainning Accurancy:  0.9330985915492958\n",
      "Average Global Trainning Loss:  0.23727188854279524\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9467316720837847\n",
      "Average Personal Trainning Loss:  0.1938017862029952\n",
      "-------------Round number:  91  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.23527434828824711\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9469122426868906\n",
      "Average Personal Trainning Loss:  0.19273817862100487\n",
      "-------------Round number:  92  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9320151679306609\n",
      "Average Global Trainning Loss:  0.24112569988742552\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9458288190682557\n",
      "Average Personal Trainning Loss:  0.1948579214419127\n",
      "-------------Round number:  93  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9343625857710365\n",
      "Average Global Trainning Loss:  0.2331243413757787\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.19038763077261647\n",
      "-------------Round number:  94  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.23689888857383082\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9482665222101841\n",
      "Average Personal Trainning Loss:  0.1899213918325659\n",
      "-------------Round number:  95  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9342723004694836\n",
      "Average Global Trainning Loss:  0.23704154640382358\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.1891420198373736\n",
      "-------------Round number:  96  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9344528710725893\n",
      "Average Global Trainning Loss:  0.23058883650460454\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9465511014806789\n",
      "Average Personal Trainning Loss:  0.18988632251743634\n",
      "-------------Round number:  97  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.23006361234312928\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.18671319974635472\n",
      "-------------Round number:  98  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9307511737089202\n",
      "Average Global Trainning Loss:  0.23778595929543608\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9480859516070783\n",
      "Average Personal Trainning Loss:  0.1900930353001422\n",
      "-------------Round number:  99  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9340014445648248\n",
      "Average Global Trainning Loss:  0.2326941416124955\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.948537378114843\n",
      "Average Personal Trainning Loss:  0.18857026435959506\n",
      "-------------Round number:  100  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9329180209461899\n",
      "Average Global Trainning Loss:  0.24037687853382314\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9478150957024196\n",
      "Average Personal Trainning Loss:  0.19226232923381636\n",
      "-------------Round number:  101  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9307511737089202\n",
      "Average Global Trainning Loss:  0.2442468248493364\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.19056233812127574\n",
      "-------------Round number:  102  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.910097192224622\n",
      "Average Global Trainning Accurancy:  0.9273203322499097\n",
      "Average Global Trainning Loss:  0.25418545994012953\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9461899602744673\n",
      "Average Personal Trainning Loss:  0.2000627280056541\n",
      "-------------Round number:  103  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9106371490280778\n",
      "Average Global Trainning Accurancy:  0.9288551823763092\n",
      "Average Global Trainning Loss:  0.24223742583203547\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9458288190682557\n",
      "Average Personal Trainning Loss:  0.19473384527920728\n",
      "-------------Round number:  104  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9305706031058144\n",
      "Average Global Trainning Loss:  0.2348714809893012\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.18889593948909805\n",
      "-------------Round number:  105  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9360780065005417\n",
      "Average Global Trainning Loss:  0.22465764765878926\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9497110870350307\n",
      "Average Personal Trainning Loss:  0.18563971720950703\n",
      "-------------Round number:  106  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9337305886601661\n",
      "Average Global Trainning Loss:  0.23738421615429758\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9477248104008668\n",
      "Average Personal Trainning Loss:  0.1940843024896172\n",
      "-------------Round number:  107  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.23296191159376128\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9478150957024196\n",
      "Average Personal Trainning Loss:  0.19261868725876896\n",
      "-------------Round number:  108  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9328277356446371\n",
      "Average Global Trainning Loss:  0.2392522798802027\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9475442397977609\n",
      "Average Personal Trainning Loss:  0.19430712820089607\n",
      "-------------Round number:  109  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9312928855182376\n",
      "Average Global Trainning Loss:  0.24203829560395224\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9479053810039726\n",
      "Average Personal Trainning Loss:  0.1935877333310762\n",
      "-------------Round number:  110  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.933820873961719\n",
      "Average Global Trainning Loss:  0.23442668921683144\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.19078915349065548\n",
      "-------------Round number:  111  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9347237269772481\n",
      "Average Global Trainning Loss:  0.22927729702030292\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9474539544962081\n",
      "Average Personal Trainning Loss:  0.19021226215465872\n",
      "-------------Round number:  112  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9363488624052004\n",
      "Average Global Trainning Loss:  0.2267790436529433\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.1874078411021014\n",
      "-------------Round number:  113  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9341820151679306\n",
      "Average Global Trainning Loss:  0.23193780383120036\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9478150957024196\n",
      "Average Personal Trainning Loss:  0.19055222070100894\n",
      "-------------Round number:  114  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9332791621524016\n",
      "Average Global Trainning Loss:  0.2350012220256636\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.19231922043579586\n",
      "-------------Round number:  115  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9380642831347057\n",
      "Average Global Trainning Loss:  0.22338421932839023\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9495305164319249\n",
      "Average Personal Trainning Loss:  0.183135115656882\n",
      "-------------Round number:  116  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9361682918020946\n",
      "Average Global Trainning Loss:  0.22417644199028305\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9492596605272662\n",
      "Average Personal Trainning Loss:  0.1845924980849641\n",
      "-------------Round number:  117  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9366197183098591\n",
      "Average Global Trainning Loss:  0.22115889384282458\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.17965584724291261\n",
      "-------------Round number:  118  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.21706894323170595\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.17804366167205557\n",
      "-------------Round number:  119  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9374322860238353\n",
      "Average Global Trainning Loss:  0.22013095071833244\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9496208017334777\n",
      "Average Personal Trainning Loss:  0.18109234458231763\n",
      "-------------Round number:  120  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.22732694935135653\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9488985193210545\n",
      "Average Personal Trainning Loss:  0.18576945824586943\n",
      "-------------Round number:  121  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.2280450437248894\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.949440231130372\n",
      "Average Personal Trainning Loss:  0.18278143577258826\n",
      "-------------Round number:  122  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9358974358974359\n",
      "Average Global Trainning Loss:  0.22776691385794737\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.1835785408061349\n",
      "-------------Round number:  123  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9331888768508487\n",
      "Average Global Trainning Loss:  0.23417044736366918\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.94844709281329\n",
      "Average Personal Trainning Loss:  0.1882173008503747\n",
      "-------------Round number:  124  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9336403033586133\n",
      "Average Global Trainning Loss:  0.23153039581640483\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.18653496562810357\n",
      "-------------Round number:  125  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9354460093896714\n",
      "Average Global Trainning Loss:  0.22391821632922534\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9495305164319249\n",
      "Average Personal Trainning Loss:  0.1847234734906837\n",
      "-------------Round number:  126  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.936800288912965\n",
      "Average Global Trainning Loss:  0.22052500109329856\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9506139400505598\n",
      "Average Personal Trainning Loss:  0.1815365632547287\n",
      "-------------Round number:  127  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9352654387865655\n",
      "Average Global Trainning Loss:  0.22349319650878025\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9488082340195017\n",
      "Average Personal Trainning Loss:  0.18416913143776523\n",
      "-------------Round number:  128  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9363488624052004\n",
      "Average Global Trainning Loss:  0.21731063716030155\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.1777793192699869\n",
      "-------------Round number:  129  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9344528710725893\n",
      "Average Global Trainning Loss:  0.22842130595572635\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.188721143971199\n",
      "-------------Round number:  130  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.23055085760456168\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9468219573853377\n",
      "Average Personal Trainning Loss:  0.1925021275237563\n",
      "-------------Round number:  131  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9345431563741423\n",
      "Average Global Trainning Loss:  0.22962124522475397\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9482665222101841\n",
      "Average Personal Trainning Loss:  0.18942799676665764\n",
      "-------------Round number:  132  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.9346334416756952\n",
      "Average Global Trainning Loss:  0.22814943610480995\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9486276634163958\n",
      "Average Personal Trainning Loss:  0.1857197748792434\n",
      "-------------Round number:  133  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.934814012278801\n",
      "Average Global Trainning Loss:  0.22262265751963706\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9489888046226075\n",
      "Average Personal Trainning Loss:  0.1863857612320558\n",
      "-------------Round number:  134  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9316540267244493\n",
      "Average Global Trainning Loss:  0.23013897500084643\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9476345250993138\n",
      "Average Personal Trainning Loss:  0.1908974253171271\n",
      "-------------Round number:  135  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9360780065005417\n",
      "Average Global Trainning Loss:  0.22158660282508352\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9487179487179487\n",
      "Average Personal Trainning Loss:  0.1832458011162931\n",
      "-------------Round number:  136  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9369808595160708\n",
      "Average Global Trainning Loss:  0.21946983571601886\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.18076715438363353\n",
      "-------------Round number:  137  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9379739978331527\n",
      "Average Global Trainning Loss:  0.2203267084729934\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9500722282412424\n",
      "Average Personal Trainning Loss:  0.1818680685752133\n",
      "-------------Round number:  138  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9389671361502347\n",
      "Average Global Trainning Loss:  0.2182873098718513\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9505236547490069\n",
      "Average Personal Trainning Loss:  0.17827862167496164\n",
      "-------------Round number:  139  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9376128566269412\n",
      "Average Global Trainning Loss:  0.22458616444762325\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9490790899241603\n",
      "Average Personal Trainning Loss:  0.1843527218373341\n",
      "-------------Round number:  140  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.937703141928494\n",
      "Average Global Trainning Loss:  0.22330539602801103\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.18019037325918652\n",
      "-------------Round number:  141  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9354460093896714\n",
      "Average Global Trainning Loss:  0.22910940074541802\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9490790899241603\n",
      "Average Personal Trainning Loss:  0.1843077775673472\n",
      "-------------Round number:  142  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9313831708197905\n",
      "Average Global Trainning Loss:  0.23539044513475083\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9479956663055255\n",
      "Average Personal Trainning Loss:  0.18688971456442985\n",
      "-------------Round number:  143  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9355362946912242\n",
      "Average Global Trainning Loss:  0.224762833561868\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9502527988443481\n",
      "Average Personal Trainning Loss:  0.18088430926101481\n",
      "-------------Round number:  144  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.2186281941952194\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.17646333826023045\n",
      "-------------Round number:  145  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9392379920548934\n",
      "Average Global Trainning Loss:  0.21409089490367686\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.1755437771737597\n",
      "-------------Round number:  146  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9389671361502347\n",
      "Average Global Trainning Loss:  0.21187513578062928\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9508847959552185\n",
      "Average Personal Trainning Loss:  0.1745379204438369\n",
      "-------------Round number:  147  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9354460093896714\n",
      "Average Global Trainning Loss:  0.22335937764507718\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9498916576381365\n",
      "Average Personal Trainning Loss:  0.18176541753777875\n",
      "-------------Round number:  148  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.21467523654043652\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17896893171680323\n",
      "-------------Round number:  149  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.21250814683775732\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.17650549417800876\n",
      "-------------Round number:  150  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.21246033706747697\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.17669269951640934\n",
      "-------------Round number:  151  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.21183561391888994\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.17577630150141635\n",
      "-------------Round number:  152  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9404117009750813\n",
      "Average Global Trainning Loss:  0.20927066052162333\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.952329360780065\n",
      "Average Personal Trainning Loss:  0.17389383312595927\n",
      "-------------Round number:  153  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.20708188118595386\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.17182396103131206\n",
      "-------------Round number:  154  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.20664584021053403\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.17428604296804465\n",
      "-------------Round number:  155  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.2072905998188651\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.1735330225543969\n",
      "-------------Round number:  156  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.2045696529940863\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17160785822456776\n",
      "-------------Round number:  157  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.2066608951082295\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1717657142272707\n",
      "-------------Round number:  158  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.20462603722293699\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.1696750672554961\n",
      "-------------Round number:  159  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20731608072916666\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9529613578909354\n",
      "Average Personal Trainning Loss:  0.17242502176016838\n",
      "-------------Round number:  160  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20534472673883847\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16933847016141318\n",
      "-------------Round number:  161  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9416756951968219\n",
      "Average Global Trainning Loss:  0.20638582912237044\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.16909407604984877\n",
      "-------------Round number:  162  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.20715025643141702\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1688230768701754\n",
      "-------------Round number:  163  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.20737246495801734\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16810353872534084\n",
      "-------------Round number:  164  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9388768508486819\n",
      "Average Global Trainning Loss:  0.21376832773987675\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9526002166847237\n",
      "Average Personal Trainning Loss:  0.1742868475123578\n",
      "-------------Round number:  165  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9412242686890574\n",
      "Average Global Trainning Loss:  0.20594108143452058\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.17041863151817557\n",
      "-------------Round number:  166  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.2044272817141229\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9532322137955941\n",
      "Average Personal Trainning Loss:  0.169522523449491\n",
      "-------------Round number:  167  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.2101268279246795\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.17045068103684205\n",
      "-------------Round number:  168  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.939779703864211\n",
      "Average Global Trainning Loss:  0.21017027331758983\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.17010295257623465\n",
      "-------------Round number:  169  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9370711448176237\n",
      "Average Global Trainning Loss:  0.21728304018824485\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9521487901769592\n",
      "Average Personal Trainning Loss:  0.17337485795935467\n",
      "-------------Round number:  170  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9399602744673167\n",
      "Average Global Trainning Loss:  0.20928597992703818\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16954593238265733\n",
      "-------------Round number:  171  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9383351390393644\n",
      "Average Global Trainning Loss:  0.21484661550029344\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17267675596094598\n",
      "-------------Round number:  172  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9357168652943301\n",
      "Average Global Trainning Loss:  0.2197208535417231\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.1724425453965782\n",
      "-------------Round number:  173  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9375225713253882\n",
      "Average Global Trainning Loss:  0.2132884005253476\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.16864769723106265\n",
      "-------------Round number:  174  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9340917298663778\n",
      "Average Global Trainning Loss:  0.2200727590200659\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17124051210810537\n",
      "-------------Round number:  175  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9344528710725893\n",
      "Average Global Trainning Loss:  0.21863491709975397\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.1700494338476774\n",
      "-------------Round number:  176  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9402311303719755\n",
      "Average Global Trainning Loss:  0.20474854838163598\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.16757345423452172\n",
      "-------------Round number:  177  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9387865655471289\n",
      "Average Global Trainning Loss:  0.2079803918664229\n",
      "Average Personal Accurancy:  0.9354751619870411\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16500720034096808\n",
      "-------------Round number:  178  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.937793427230047\n",
      "Average Global Trainning Loss:  0.210138818941292\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9535030697002528\n",
      "Average Personal Trainning Loss:  0.16778133525965488\n",
      "-------------Round number:  179  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9403214156735283\n",
      "Average Global Trainning Loss:  0.20732527237241558\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16755574323847733\n",
      "-------------Round number:  180  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.210947088404828\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16727356860765957\n",
      "-------------Round number:  181  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19946992212187387\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16346339001557422\n",
      "-------------Round number:  182  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.2040934068453187\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16866273008644816\n",
      "-------------Round number:  183  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.2051540607577758\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16798175496287018\n",
      "-------------Round number:  184  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.20318026007104326\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16540063353125564\n",
      "-------------Round number:  185  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.20734665341306655\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.17046304677272367\n",
      "-------------Round number:  186  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9358974358974359\n",
      "Average Global Trainning Loss:  0.21470082766228782\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.17119809168260766\n",
      "-------------Round number:  187  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.912257019438445\n",
      "Average Global Trainning Accurancy:  0.9361682918020946\n",
      "Average Global Trainning Loss:  0.22012475682923663\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.17409421976570963\n",
      "-------------Round number:  188  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9353557240881184\n",
      "Average Global Trainning Loss:  0.2221837510439238\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17683519202907752\n",
      "-------------Round number:  189  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9146868250539957\n",
      "Average Global Trainning Accurancy:  0.9363488624052004\n",
      "Average Global Trainning Loss:  0.21524399426406193\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9516973636691947\n",
      "Average Personal Trainning Loss:  0.17415341438907886\n",
      "-------------Round number:  190  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9354460093896714\n",
      "Average Global Trainning Loss:  0.21546836293703728\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9510653665583243\n",
      "Average Personal Trainning Loss:  0.1743643152106751\n",
      "-------------Round number:  191  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.20528823229843807\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16960787127361526\n",
      "-------------Round number:  192  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9390574214517876\n",
      "Average Global Trainning Loss:  0.212292925723411\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.1721496912665899\n",
      "-------------Round number:  193  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9384254243409172\n",
      "Average Global Trainning Loss:  0.20957059023310537\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17248970491871501\n",
      "-------------Round number:  194  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9398699891657638\n",
      "Average Global Trainning Loss:  0.21219862872144726\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.1740589190063256\n",
      "-------------Round number:  195  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20413998224624189\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1663942237156916\n",
      "-------------Round number:  196  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.20340562064796633\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16706768241157682\n",
      "-------------Round number:  197  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.2023342100882539\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16762874736902988\n",
      "-------------Round number:  198  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.20492870018085274\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16651717572058955\n",
      "-------------Round number:  199  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9420368364030336\n",
      "Average Global Trainning Loss:  0.20914631985119853\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.17229380388903937\n",
      "-------------Round number:  200  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.20254008526318165\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9531419284940412\n",
      "Average Personal Trainning Loss:  0.16936241913117325\n",
      "-------------Round number:  201  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.20508725051631907\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.16919289172535212\n",
      "-------------Round number:  202  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.19796079537118544\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16504235782533744\n",
      "-------------Round number:  203  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9427591188154568\n",
      "Average Global Trainning Loss:  0.20470038593439643\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9526905019862766\n",
      "Average Personal Trainning Loss:  0.17314525423776633\n",
      "-------------Round number:  204  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.2027865182884164\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.1686575391224551\n",
      "-------------Round number:  205  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.2021939548700456\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.16864339898062253\n",
      "-------------Round number:  206  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9445648248465149\n",
      "Average Global Trainning Loss:  0.19762566409071416\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.16588948788131433\n",
      "-------------Round number:  207  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.19814163048201067\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16694058645240836\n",
      "-------------Round number:  208  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9445648248465149\n",
      "Average Global Trainning Loss:  0.1969309786503476\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16415498953254784\n",
      "-------------Round number:  209  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.2067676680576246\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.1723482814580794\n",
      "-------------Round number:  210  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.2035656698605092\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9528710725893824\n",
      "Average Personal Trainning Loss:  0.17102693314585027\n",
      "-------------Round number:  211  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.942668833513904\n",
      "Average Global Trainning Loss:  0.199187802596831\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.16766887539429284\n",
      "-------------Round number:  212  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.19922426057748735\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16664757802625046\n",
      "-------------Round number:  213  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.19816649420763363\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16529002521992936\n",
      "-------------Round number:  214  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9415854098952691\n",
      "Average Global Trainning Loss:  0.201187569124684\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16602117966210725\n",
      "-------------Round number:  215  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.20384567332379694\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.17189489318472936\n",
      "-------------Round number:  216  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19633356592378792\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16662503976432716\n",
      "-------------Round number:  217  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.19626003277779658\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16487938800672625\n",
      "-------------Round number:  218  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9422174070061394\n",
      "Average Global Trainning Loss:  0.20189089515055075\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.16865337312587464\n",
      "-------------Round number:  219  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.1987486977403282\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.954315637414229\n",
      "Average Personal Trainning Loss:  0.1682550465427783\n",
      "-------------Round number:  220  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.19620851989944474\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.16339479434701157\n",
      "-------------Round number:  221  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.1977542589269592\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16341531573757448\n",
      "-------------Round number:  222  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.939779703864211\n",
      "Average Global Trainning Loss:  0.20789669721554488\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.1722057779242563\n",
      "-------------Round number:  223  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9407728421812929\n",
      "Average Global Trainning Loss:  0.2068753888263475\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16873423533992415\n",
      "-------------Round number:  224  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9372517154207295\n",
      "Average Global Trainning Loss:  0.21327495471627844\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9507945106536656\n",
      "Average Personal Trainning Loss:  0.17100901274786137\n",
      "-------------Round number:  225  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9366197183098591\n",
      "Average Global Trainning Loss:  0.2140757518367416\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17183504831321664\n",
      "-------------Round number:  226  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9374322860238353\n",
      "Average Global Trainning Loss:  0.2115915394208198\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.17091274295915718\n",
      "-------------Round number:  227  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.20943399403834867\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9509750812567714\n",
      "Average Personal Trainning Loss:  0.17052662781577285\n",
      "-------------Round number:  228  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9378837125315999\n",
      "Average Global Trainning Loss:  0.21075214621563515\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.952239075478512\n",
      "Average Personal Trainning Loss:  0.17083306000868995\n",
      "-------------Round number:  229  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9149568034557235\n",
      "Average Global Trainning Accurancy:  0.9373420007222825\n",
      "Average Global Trainning Loss:  0.21172606363844124\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9520585048754063\n",
      "Average Personal Trainning Loss:  0.16974555856271442\n",
      "-------------Round number:  230  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9152267818574514\n",
      "Average Global Trainning Accurancy:  0.9366197183098591\n",
      "Average Global Trainning Loss:  0.21639938602468176\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9490790899241603\n",
      "Average Personal Trainning Loss:  0.17709964464269592\n",
      "-------------Round number:  231  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9117170626349892\n",
      "Average Global Trainning Accurancy:  0.9344528710725893\n",
      "Average Global Trainning Loss:  0.22487145806529885\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.949349945828819\n",
      "Average Personal Trainning Loss:  0.18016668879714587\n",
      "-------------Round number:  232  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9401408450704225\n",
      "Average Global Trainning Loss:  0.21228468189948987\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16923681102792637\n",
      "-------------Round number:  233  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.20722802170091864\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9538642109064644\n",
      "Average Personal Trainning Loss:  0.1691054057971628\n",
      "-------------Round number:  234  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.20337848656441856\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16458272055711673\n",
      "-------------Round number:  235  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.19590770849556474\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16047374743251175\n",
      "-------------Round number:  236  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9440231130371975\n",
      "Average Global Trainning Loss:  0.19588716506269185\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16247719502612631\n",
      "-------------Round number:  237  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9447453954496208\n",
      "Average Global Trainning Loss:  0.19130703756291756\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.1610794480676124\n",
      "-------------Round number:  238  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19275202119165313\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16239177005391725\n",
      "-------------Round number:  239  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.1921915072919488\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.1612440710594698\n",
      "-------------Round number:  240  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.1907600135569023\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.1615163817565852\n",
      "-------------Round number:  241  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19297899085720252\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.16206402294727904\n",
      "-------------Round number:  242  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.19135059316737765\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9547670639219935\n",
      "Average Personal Trainning Loss:  0.16140121068709937\n",
      "-------------Round number:  243  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.18984327388610509\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.1588873734066055\n",
      "-------------Round number:  244  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.19078132847062343\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16041993113277017\n",
      "-------------Round number:  245  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9449259660527266\n",
      "Average Global Trainning Loss:  0.1925129943825614\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.1620148575749368\n",
      "-------------Round number:  246  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.19292362057460952\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16167513047284104\n",
      "-------------Round number:  247  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.1933262013235261\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16012471847561732\n",
      "-------------Round number:  248  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.19671917409404344\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.16414213886584733\n",
      "-------------Round number:  249  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.19051137630067264\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16159527118389422\n",
      "-------------Round number:  250  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.18943696798680706\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16033524457794443\n",
      "-------------Round number:  251  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.1923162888085726\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16111924545822612\n",
      "-------------Round number:  252  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.18766864571342318\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.1591747169591064\n",
      "-------------Round number:  253  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.18510514710861323\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15655030443075119\n",
      "-------------Round number:  254  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.1873168504466301\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.1580864660745926\n",
      "-------------Round number:  255  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.18705957260490025\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.1572947063012087\n",
      "-------------Round number:  256  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.186002467504345\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.15731944879412693\n",
      "-------------Round number:  257  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9456482484651498\n",
      "Average Global Trainning Loss:  0.18806809645432693\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.15853621736680096\n",
      "-------------Round number:  258  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.186915371813211\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15595161325021442\n",
      "-------------Round number:  259  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.18614516941895765\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.15607280187031644\n",
      "-------------Round number:  260  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9410436980859516\n",
      "Average Global Trainning Loss:  0.19835817413495396\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.1646618193863703\n",
      "-------------Round number:  261  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.19649868486761918\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9540447815095703\n",
      "Average Personal Trainning Loss:  0.1649631157210692\n",
      "-------------Round number:  262  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.943571686529433\n",
      "Average Global Trainning Loss:  0.19834014352541532\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.166052248297981\n",
      "-------------Round number:  263  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.2008770370621163\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.166583247544663\n",
      "-------------Round number:  264  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.199923266310604\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9541350668111231\n",
      "Average Personal Trainning Loss:  0.16440541221588345\n",
      "-------------Round number:  265  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19646088230605588\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16498089284404344\n",
      "-------------Round number:  266  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.940592271578187\n",
      "Average Global Trainning Loss:  0.2029979260831415\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9527807872878296\n",
      "Average Personal Trainning Loss:  0.16867901935350083\n",
      "-------------Round number:  267  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9449259660527266\n",
      "Average Global Trainning Loss:  0.19392506884254243\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16387767523107394\n",
      "-------------Round number:  268  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.19621535301552906\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16575847941212982\n",
      "-------------Round number:  269  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9451065366558324\n",
      "Average Global Trainning Loss:  0.19560383321060176\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.16321905100978468\n",
      "-------------Round number:  270  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.2010552491380575\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9539544962080173\n",
      "Average Personal Trainning Loss:  0.16944021746413981\n",
      "-------------Round number:  271  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9442939689418562\n",
      "Average Global Trainning Loss:  0.20075937521160617\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.1676734712159173\n",
      "-------------Round number:  272  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9432105453232213\n",
      "Average Global Trainning Loss:  0.2020235237295165\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16869235495102022\n",
      "-------------Round number:  273  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.942578548212351\n",
      "Average Global Trainning Loss:  0.20493149955421633\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16895042631590826\n",
      "-------------Round number:  274  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9452871072589383\n",
      "Average Global Trainning Loss:  0.19856629762549657\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16784327415061281\n",
      "-------------Round number:  275  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.2012813811958288\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9551282051282052\n",
      "Average Personal Trainning Loss:  0.16685217474720115\n",
      "-------------Round number:  276  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.20431537290650956\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.1701277281326178\n",
      "-------------Round number:  277  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20452010188131997\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16965542755733118\n",
      "-------------Round number:  278  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.2056726060993364\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16929023056608883\n",
      "-------------Round number:  279  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9405019862766342\n",
      "Average Global Trainning Loss:  0.20779856485164996\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.1706312295976379\n",
      "-------------Round number:  280  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9411339833875045\n",
      "Average Global Trainning Loss:  0.20544949383802816\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.1669720077652413\n",
      "-------------Round number:  281  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19689006812308144\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9546767786204406\n",
      "Average Personal Trainning Loss:  0.16620237847104663\n",
      "-------------Round number:  282  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.19924052780223006\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9534127843986999\n",
      "Average Personal Trainning Loss:  0.16541363849412583\n",
      "-------------Round number:  283  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.20575660934255371\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.17013552008918495\n",
      "-------------Round number:  284  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.19971218915052816\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16529165635086562\n",
      "-------------Round number:  285  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19637229426236907\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16428297820526927\n",
      "-------------Round number:  286  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9409534127843987\n",
      "Average Global Trainning Loss:  0.20246575859403215\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9524196460816179\n",
      "Average Personal Trainning Loss:  0.16827883019521375\n",
      "-------------Round number:  287  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19673478004948763\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16315844567857868\n",
      "-------------Round number:  288  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9467316720837847\n",
      "Average Global Trainning Loss:  0.18930707265427502\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15824609648324645\n",
      "-------------Round number:  289  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9192764578833693\n",
      "Average Global Trainning Accurancy:  0.9441133983387504\n",
      "Average Global Trainning Loss:  0.19472141341639582\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.1640145800181699\n",
      "-------------Round number:  290  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9433911159263272\n",
      "Average Global Trainning Loss:  0.19715045393051417\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9535933550018058\n",
      "Average Personal Trainning Loss:  0.16662660476833355\n",
      "-------------Round number:  291  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9421271217045865\n",
      "Average Global Trainning Loss:  0.20210503619170955\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.1689153239373138\n",
      "-------------Round number:  292  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.1994623616095612\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.1684949109596481\n",
      "-------------Round number:  293  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9433008306247743\n",
      "Average Global Trainning Loss:  0.19670709490819113\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.16703654764877324\n",
      "-------------Round number:  294  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9428494041170098\n",
      "Average Global Trainning Loss:  0.19775258371140303\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.16616776102327105\n",
      "-------------Round number:  295  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9408631274828458\n",
      "Average Global Trainning Loss:  0.2060983753583198\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17264963289855317\n",
      "-------------Round number:  296  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9423979776092453\n",
      "Average Global Trainning Loss:  0.20263021626856492\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9536836403033586\n",
      "Average Personal Trainning Loss:  0.17101635283707453\n",
      "-------------Round number:  297  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9419465511014807\n",
      "Average Global Trainning Loss:  0.20256492694649467\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16719919785389017\n",
      "-------------Round number:  298  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9442036836403034\n",
      "Average Global Trainning Loss:  0.1949617627640845\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9561213434452871\n",
      "Average Personal Trainning Loss:  0.16428016781075072\n",
      "-------------Round number:  299  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9423076923076923\n",
      "Average Global Trainning Loss:  0.20328892865909398\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9544962080173348\n",
      "Average Personal Trainning Loss:  0.1696297372450851\n",
      "-------------Round number:  300  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19588114751207567\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9559407728421813\n",
      "Average Personal Trainning Loss:  0.16538113710810537\n",
      "-------------Round number:  301  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9413145539906104\n",
      "Average Global Trainning Loss:  0.20255251712599315\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9519682195738534\n",
      "Average Personal Trainning Loss:  0.17116385997525618\n",
      "-------------Round number:  302  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.19461847582893194\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.16554341259395314\n",
      "-------------Round number:  303  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.19156958351672534\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.1627372501989098\n",
      "-------------Round number:  304  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9438425424340917\n",
      "Average Global Trainning Loss:  0.1922302576728399\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.162513961599122\n",
      "-------------Round number:  305  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.19093419189012278\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.16104921703951675\n",
      "-------------Round number:  306  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.19278182239470476\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.15875086538108862\n",
      "-------------Round number:  307  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9434814012278802\n",
      "Average Global Trainning Loss:  0.19247281125152357\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9553990610328639\n",
      "Average Personal Trainning Loss:  0.16050239141429104\n",
      "-------------Round number:  308  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9446551101480679\n",
      "Average Global Trainning Loss:  0.19184475971413417\n",
      "Average Personal Accurancy:  0.9262958963282938\n",
      "Average Personal Trainning Accurancy:  0.9550379198266522\n",
      "Average Personal Trainning Loss:  0.16231482034988376\n",
      "-------------Round number:  309  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.18729154587480815\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9563019140483929\n",
      "Average Personal Trainning Loss:  0.15816105725146148\n",
      "-------------Round number:  310  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9465511014806789\n",
      "Average Global Trainning Loss:  0.18772361923443706\n",
      "Average Personal Accurancy:  0.9260259179265659\n",
      "Average Personal Trainning Accurancy:  0.9567533405561575\n",
      "Average Personal Trainning Loss:  0.15832564717985395\n",
      "-------------Round number:  311  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.18905340975137686\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.1593138810829722\n",
      "-------------Round number:  312  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18354190648699892\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15480217291328097\n",
      "-------------Round number:  313  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.946460816179126\n",
      "Average Global Trainning Loss:  0.18779735076121795\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.1578316349292671\n",
      "-------------Round number:  314  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.1864983313089676\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15758644729454452\n",
      "-------------Round number:  315  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.18419313551330016\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.15476083256097078\n",
      "-------------Round number:  316  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.18589461448176237\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.15720090525121885\n",
      "-------------Round number:  317  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.1889705967928968\n",
      "Average Personal Accurancy:  0.925755939524838\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.1588160444916091\n",
      "-------------Round number:  318  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.19300098908253205\n",
      "Average Personal Accurancy:  0.9254859611231101\n",
      "Average Personal Trainning Accurancy:  0.9557602022390754\n",
      "Average Personal Trainning Loss:  0.15963498243316065\n",
      "-------------Round number:  319  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9141468682505399\n",
      "Average Global Trainning Accurancy:  0.9400505597688696\n",
      "Average Global Trainning Loss:  0.19574684371755371\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16294229878721447\n",
      "-------------Round number:  320  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.18732804794008442\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9560310581437342\n",
      "Average Personal Trainning Loss:  0.15871333834839968\n",
      "-------------Round number:  321  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9165766738660908\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.189664576879345\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9556699169375226\n",
      "Average Personal Trainning Loss:  0.15671071734140823\n",
      "-------------Round number:  322  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9429396894185627\n",
      "Average Global Trainning Loss:  0.19401583907491424\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.16299122169414726\n",
      "-------------Round number:  323  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.91792656587473\n",
      "Average Global Trainning Accurancy:  0.9439328277356447\n",
      "Average Global Trainning Loss:  0.19322747381726255\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.1619556960150325\n",
      "-------------Round number:  324  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.19735039972406554\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9553087757313109\n",
      "Average Personal Trainning Loss:  0.16320214455805346\n",
      "-------------Round number:  325  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9163066954643628\n",
      "Average Global Trainning Accurancy:  0.94068255687974\n",
      "Average Global Trainning Loss:  0.19813415813893778\n",
      "Average Personal Accurancy:  0.9271058315334774\n",
      "Average Personal Trainning Accurancy:  0.9548573492235464\n",
      "Average Personal Trainning Loss:  0.1628295082872032\n",
      "-------------Round number:  326  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9454676778620441\n",
      "Average Global Trainning Loss:  0.18922461237275415\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.1597576038034094\n",
      "-------------Round number:  327  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.19257383115802185\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9566630552546046\n",
      "Average Personal Trainning Loss:  0.16170656280682896\n",
      "-------------Round number:  328  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19710050605616874\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9558504875406284\n",
      "Average Personal Trainning Loss:  0.16623711715152695\n",
      "-------------Round number:  329  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9176565874730022\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.1988330536605047\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9565727699530516\n",
      "Average Personal Trainning Loss:  0.16571936533312454\n",
      "-------------Round number:  330  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9157667386609071\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.20461600797190999\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9544059227157818\n",
      "Average Personal Trainning Loss:  0.1693019791172919\n",
      "-------------Round number:  331  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9184665226781857\n",
      "Average Global Trainning Accurancy:  0.9437522571325389\n",
      "Average Global Trainning Loss:  0.19407136365367686\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9562116287468401\n",
      "Average Personal Trainning Loss:  0.16403583982611616\n",
      "-------------Round number:  332  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9460996749729144\n",
      "Average Global Trainning Loss:  0.19148952584698897\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9572950523654749\n",
      "Average Personal Trainning Loss:  0.16186524539615496\n",
      "-------------Round number:  333  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9443842542434092\n",
      "Average Global Trainning Loss:  0.1971203220928133\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16600085665233388\n",
      "-------------Round number:  334  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9417659804983749\n",
      "Average Global Trainning Loss:  0.19858712760839878\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16696828261485983\n",
      "-------------Round number:  335  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9454676778620441\n",
      "Average Global Trainning Loss:  0.1909057132256681\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.1623307679611322\n",
      "-------------Round number:  336  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9470928132899964\n",
      "Average Global Trainning Loss:  0.18818322343919286\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15994539326302365\n",
      "-------------Round number:  337  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18587700267611276\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.15789509473961155\n",
      "-------------Round number:  338  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9478150957024196\n",
      "Average Global Trainning Loss:  0.18509106207255552\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.1579252816830873\n",
      "-------------Round number:  339  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.18247134455621952\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.15558730897252507\n",
      "-------------Round number:  340  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.18027249188490316\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.15431832216758082\n",
      "-------------Round number:  341  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.18247059511768124\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15614107792538484\n",
      "-------------Round number:  342  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9498013723365836\n",
      "Average Global Trainning Loss:  0.18072109697699418\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.1545404866095612\n",
      "-------------Round number:  343  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.18057554058324304\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.15245445750172107\n",
      "-------------Round number:  344  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.1821119446924939\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15433383995378522\n",
      "-------------Round number:  345  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.1859604769038913\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.1549014735196032\n",
      "-------------Round number:  346  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9444745395449621\n",
      "Average Global Trainning Loss:  0.19158549806450884\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15882055214399377\n",
      "-------------Round number:  347  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.18386761467996682\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.15535887349336402\n",
      "-------------Round number:  348  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9475442397977609\n",
      "Average Global Trainning Loss:  0.1849894470236886\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.1563164024587227\n",
      "-------------Round number:  349  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.18161199203937567\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.15218259867195963\n",
      "-------------Round number:  350  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.1857046097699982\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9564824846514988\n",
      "Average Personal Trainning Loss:  0.15600495564029207\n",
      "-------------Round number:  351  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.1846025273359911\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.15198716053079292\n",
      "-------------Round number:  352  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.18493676590290944\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15137306177560153\n",
      "-------------Round number:  353  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.17840787778050515\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9592813289996388\n",
      "Average Personal Trainning Loss:  0.15023690193041261\n",
      "-------------Round number:  354  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.18454552592246184\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15206802274484246\n",
      "-------------Round number:  355  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9480859516070783\n",
      "Average Global Trainning Loss:  0.18055204348083695\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15022968307390416\n",
      "-------------Round number:  356  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.17932308551076087\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.1496102059950851\n",
      "-------------Round number:  357  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.17524291066410483\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14695956311789005\n",
      "-------------Round number:  358  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.17397855274424995\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.1457621476933516\n",
      "-------------Round number:  359  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.1735833341268565\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14871623603046566\n",
      "-------------Round number:  360  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.949349945828819\n",
      "Average Global Trainning Loss:  0.17447107713891521\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.1486658583310762\n",
      "-------------Round number:  361  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.1796342347580072\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9576561935716865\n",
      "Average Personal Trainning Loss:  0.15016060247452262\n",
      "-------------Round number:  362  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9469122426868906\n",
      "Average Global Trainning Loss:  0.1788049810153993\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.1494760124121129\n",
      "-------------Round number:  363  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9463705308775732\n",
      "Average Global Trainning Loss:  0.1805870246267267\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15133725404308865\n",
      "-------------Round number:  364  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9466413867822319\n",
      "Average Global Trainning Loss:  0.18039460628202306\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.15038322980501195\n",
      "-------------Round number:  365  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9487179487179487\n",
      "Average Global Trainning Loss:  0.17453728121684836\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14538440862774807\n",
      "-------------Round number:  366  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17230517772097328\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14432701697716346\n",
      "-------------Round number:  367  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9491693752257132\n",
      "Average Global Trainning Loss:  0.17497272704989955\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.14892650864622833\n",
      "-------------Round number:  368  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9496208017334777\n",
      "Average Global Trainning Loss:  0.1776276571563798\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.15177470572634524\n",
      "-------------Round number:  369  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.17606430632321574\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9591007583965331\n",
      "Average Personal Trainning Loss:  0.1492637449672998\n",
      "-------------Round number:  370  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.1833186068660561\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.15515552216292547\n",
      "-------------Round number:  371  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9489888046226075\n",
      "Average Global Trainning Loss:  0.1807374854344416\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.1539995132176271\n",
      "-------------Round number:  372  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.18192176364225013\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15458719426434409\n",
      "-------------Round number:  373  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.1814904287000045\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.1533915422246016\n",
      "-------------Round number:  374  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9432105453232213\n",
      "Average Global Trainning Loss:  0.19124157190236774\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16173485411164906\n",
      "-------------Round number:  375  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9461899602744673\n",
      "Average Global Trainning Loss:  0.18865041019857123\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15818233910171767\n",
      "-------------Round number:  376  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9431202600216685\n",
      "Average Global Trainning Loss:  0.1937514856516906\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.16179538229477022\n",
      "-------------Round number:  377  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9168466522678186\n",
      "Average Global Trainning Accurancy:  0.9401408450704225\n",
      "Average Global Trainning Loss:  0.2007850765450072\n",
      "Average Personal Accurancy:  0.9279157667386609\n",
      "Average Personal Trainning Accurancy:  0.954225352112676\n",
      "Average Personal Trainning Loss:  0.16469458528011016\n",
      "-------------Round number:  378  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9130669546436285\n",
      "Average Global Trainning Accurancy:  0.9374322860238353\n",
      "Average Global Trainning Loss:  0.2066776031791712\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.953322499097147\n",
      "Average Personal Trainning Loss:  0.1678207358886895\n",
      "-------------Round number:  379  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9136069114470843\n",
      "Average Global Trainning Accurancy:  0.9368905742145178\n",
      "Average Global Trainning Loss:  0.20846014274247246\n",
      "Average Personal Accurancy:  0.9268358531317494\n",
      "Average Personal Trainning Accurancy:  0.951336222462983\n",
      "Average Personal Trainning Loss:  0.1669896195708909\n",
      "-------------Round number:  380  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9133369330453563\n",
      "Average Global Trainning Accurancy:  0.9389671361502347\n",
      "Average Global Trainning Loss:  0.20299164402480588\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9545864933188877\n",
      "Average Personal Trainning Loss:  0.16004698626958064\n",
      "-------------Round number:  381  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.911987041036717\n",
      "Average Global Trainning Accurancy:  0.9382448537378115\n",
      "Average Global Trainning Loss:  0.20423767376393778\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.955218490429758\n",
      "Average Personal Trainning Loss:  0.16095299133543248\n",
      "-------------Round number:  382  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9090172786177105\n",
      "Average Global Trainning Accurancy:  0.9343625857710365\n",
      "Average Global Trainning Loss:  0.21382286041469167\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9530516431924883\n",
      "Average Personal Trainning Loss:  0.16403341517202172\n",
      "-------------Round number:  383  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9095572354211663\n",
      "Average Global Trainning Accurancy:  0.9347237269772481\n",
      "Average Global Trainning Loss:  0.2140777136023271\n",
      "Average Personal Accurancy:  0.9265658747300216\n",
      "Average Personal Trainning Accurancy:  0.9516070783676418\n",
      "Average Personal Trainning Loss:  0.1680116002505417\n",
      "-------------Round number:  384  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9144168466522679\n",
      "Average Global Trainning Accurancy:  0.9391477067533406\n",
      "Average Global Trainning Loss:  0.20266852580325703\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9570241964608162\n",
      "Average Personal Trainning Loss:  0.1589961962908259\n",
      "-------------Round number:  385  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9125269978401728\n",
      "Average Global Trainning Accurancy:  0.938696280245576\n",
      "Average Global Trainning Loss:  0.207557906911622\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9537739256049115\n",
      "Average Personal Trainning Loss:  0.16647000517729776\n",
      "-------------Round number:  386  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.19150074538275325\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9579270494763452\n",
      "Average Personal Trainning Loss:  0.1575415911937974\n",
      "-------------Round number:  387  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.18135112130112405\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9571144817623691\n",
      "Average Personal Trainning Loss:  0.15404735605137235\n",
      "-------------Round number:  388  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9187365010799136\n",
      "Average Global Trainning Accurancy:  0.9436619718309859\n",
      "Average Global Trainning Loss:  0.18937051042230948\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9549476345250993\n",
      "Average Personal Trainning Loss:  0.16063495386632698\n",
      "-------------Round number:  389  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.18500481051372336\n",
      "Average Personal Accurancy:  0.9281857451403888\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15721713941249663\n",
      "-------------Round number:  390  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9474539544962081\n",
      "Average Global Trainning Loss:  0.18344765356965512\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.15445090666192668\n",
      "-------------Round number:  391  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9458288190682557\n",
      "Average Global Trainning Loss:  0.18506271566196056\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9563921993499458\n",
      "Average Personal Trainning Loss:  0.1561307731454835\n",
      "-------------Round number:  392  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9471830985915493\n",
      "Average Global Trainning Loss:  0.18385984476570963\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.15321230518124773\n",
      "-------------Round number:  393  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9460093896713615\n",
      "Average Global Trainning Loss:  0.18306855890198967\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15292304394778125\n",
      "-------------Round number:  394  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.94844709281329\n",
      "Average Global Trainning Loss:  0.17842781504985442\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15010865977112675\n",
      "-------------Round number:  395  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.948537378114843\n",
      "Average Global Trainning Loss:  0.17654271261835838\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.14793885886432376\n",
      "-------------Round number:  396  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9181965442764579\n",
      "Average Global Trainning Accurancy:  0.945557963163597\n",
      "Average Global Trainning Loss:  0.18280874619461562\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.1505910006185954\n",
      "-------------Round number:  397  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.17712527984916712\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9583784759841097\n",
      "Average Personal Trainning Loss:  0.14827971012422694\n",
      "-------------Round number:  398  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9475442397977609\n",
      "Average Global Trainning Loss:  0.1765273160648587\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9586493318887686\n",
      "Average Personal Trainning Loss:  0.14698679639183257\n",
      "-------------Round number:  399  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9483568075117371\n",
      "Average Global Trainning Loss:  0.17660062878775054\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.1481117477224122\n",
      "-------------Round number:  400  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9490790899241603\n",
      "Average Global Trainning Loss:  0.1775571107433866\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.15133042092700433\n",
      "-------------Round number:  401  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.1736804966291136\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14789974478531848\n",
      "-------------Round number:  402  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17459229882248217\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14755243512860014\n",
      "-------------Round number:  403  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17500871112089203\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.14824444242830784\n",
      "-------------Round number:  404  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17854738356017516\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15187461249619108\n",
      "-------------Round number:  405  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.17381139488674838\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.148336358860797\n",
      "-------------Round number:  406  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9511556518598772\n",
      "Average Global Trainning Loss:  0.17375032666703344\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14775470638585117\n",
      "-------------Round number:  407  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1737142103421813\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9599133261105092\n",
      "Average Personal Trainning Loss:  0.14692830712238172\n",
      "-------------Round number:  408  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.1721166057593558\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14614644434616514\n",
      "-------------Round number:  409  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17317856016809993\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.1470425413936947\n",
      "-------------Round number:  410  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.17218577452797715\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14661117338798416\n",
      "-------------Round number:  411  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9495305164319249\n",
      "Average Global Trainning Loss:  0.17342658023965105\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14611086805790674\n",
      "-------------Round number:  412  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1721363997536904\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14724041521011083\n",
      "-------------Round number:  413  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.1719802410088536\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.1461622817458638\n",
      "-------------Round number:  414  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16896173402091233\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14328658688408497\n",
      "-------------Round number:  415  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1705269033446472\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14465726588598096\n",
      "-------------Round number:  416  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1690743151189791\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14394517804190932\n",
      "-------------Round number:  417  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.17031952929264288\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14213702531444677\n",
      "-------------Round number:  418  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.16859039824634908\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14238026220473884\n",
      "-------------Round number:  419  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.1688998392145743\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14367163297543675\n",
      "-------------Round number:  420  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16843553999779928\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.14077137195921927\n",
      "-------------Round number:  421  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17041497249472395\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.1421455226249323\n",
      "-------------Round number:  422  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17166736144027628\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.1427196366298754\n",
      "-------------Round number:  423  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.1723678550293145\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14541555441170662\n",
      "-------------Round number:  424  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9479956663055255\n",
      "Average Global Trainning Loss:  0.17606857151019095\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14725127104776092\n",
      "-------------Round number:  425  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17601363105264198\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.14673793871250337\n",
      "-------------Round number:  426  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17206157713256703\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14544854072854596\n",
      "-------------Round number:  427  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16927897796685965\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1424527373198526\n",
      "-------------Round number:  428  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.167538451046322\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9605453232213795\n",
      "Average Personal Trainning Loss:  0.14293493489230658\n",
      "-------------Round number:  429  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.170211797502765\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.1448318960865554\n",
      "-------------Round number:  430  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1708450840887674\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9588299024918743\n",
      "Average Personal Trainning Loss:  0.14533335863790517\n",
      "-------------Round number:  431  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.1688353985214371\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14466423125592498\n",
      "-------------Round number:  432  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17195349266572996\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9594618996027446\n",
      "Average Personal Trainning Loss:  0.14372672772915537\n",
      "-------------Round number:  433  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.1747307796347395\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.958197905381004\n",
      "Average Personal Trainning Loss:  0.14834334627305096\n",
      "-------------Round number:  434  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17711127196119425\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9580173347778982\n",
      "Average Personal Trainning Loss:  0.15039193651744198\n",
      "-------------Round number:  435  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9488985193210545\n",
      "Average Global Trainning Loss:  0.1781361622257584\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.147972759937026\n",
      "-------------Round number:  436  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16921023902328233\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14325846089658947\n",
      "-------------Round number:  437  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16842972082797264\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.1426675396303099\n",
      "-------------Round number:  438  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.17225684995640914\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14482597772633396\n",
      "-------------Round number:  439  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16768291634573063\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14057084204445422\n",
      "-------------Round number:  440  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.1684738605536464\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.142644395204863\n",
      "-------------Round number:  441  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16626162820019072\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14079360162880328\n",
      "-------------Round number:  442  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.949440231130372\n",
      "Average Global Trainning Loss:  0.17180313104840986\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1445640709995147\n",
      "-------------Round number:  443  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17099920391993387\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.1433133352272086\n",
      "-------------Round number:  444  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16639642794668652\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.1402399539086482\n",
      "-------------Round number:  445  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1729747239068425\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.14548093190301667\n",
      "-------------Round number:  446  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.1719785437509875\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9600036114120621\n",
      "Average Personal Trainning Loss:  0.1460705526730092\n",
      "-------------Round number:  447  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17108796830210027\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14486079355489911\n",
      "-------------Round number:  448  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.17044957892134457\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14442998762809228\n",
      "-------------Round number:  449  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1684287399451799\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14232807703593356\n",
      "-------------Round number:  450  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17072713568822792\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14538447475467792\n",
      "-------------Round number:  451  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.17213655404986006\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.1460629260337667\n",
      "-------------Round number:  452  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9486276634163958\n",
      "Average Global Trainning Loss:  0.17646777978568526\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9578367641747924\n",
      "Average Personal Trainning Loss:  0.15069294630211155\n",
      "-------------Round number:  453  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9492596605272662\n",
      "Average Global Trainning Loss:  0.17361176870669126\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14654158581547377\n",
      "-------------Round number:  454  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.17004182925074485\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14308398499218467\n",
      "-------------Round number:  455  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.17103840616817895\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14589020249300289\n",
      "-------------Round number:  456  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16806224245765056\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14245336552568616\n",
      "-------------Round number:  457  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1666309360822386\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14212710627496952\n",
      "-------------Round number:  458  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16611299690420164\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14107619506351007\n",
      "-------------Round number:  459  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.16461814254920548\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.14092519421920144\n",
      "-------------Round number:  460  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16429803310296473\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.1402584804701607\n",
      "-------------Round number:  461  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.1661727866699395\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14142109108728895\n",
      "-------------Round number:  462  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.1672867719513193\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.14065319211442534\n",
      "-------------Round number:  463  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16914818992077466\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14121531510275595\n",
      "-------------Round number:  464  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16628925823571236\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14101015630290153\n",
      "-------------Round number:  465  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.16884720217841503\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.14209113322513203\n",
      "-------------Round number:  466  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16836724190042096\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.1405615181473456\n",
      "-------------Round number:  467  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.1700828389684058\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.14330353742043608\n",
      "-------------Round number:  468  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.1681952347347305\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.14139719722330377\n",
      "-------------Round number:  469  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.17056149875011287\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.14229973062533857\n",
      "-------------Round number:  470  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.17186103619664703\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9595521849042976\n",
      "Average Personal Trainning Loss:  0.14522257398809926\n",
      "-------------Round number:  471  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9501625135427952\n",
      "Average Global Trainning Loss:  0.17252176545853648\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14323371840367122\n",
      "-------------Round number:  472  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9488082340195017\n",
      "Average Global Trainning Loss:  0.17262999320038822\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9591910436980859\n",
      "Average Personal Trainning Loss:  0.1439922604159613\n",
      "-------------Round number:  473  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9454676778620441\n",
      "Average Global Trainning Loss:  0.18037350077024647\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.1491850539207803\n",
      "-------------Round number:  474  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9198164146868251\n",
      "Average Global Trainning Accurancy:  0.9457385337667028\n",
      "Average Global Trainning Loss:  0.1805169300810875\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9569339111592633\n",
      "Average Personal Trainning Loss:  0.15145837653626085\n",
      "-------------Round number:  475  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.16876690204326922\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14392606735918315\n",
      "-------------Round number:  476  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.16839589690335524\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.14294296931428313\n",
      "-------------Round number:  477  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9507042253521126\n",
      "Average Global Trainning Loss:  0.17136376168418765\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.1477133219489211\n",
      "-------------Round number:  478  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.17247592847499663\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9590104730949801\n",
      "Average Personal Trainning Loss:  0.14676582223458942\n",
      "-------------Round number:  479  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.952239075478512\n",
      "Average Global Trainning Loss:  0.1682488526536825\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14502036885777808\n",
      "-------------Round number:  480  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16836891711597712\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14158414907513994\n",
      "-------------Round number:  481  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.951426507764536\n",
      "Average Global Trainning Loss:  0.16978722954967385\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14370458622881116\n",
      "-------------Round number:  482  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.16899782830345453\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14438562747931902\n",
      "-------------Round number:  483  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.17154589729129988\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.1430610830321472\n",
      "-------------Round number:  484  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16719714791906487\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.1412476511714518\n",
      "-------------Round number:  485  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9506139400505598\n",
      "Average Global Trainning Loss:  0.17024689988135946\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.14265082053821326\n",
      "-------------Round number:  486  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16709216039677569\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1407977345619188\n",
      "-------------Round number:  487  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.16497181141234427\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13910488515780178\n",
      "-------------Round number:  488  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16519739241236683\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.1409600871958514\n",
      "-------------Round number:  489  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16616522615762686\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14139488278075907\n",
      "-------------Round number:  490  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.1724470310066529\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9608161791260382\n",
      "Average Personal Trainning Loss:  0.14606753287654614\n",
      "-------------Round number:  491  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9499819429396894\n",
      "Average Global Trainning Loss:  0.16944660973402514\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14246858574070626\n",
      "-------------Round number:  492  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9477248104008668\n",
      "Average Global Trainning Loss:  0.17430017208872223\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9596424702058505\n",
      "Average Personal Trainning Loss:  0.1456672886124842\n",
      "-------------Round number:  493  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9190064794816415\n",
      "Average Global Trainning Accurancy:  0.9459191043698086\n",
      "Average Global Trainning Loss:  0.17960652757440074\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9585590465872156\n",
      "Average Personal Trainning Loss:  0.14723538956344234\n",
      "-------------Round number:  494  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.18592465815022347\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9574756229685807\n",
      "Average Personal Trainning Loss:  0.15042937538089113\n",
      "-------------Round number:  495  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9173866090712743\n",
      "Average Global Trainning Accurancy:  0.9448356807511737\n",
      "Average Global Trainning Loss:  0.18566574917755732\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.15136682380188585\n",
      "-------------Round number:  496  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9127969762419006\n",
      "Average Global Trainning Accurancy:  0.9414048392921632\n",
      "Average Global Trainning Loss:  0.19300522120604235\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9554893463344167\n",
      "Average Personal Trainning Loss:  0.15485305758579926\n",
      "-------------Round number:  497  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9111771058315334\n",
      "Average Global Trainning Accurancy:  0.9386059949440231\n",
      "Average Global Trainning Loss:  0.20030938145398836\n",
      "Average Personal Accurancy:  0.927645788336933\n",
      "Average Personal Trainning Accurancy:  0.9555796316359697\n",
      "Average Personal Trainning Loss:  0.1575394200262674\n",
      "-------------Round number:  498  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.916036717062635\n",
      "Average Global Trainning Accurancy:  0.9430299747201155\n",
      "Average Global Trainning Loss:  0.1881867281664748\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9587396171903214\n",
      "Average Personal Trainning Loss:  0.15044749415966954\n",
      "-------------Round number:  499  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9154967602591793\n",
      "Average Global Trainning Accurancy:  0.9418562657999278\n",
      "Average Global Trainning Loss:  0.19315535137910797\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9573853376670278\n",
      "Average Personal Trainning Loss:  0.1523593559554442\n",
      "-------------Round number:  500  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9479053810039726\n",
      "Average Global Trainning Loss:  0.18157792564934883\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9606356085229325\n",
      "Average Personal Trainning Loss:  0.14737358382567037\n",
      "-------------Round number:  501  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1677750091166994\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14338081775911882\n",
      "-------------Round number:  502  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.1660457899011658\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1424588099762437\n",
      "-------------Round number:  503  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16607836843527107\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.14147028952309612\n",
      "-------------Round number:  504  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16324949143982484\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.1385430046348806\n",
      "-------------Round number:  505  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16296845198796947\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13812718747883937\n",
      "-------------Round number:  506  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16367351935632224\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13787969642272707\n",
      "-------------Round number:  507  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.1617389319389897\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13683603713124098\n",
      "-------------Round number:  508  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9520585048754063\n",
      "Average Global Trainning Loss:  0.16247612597409375\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.13767889097908767\n",
      "-------------Round number:  509  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16479459124035076\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.13964579242280606\n",
      "-------------Round number:  510  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.16538690117215715\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1384149608563843\n",
      "-------------Round number:  511  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.16922763040583244\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14411222568786114\n",
      "-------------Round number:  512  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.169140629408462\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.960184182015168\n",
      "Average Personal Trainning Loss:  0.14190522838301847\n",
      "-------------Round number:  513  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9500722282412424\n",
      "Average Global Trainning Loss:  0.17372204638336833\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9603647526182737\n",
      "Average Personal Trainning Loss:  0.14197218189948987\n",
      "-------------Round number:  514  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9498916576381365\n",
      "Average Global Trainning Loss:  0.17183483891127213\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9597327555074034\n",
      "Average Personal Trainning Loss:  0.14541912526591844\n",
      "-------------Round number:  515  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9497110870350307\n",
      "Average Global Trainning Loss:  0.17368704319516862\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9593716143011918\n",
      "Average Personal Trainning Loss:  0.1448005078371874\n",
      "-------------Round number:  516  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.1786509493534726\n",
      "Average Personal Accurancy:  0.9284557235421166\n",
      "Average Personal Trainning Accurancy:  0.9584687612856627\n",
      "Average Personal Trainning Loss:  0.14733083276552342\n",
      "-------------Round number:  517  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9171166306695464\n",
      "Average Global Trainning Accurancy:  0.9450162513542795\n",
      "Average Global Trainning Loss:  0.18463534833550582\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9582881906825569\n",
      "Average Personal Trainning Loss:  0.14848228997381727\n",
      "-------------Round number:  518  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16893185566977587\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.1418045942169443\n",
      "-------------Round number:  519  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16893359701226188\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14227995867331392\n",
      "-------------Round number:  520  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.17041979976060287\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.1422785369443222\n",
      "-------------Round number:  521  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16621332247793652\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.14112289169713796\n",
      "-------------Round number:  522  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9298056155507559\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16523658363945692\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13975504513207046\n",
      "-------------Round number:  523  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9507945106536656\n",
      "Average Global Trainning Loss:  0.1716124981308121\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.14414122234659962\n",
      "-------------Round number:  524  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.171946064407277\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14280852224474652\n",
      "-------------Round number:  525  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9512459371614301\n",
      "Average Global Trainning Loss:  0.17486185423085387\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.14722597749709393\n",
      "-------------Round number:  526  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16959480018381523\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14562760143342024\n",
      "-------------Round number:  527  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9289956803455723\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1654257287011331\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.1412808579113906\n",
      "-------------Round number:  528  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16323515291720272\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13937976378402628\n",
      "-------------Round number:  529  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.1631443165579011\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13957126737286701\n",
      "-------------Round number:  530  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16155549583559048\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13830257813910707\n",
      "-------------Round number:  531  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.16164086570202466\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1369650287290651\n",
      "-------------Round number:  532  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.162537491764993\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13662125686309362\n",
      "-------------Round number:  533  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.16252582036187477\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13908472746535303\n",
      "-------------Round number:  534  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16174619488011804\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13722746447132314\n",
      "-------------Round number:  535  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1634087250868996\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.1359558987161148\n",
      "-------------Round number:  536  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.16248873417538484\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.1375101570964247\n",
      "-------------Round number:  537  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16309480952975464\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.1361363480865159\n",
      "-------------Round number:  538  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16183273298897954\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13683059268068345\n",
      "-------------Round number:  539  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.16360567312629784\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13641071973961155\n",
      "-------------Round number:  540  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.1596994892532277\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1353402790415369\n",
      "-------------Round number:  541  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9555796316359697\n",
      "Average Global Trainning Loss:  0.15867171144606018\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1358229284813448\n",
      "-------------Round number:  542  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.16070727468527107\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1366098940523147\n",
      "-------------Round number:  543  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16215881590121659\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.1375988773939712\n",
      "-------------Round number:  544  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16488191185121548\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14157136453536925\n",
      "-------------Round number:  545  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16628572044496548\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14343490958773475\n",
      "-------------Round number:  546  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16491440221608095\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.1412858394734392\n",
      "-------------Round number:  547  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.16340146214577125\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.13973840318805864\n",
      "-------------Round number:  548  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.16268125171048325\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.14070716271033654\n",
      "-------------Round number:  549  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16714125964218807\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14273272976198537\n",
      "-------------Round number:  550  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.167335287075518\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.1420816440106988\n",
      "-------------Round number:  551  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16606988214594054\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.14238343629737157\n",
      "-------------Round number:  552  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.16185822492043608\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13868322678962397\n",
      "-------------Round number:  553  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.16341889761294126\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.13992663349387188\n",
      "-------------Round number:  554  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9509750812567714\n",
      "Average Global Trainning Loss:  0.17195254484640213\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9609064644275912\n",
      "Average Personal Trainning Loss:  0.14560768620638093\n",
      "-------------Round number:  555  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.17357629160882765\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.14649569372615903\n",
      "-------------Round number:  556  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.16923643630865723\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14321775977126783\n",
      "-------------Round number:  557  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.17175158510659308\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9607258938244854\n",
      "Average Personal Trainning Loss:  0.14673285796006005\n",
      "-------------Round number:  558  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.951336222462983\n",
      "Average Global Trainning Loss:  0.1733050499637448\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.961087035030697\n",
      "Average Personal Trainning Loss:  0.14525481086640032\n",
      "-------------Round number:  559  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9516973636691947\n",
      "Average Global Trainning Loss:  0.1716307712057602\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.14408492628698877\n",
      "-------------Round number:  560  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1649531305546621\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.14103611112286701\n",
      "-------------Round number:  561  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.16429764736254063\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1392288290666475\n",
      "-------------Round number:  562  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16187941860145247\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13795538971509344\n",
      "-------------Round number:  563  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.16161007259502527\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13781264371586088\n",
      "-------------Round number:  564  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16176065463544487\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.13825006233565254\n",
      "-------------Round number:  565  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.1633831339650483\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13819962953048823\n",
      "-------------Round number:  566  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1618832760056936\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13767941999452646\n",
      "-------------Round number:  567  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15788193548057172\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13325043661407548\n",
      "-------------Round number:  568  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16390788421685965\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.14008942697400348\n",
      "-------------Round number:  569  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16387963699665944\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.14050682015520607\n",
      "-------------Round number:  570  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16194014516536318\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13846604390969214\n",
      "-------------Round number:  571  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.16277533931050245\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13980206137919263\n",
      "-------------Round number:  572  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.1625291707929871\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.14060394959399827\n",
      "-------------Round number:  573  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16179663870643735\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13836275364526904\n",
      "-------------Round number:  574  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15871636916601775\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13586629672617032\n",
      "-------------Round number:  575  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15816522324804194\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13592965734611998\n",
      "-------------Round number:  576  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15819928963806879\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.1355207614754029\n",
      "-------------Round number:  577  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.16065936572459596\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13802030431789455\n",
      "-------------Round number:  578  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.16166626946424137\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9618093174431203\n",
      "Average Personal Trainning Loss:  0.1394067766348693\n",
      "-------------Round number:  579  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1621420196610351\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13780420151115025\n",
      "-------------Round number:  580  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16252875198909805\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.137975194730583\n",
      "-------------Round number:  581  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.1600973088631952\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9614481762369086\n",
      "Average Personal Trainning Loss:  0.13726672182534308\n",
      "-------------Round number:  582  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15901589109476572\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13572074033241918\n",
      "-------------Round number:  583  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.16424357757623465\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.1394580911324316\n",
      "-------------Round number:  584  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.1652778909283022\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.14048546115686508\n",
      "-------------Round number:  585  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9526002166847237\n",
      "Average Global Trainning Loss:  0.163734223877923\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9618996027446731\n",
      "Average Personal Trainning Loss:  0.13951249155338682\n",
      "-------------Round number:  586  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9279157667386609\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16144607780900144\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13684195549146239\n",
      "-------------Round number:  587  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.16037873405547468\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13590182892980882\n",
      "-------------Round number:  588  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.16370681426550085\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13849271510473096\n",
      "-------------Round number:  589  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16609563858511647\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.1390679973521014\n",
      "-------------Round number:  590  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16586664102705173\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9617190321415674\n",
      "Average Personal Trainning Loss:  0.13999989111098884\n",
      "-------------Round number:  591  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.16672418607447972\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13767439434785797\n",
      "-------------Round number:  592  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.16528658661957724\n",
      "Average Personal Accurancy:  0.9287257019438445\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.14064224810753545\n",
      "-------------Round number:  593  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9518779342723005\n",
      "Average Global Trainning Loss:  0.1654672674342328\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13939253730264198\n",
      "-------------Round number:  594  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15667509696852994\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.1328863527594856\n",
      "-------------Round number:  595  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9547670639219935\n",
      "Average Global Trainning Loss:  0.16258581952955714\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.13863235313826067\n",
      "-------------Round number:  596  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1629585439696472\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13890233837167637\n",
      "-------------Round number:  597  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.16143678697535777\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13763589745353128\n",
      "-------------Round number:  598  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15998932358675289\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13468912716332046\n",
      "-------------Round number:  599  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.16332665054580287\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13828984870511127\n",
      "-------------Round number:  600  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16467396469915244\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1402756624507663\n",
      "-------------Round number:  601  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.16206130072200028\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13708449804899106\n",
      "-------------Round number:  602  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1663666267436349\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14147214107713185\n",
      "-------------Round number:  603  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.165687778702967\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.14092984514660076\n",
      "-------------Round number:  604  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.16176248414717068\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13706508979508059\n",
      "-------------Round number:  605  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15974603159068596\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13567528908930346\n",
      "-------------Round number:  606  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15780482045921362\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13383909854358522\n",
      "-------------Round number:  607  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.1584527100755575\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13546107090005982\n",
      "-------------Round number:  608  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.1597038536305977\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1363929426166373\n",
      "-------------Round number:  609  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.16045514372291442\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13489413166700523\n",
      "-------------Round number:  610  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.16214821355013093\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13509880553604076\n",
      "-------------Round number:  611  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1599600183356751\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13559307127319203\n",
      "-------------Round number:  612  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.16411174252042704\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13853749405739324\n",
      "-------------Round number:  613  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15981852874810965\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.13626130594161925\n",
      "-------------Round number:  614  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15755268949685694\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13505626387783834\n",
      "-------------Round number:  615  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.1579168284572217\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13586561341456188\n",
      "-------------Round number:  616  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.16032146813422604\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13592933773262572\n",
      "-------------Round number:  617  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15723316417182986\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13411065980216233\n",
      "-------------Round number:  618  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.1595145983573718\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13600760997525618\n",
      "-------------Round number:  619  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1616230114309656\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13771693600606041\n",
      "-------------Round number:  620  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15645174224181224\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.1337103824746355\n",
      "-------------Round number:  621  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15741321678065187\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13397594822490633\n",
      "-------------Round number:  622  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15912796521970363\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13669906621721514\n",
      "-------------Round number:  623  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.16189262194511217\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13732545356020337\n",
      "-------------Round number:  624  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9532322137955941\n",
      "Average Global Trainning Loss:  0.1633737549621648\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13677166256503362\n",
      "-------------Round number:  625  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15704695073737698\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.133707527995497\n",
      "-------------Round number:  626  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9558504875406284\n",
      "Average Global Trainning Loss:  0.15538718684049407\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.1334513632904196\n",
      "-------------Round number:  627  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15642215044070512\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13347725198345523\n",
      "-------------Round number:  628  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15750694068255688\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13344380277810694\n",
      "-------------Round number:  629  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.15527074833818616\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.13292692163094755\n",
      "-------------Round number:  630  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15753627899709957\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13302195705029454\n",
      "-------------Round number:  631  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15691218405434612\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13335015602428674\n",
      "-------------Round number:  632  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1552253522008453\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.13128280777412873\n",
      "-------------Round number:  633  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.1571098154053528\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1324713621900675\n",
      "-------------Round number:  634  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16075224099756794\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13496263916632809\n",
      "-------------Round number:  635  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15947868041330918\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13356102378241808\n",
      "-------------Round number:  636  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15778789196517246\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.1334984456644716\n",
      "-------------Round number:  637  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.15950429357747042\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.1372726842701844\n",
      "-------------Round number:  638  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15825456073026703\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.13398936097051056\n",
      "-------------Round number:  639  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15901552739665153\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13526798026490272\n",
      "-------------Round number:  640  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9548573492235464\n",
      "Average Global Trainning Loss:  0.15887845729223096\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.1373095720758848\n",
      "-------------Round number:  641  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15978143154046473\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9625315998555435\n",
      "Average Personal Trainning Loss:  0.13651316137510158\n",
      "-------------Round number:  642  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15755521334134615\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.1329903263355171\n",
      "-------------Round number:  643  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.952329360780065\n",
      "Average Global Trainning Loss:  0.1608383162179205\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.13748427942454405\n",
      "-------------Round number:  644  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.1577981526604539\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13576593808897053\n",
      "-------------Round number:  645  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15933287053299364\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13612506242382177\n",
      "-------------Round number:  646  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.15785255308140914\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13561352653682512\n",
      "-------------Round number:  647  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.1615296181637098\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.1384432962458243\n",
      "-------------Round number:  648  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16308853849257404\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9611773203322499\n",
      "Average Personal Trainning Loss:  0.13994047606452015\n",
      "-------------Round number:  649  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16392969508255462\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1400911683164895\n",
      "-------------Round number:  650  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.16523294665831528\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9612676056338029\n",
      "Average Personal Trainning Loss:  0.13956079727564102\n",
      "-------------Round number:  651  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.1663584600677986\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.960093896713615\n",
      "Average Personal Trainning Loss:  0.1423750051138159\n",
      "-------------Round number:  652  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.1606216403111175\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9619898880462261\n",
      "Average Personal Trainning Loss:  0.13887074072036384\n",
      "-------------Round number:  653  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16510348115082724\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14109973625053607\n",
      "-------------Round number:  654  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9525099313831709\n",
      "Average Global Trainning Loss:  0.16564615180062747\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9615384615384616\n",
      "Average Personal Trainning Loss:  0.1404983559081855\n",
      "-------------Round number:  655  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.92170626349892\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.16736147333973794\n",
      "Average Personal Accurancy:  0.9292656587473002\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.1433369645834744\n",
      "-------------Round number:  656  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.16932663344097035\n",
      "Average Personal Accurancy:  0.9273758099352052\n",
      "Average Personal Trainning Accurancy:  0.9598230408089563\n",
      "Average Personal Trainning Loss:  0.1437857129505801\n",
      "-------------Round number:  657  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9195464362850972\n",
      "Average Global Trainning Accurancy:  0.9476345250993138\n",
      "Average Global Trainning Loss:  0.1736810366657074\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9577464788732394\n",
      "Average Personal Trainning Loss:  0.14442403620440591\n",
      "-------------Round number:  658  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16662464300274807\n",
      "Average Personal Accurancy:  0.9295356371490281\n",
      "Average Personal Trainning Accurancy:  0.9602744673167208\n",
      "Average Personal Trainning Loss:  0.1398018519772481\n",
      "-------------Round number:  659  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.16280549319051327\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9616287468400144\n",
      "Average Personal Trainning Loss:  0.13855576713234133\n",
      "-------------Round number:  660  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.953322499097147\n",
      "Average Global Trainning Loss:  0.16008737880256296\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13553972888311439\n",
      "-------------Round number:  661  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9535933550018058\n",
      "Average Global Trainning Loss:  0.159981002614747\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13477469541054418\n",
      "-------------Round number:  662  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.15361170081637662\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.13222239429918856\n",
      "-------------Round number:  663  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15431411208638046\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.963073311664861\n",
      "Average Personal Trainning Loss:  0.1328455965283891\n",
      "-------------Round number:  664  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.1564205082886139\n",
      "Average Personal Accurancy:  0.9300755939524838\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13432353341049905\n",
      "-------------Round number:  665  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15496450350490362\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.1317187495591538\n",
      "-------------Round number:  666  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.1531426955664274\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.13123161450927118\n",
      "-------------Round number:  667  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1538877256427185\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13244490039697318\n",
      "-------------Round number:  668  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9579270494763452\n",
      "Average Global Trainning Loss:  0.15370071868510743\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.1322126515981909\n",
      "-------------Round number:  669  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9575659082701337\n",
      "Average Global Trainning Loss:  0.15333942318272617\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.13014271337661384\n",
      "-------------Round number:  670  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9551282051282052\n",
      "Average Global Trainning Loss:  0.15683796759674634\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13172586922526747\n",
      "-------------Round number:  671  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.16167570357289973\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.1375282538328932\n",
      "-------------Round number:  672  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9516070783676418\n",
      "Average Global Trainning Loss:  0.16431037679653643\n",
      "Average Personal Accurancy:  0.9349352051835853\n",
      "Average Personal Trainning Accurancy:  0.962080173347779\n",
      "Average Personal Trainning Loss:  0.1379616387099641\n",
      "-------------Round number:  673  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9519682195738534\n",
      "Average Global Trainning Loss:  0.16303317923113603\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13781039540024603\n",
      "-------------Round number:  674  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.15886323707721087\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.9631635969664138\n",
      "Average Personal Trainning Loss:  0.13645273238237518\n",
      "-------------Round number:  675  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.1634274720715116\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13605501196280245\n",
      "-------------Round number:  676  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.16203540100780967\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9628927410617552\n",
      "Average Personal Trainning Loss:  0.13588585927625046\n",
      "-------------Round number:  677  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15972281001715422\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13573110021809542\n",
      "-------------Round number:  678  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.1576160170533417\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13282962687483071\n",
      "-------------Round number:  679  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9544962080173348\n",
      "Average Global Trainning Loss:  0.1549501208976616\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13022799507380822\n",
      "-------------Round number:  680  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.15454866430655245\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.13160330296079362\n",
      "-------------Round number:  681  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15422459826567578\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.12966629088936665\n",
      "-------------Round number:  682  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.1542896341011816\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.1297895625077589\n",
      "-------------Round number:  683  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15373765057542774\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13054175633478354\n",
      "-------------Round number:  684  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.1527964549617416\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.12870986403950546\n",
      "-------------Round number:  685  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.15286554658227813\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12912481052430366\n",
      "-------------Round number:  686  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.957204767063922\n",
      "Average Global Trainning Loss:  0.15432603697606312\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13252629162646148\n",
      "-------------Round number:  687  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15523732117514785\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12980741677881794\n",
      "-------------Round number:  688  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15423785671511037\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13165160868304782\n",
      "-------------Round number:  689  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9235961123110151\n",
      "Average Global Trainning Accurancy:  0.9560310581437342\n",
      "Average Global Trainning Loss:  0.152467561654986\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9648790176959191\n",
      "Average Personal Trainning Loss:  0.12906546160476481\n",
      "-------------Round number:  690  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.15256175946655492\n",
      "Average Personal Accurancy:  0.9352051835853131\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.12893804603210207\n",
      "-------------Round number:  691  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15283545882919713\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12885918966825793\n",
      "-------------Round number:  692  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15484294016553246\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.1304141644236412\n",
      "-------------Round number:  693  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15392108667882698\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12899393430897887\n",
      "-------------Round number:  694  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9545864933188877\n",
      "Average Global Trainning Loss:  0.1548915765224359\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12790814114202442\n",
      "-------------Round number:  695  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1573888710493127\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.13078687784257628\n",
      "-------------Round number:  696  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9200863930885529\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.1560798443883453\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12711697651100917\n",
      "-------------Round number:  697  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.15610096092127687\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.12848017214867732\n",
      "-------------Round number:  698  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9503430841459011\n",
      "Average Global Trainning Loss:  0.15955437370567557\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9621704586493319\n",
      "Average Personal Trainning Loss:  0.13068492113790517\n",
      "-------------Round number:  699  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9515167930660888\n",
      "Average Global Trainning Loss:  0.1583685745784805\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.12985401422205106\n",
      "-------------Round number:  700  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9508847959552185\n",
      "Average Global Trainning Loss:  0.15914016563826067\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9613578909353557\n",
      "Average Personal Trainning Loss:  0.1316706642599991\n",
      "-------------Round number:  701  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9530516431924883\n",
      "Average Global Trainning Loss:  0.15646169434475443\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.1310305335367574\n",
      "-------------Round number:  702  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15491350862083558\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9633441675695197\n",
      "Average Personal Trainning Loss:  0.1282018108374808\n",
      "-------------Round number:  703  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15258405526306879\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12782817164152785\n",
      "-------------Round number:  704  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.15435187056332386\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.12880390755490476\n",
      "-------------Round number:  705  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.954225352112676\n",
      "Average Global Trainning Loss:  0.15341218484786925\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.1288623527397357\n",
      "-------------Round number:  706  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15451383745683234\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12798426425943482\n",
      "-------------Round number:  707  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15335817016733816\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9634344528710725\n",
      "Average Personal Trainning Loss:  0.12951360380834687\n",
      "-------------Round number:  708  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9214362850971922\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.15376458627818596\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9637955940772842\n",
      "Average Personal Trainning Loss:  0.12814833619354346\n",
      "-------------Round number:  709  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.1544288312885123\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12842440510450523\n",
      "-------------Round number:  710  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9531419284940412\n",
      "Average Global Trainning Loss:  0.15549564602660032\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13000400112010202\n",
      "-------------Round number:  711  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9222462203023758\n",
      "Average Global Trainning Accurancy:  0.9538642109064644\n",
      "Average Global Trainning Loss:  0.15340712613773588\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12821612731779297\n",
      "-------------Round number:  712  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.1518706889650201\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.12703502320261714\n",
      "-------------Round number:  713  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9539544962080173\n",
      "Average Global Trainning Loss:  0.15311224411523225\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12699228316362518\n",
      "-------------Round number:  714  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.15570704280017042\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12926528616561145\n",
      "-------------Round number:  715  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.9537739256049115\n",
      "Average Global Trainning Loss:  0.1555503109552749\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12882775733427004\n",
      "-------------Round number:  716  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9211663066954644\n",
      "Average Global Trainning Accurancy:  0.9528710725893824\n",
      "Average Global Trainning Loss:  0.15646347977186034\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.12896520215795979\n",
      "-------------Round number:  717  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9534127843986999\n",
      "Average Global Trainning Loss:  0.1566973927650438\n",
      "Average Personal Accurancy:  0.9289956803455723\n",
      "Average Personal Trainning Accurancy:  0.9641567352834959\n",
      "Average Personal Trainning Loss:  0.13192665262659692\n",
      "-------------Round number:  718  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.15598556942869155\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.12925451849720115\n",
      "-------------Round number:  719  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9203563714902808\n",
      "Average Global Trainning Accurancy:  0.9529613578909354\n",
      "Average Global Trainning Loss:  0.15767911316557195\n",
      "Average Personal Accurancy:  0.9298056155507559\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13205850972471447\n",
      "-------------Round number:  720  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9208963282937365\n",
      "Average Global Trainning Accurancy:  0.9526905019862766\n",
      "Average Global Trainning Loss:  0.15936299134953955\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9640664499819429\n",
      "Average Personal Trainning Loss:  0.13270866969898315\n",
      "-------------Round number:  721  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9524196460816179\n",
      "Average Global Trainning Loss:  0.15571400817011444\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.12821840869687273\n",
      "-------------Round number:  722  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9541350668111231\n",
      "Average Global Trainning Loss:  0.15223547817352834\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12742022359013858\n",
      "-------------Round number:  723  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15015031973693121\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.12883439206956482\n",
      "-------------Round number:  724  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9575659082701337\n",
      "Average Global Trainning Loss:  0.1500833992839247\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12689476798440885\n",
      "-------------Round number:  725  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.15424157084433684\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.13036980427486797\n",
      "-------------Round number:  726  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.1526988405921305\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9662332972192127\n",
      "Average Personal Trainning Loss:  0.1290590472925695\n",
      "-------------Round number:  727  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1524009057096989\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.1280948395072962\n",
      "-------------Round number:  728  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.15079646801078908\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12767691731065478\n",
      "-------------Round number:  729  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.15076534426914048\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12692593581067738\n",
      "-------------Round number:  730  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15264842982927615\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12635683643124773\n",
      "-------------Round number:  731  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.921976241900648\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.1525549263504706\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.12817598827137505\n",
      "-------------Round number:  732  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9206263498920086\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.15267535451087938\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.12692595785298733\n",
      "-------------Round number:  733  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9571144817623691\n",
      "Average Global Trainning Loss:  0.1495308647004221\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9663235825207657\n",
      "Average Personal Trainning Loss:  0.12483305154444294\n",
      "-------------Round number:  734  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.1488776188027605\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9669555796316359\n",
      "Average Personal Trainning Loss:  0.12560078519998194\n",
      "-------------Round number:  735  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9564824846514988\n",
      "Average Global Trainning Loss:  0.14986804591571867\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12583308910453908\n",
      "-------------Round number:  736  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9566630552546046\n",
      "Average Global Trainning Loss:  0.14907921776955804\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.1247378067231514\n",
      "-------------Round number:  737  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15258599498634434\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.12728547894941766\n",
      "-------------Round number:  738  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15052820207754944\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12655066548378816\n",
      "-------------Round number:  739  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.1505149987338897\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9662332972192127\n",
      "Average Personal Trainning Loss:  0.12573918886415447\n",
      "-------------Round number:  740  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9549476345250993\n",
      "Average Global Trainning Loss:  0.15271060016448854\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9660527266161069\n",
      "Average Personal Trainning Loss:  0.12695280538650575\n",
      "-------------Round number:  741  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15169793236079135\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9656013001083423\n",
      "Average Personal Trainning Loss:  0.12609973492799748\n",
      "-------------Round number:  742  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9544059227157818\n",
      "Average Global Trainning Loss:  0.15382130114168585\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12684509563893778\n",
      "-------------Round number:  743  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9225161987041036\n",
      "Average Global Trainning Accurancy:  0.954315637414229\n",
      "Average Global Trainning Loss:  0.15488251713304668\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.1266079754896567\n",
      "-------------Round number:  744  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.15800752154150866\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9635247381726255\n",
      "Average Personal Trainning Loss:  0.13100796221136918\n",
      "-------------Round number:  745  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.15418586992709463\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.12959924920365543\n",
      "-------------Round number:  746  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9510653665583243\n",
      "Average Global Trainning Loss:  0.16272330843786678\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9623510292524377\n",
      "Average Personal Trainning Loss:  0.13636838748335364\n",
      "-------------Round number:  747  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9244060475161987\n",
      "Average Global Trainning Accurancy:  0.9517876489707475\n",
      "Average Global Trainning Loss:  0.15901806226229573\n",
      "Average Personal Accurancy:  0.9341252699784017\n",
      "Average Personal Trainning Accurancy:  0.9624413145539906\n",
      "Average Personal Trainning Loss:  0.13427354145153372\n",
      "-------------Round number:  748  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.15837658695814713\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.1332366050645822\n",
      "-------------Round number:  749  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9233261339092873\n",
      "Average Global Trainning Accurancy:  0.9473636691946551\n",
      "Average Global Trainning Loss:  0.16777582468216753\n",
      "Average Personal Accurancy:  0.9308855291576674\n",
      "Average Personal Trainning Accurancy:  0.9604550379198267\n",
      "Average Personal Trainning Loss:  0.13895332223458942\n",
      "-------------Round number:  750  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9505236547490069\n",
      "Average Global Trainning Loss:  0.16467615790899243\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9622607439508848\n",
      "Average Personal Trainning Loss:  0.13651815395830513\n",
      "-------------Round number:  751  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9230561555075594\n",
      "Average Global Trainning Accurancy:  0.9535030697002528\n",
      "Average Global Trainning Loss:  0.15840168212802455\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9636150234741784\n",
      "Average Personal Trainning Loss:  0.1338140805217926\n",
      "-------------Round number:  752  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9554893463344167\n",
      "Average Global Trainning Loss:  0.1551309560084868\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9652401589021308\n",
      "Average Personal Trainning Loss:  0.13133677837003996\n",
      "-------------Round number:  753  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.1535812824286464\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.12935522981136016\n",
      "-------------Round number:  754  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.1540521282114764\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9637053087757314\n",
      "Average Personal Trainning Loss:  0.13126052299876986\n",
      "-------------Round number:  755  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9559407728421813\n",
      "Average Global Trainning Loss:  0.15402839966481582\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9654207295052365\n",
      "Average Personal Trainning Loss:  0.13047526570682105\n",
      "-------------Round number:  756  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.1553894902618838\n",
      "Average Personal Accurancy:  0.9343952483801296\n",
      "Average Personal Trainning Accurancy:  0.9645178764897074\n",
      "Average Personal Trainning Loss:  0.1305900840993477\n",
      "-------------Round number:  757  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.154745050267047\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13075926984936462\n",
      "-------------Round number:  758  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9550379198266522\n",
      "Average Global Trainning Loss:  0.1537781533199598\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.1298467182174578\n",
      "-------------Round number:  759  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1538036342302614\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13034917267275528\n",
      "-------------Round number:  760  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9546767786204406\n",
      "Average Global Trainning Loss:  0.15716688294581188\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9628024557602023\n",
      "Average Personal Trainning Loss:  0.13314242929532322\n",
      "-------------Round number:  761  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15737588812875247\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.13243632593840285\n",
      "-------------Round number:  762  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15058177591188154\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12985872025522527\n",
      "-------------Round number:  763  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9565727699530516\n",
      "Average Global Trainning Loss:  0.1511269263215511\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12941996807568165\n",
      "-------------Round number:  764  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9576561935716865\n",
      "Average Global Trainning Loss:  0.1492493954235227\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.1283884100123578\n",
      "-------------Round number:  765  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9570241964608162\n",
      "Average Global Trainning Loss:  0.1495078415076799\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9663235825207657\n",
      "Average Personal Trainning Loss:  0.12611292725050222\n",
      "-------------Round number:  766  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9572950523654749\n",
      "Average Global Trainning Loss:  0.151711168767916\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9646984470928133\n",
      "Average Personal Trainning Loss:  0.1307057841842723\n",
      "-------------Round number:  767  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9582881906825569\n",
      "Average Global Trainning Loss:  0.14987334709126152\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12859795523189216\n",
      "-------------Round number:  768  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.150126425872946\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9656915854098953\n",
      "Average Personal Trainning Loss:  0.12861186392947024\n",
      "-------------Round number:  769  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9577464788732394\n",
      "Average Global Trainning Loss:  0.15125176294394976\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9647887323943662\n",
      "Average Personal Trainning Loss:  0.1304759379972745\n",
      "-------------Round number:  770  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9561213434452871\n",
      "Average Global Trainning Loss:  0.1520740623377686\n",
      "Average Personal Accurancy:  0.9303455723542117\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.12964784147593897\n",
      "-------------Round number:  771  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9241360691144709\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.15004924472465805\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9653304442036836\n",
      "Average Personal Trainning Loss:  0.12903297123989932\n",
      "-------------Round number:  772  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9249460043196545\n",
      "Average Global Trainning Accurancy:  0.9578367641747924\n",
      "Average Global Trainning Loss:  0.14996474552946687\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9657818707114482\n",
      "Average Personal Trainning Loss:  0.12769363640275144\n",
      "-------------Round number:  773  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9252159827213823\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.15100313670887505\n",
      "Average Personal Accurancy:  0.9319654427645788\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.12883657425824982\n",
      "-------------Round number:  774  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9582881906825569\n",
      "Average Global Trainning Loss:  0.14791679451206438\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9665041531238714\n",
      "Average Personal Trainning Loss:  0.1266582870621163\n",
      "-------------Round number:  775  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9585590465872156\n",
      "Average Global Trainning Loss:  0.14764183873775505\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9665041531238714\n",
      "Average Personal Trainning Loss:  0.12560199752702916\n",
      "-------------Round number:  776  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.958107620079451\n",
      "Average Global Trainning Loss:  0.1472779532639547\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9671361502347418\n",
      "Average Personal Trainning Loss:  0.12514524780141184\n",
      "-------------Round number:  777  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.958197905381004\n",
      "Average Global Trainning Loss:  0.1487316876897402\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9666847237269772\n",
      "Average Personal Trainning Loss:  0.127059942034015\n",
      "-------------Round number:  778  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9279157667386609\n",
      "Average Global Trainning Accurancy:  0.958197905381004\n",
      "Average Global Trainning Loss:  0.14891838605501195\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.12786762737633736\n",
      "-------------Round number:  779  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9569339111592633\n",
      "Average Global Trainning Loss:  0.15285171503278486\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13147900637498872\n",
      "-------------Round number:  780  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9563019140483929\n",
      "Average Global Trainning Loss:  0.15586148224483118\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9644275911881546\n",
      "Average Personal Trainning Loss:  0.13196854403665584\n",
      "-------------Round number:  781  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.9576561935716865\n",
      "Average Global Trainning Loss:  0.15326347640379537\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9646081617912604\n",
      "Average Personal Trainning Loss:  0.13186329200664726\n",
      "-------------Round number:  782  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9262958963282938\n",
      "Average Global Trainning Accurancy:  0.9568436258577103\n",
      "Average Global Trainning Loss:  0.1541920197315705\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.965962441314554\n",
      "Average Personal Trainning Loss:  0.13019363111259705\n",
      "-------------Round number:  783  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9289956803455723\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.155893377467328\n",
      "Average Personal Accurancy:  0.9346652267818575\n",
      "Average Personal Trainning Accurancy:  0.96397616468039\n",
      "Average Personal Trainning Loss:  0.13284519976681\n",
      "-------------Round number:  784  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9553087757313109\n",
      "Average Global Trainning Loss:  0.1569749715742371\n",
      "Average Personal Accurancy:  0.933585313174946\n",
      "Average Personal Trainning Accurancy:  0.9642470205850487\n",
      "Average Personal Trainning Loss:  0.13248948096884594\n",
      "-------------Round number:  785  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.927645788336933\n",
      "Average Global Trainning Accurancy:  0.9563921993499458\n",
      "Average Global Trainning Loss:  0.15558196371236233\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.964969302997472\n",
      "Average Personal Trainning Loss:  0.13216368460663822\n",
      "-------------Round number:  786  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9536836403033586\n",
      "Average Global Trainning Loss:  0.1627856000057839\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9627121704586493\n",
      "Average Personal Trainning Loss:  0.13685510372934723\n",
      "-------------Round number:  787  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.925755939524838\n",
      "Average Global Trainning Accurancy:  0.955218490429758\n",
      "Average Global Trainning Loss:  0.15980638343532752\n",
      "Average Personal Accurancy:  0.9333153347732182\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13487020473955513\n",
      "-------------Round number:  788  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9268358531317494\n",
      "Average Global Trainning Accurancy:  0.9567533405561575\n",
      "Average Global Trainning Loss:  0.1557994221211685\n",
      "Average Personal Accurancy:  0.9327753779697624\n",
      "Average Personal Trainning Accurancy:  0.9632538822679668\n",
      "Average Personal Trainning Loss:  0.13447007068704292\n",
      "-------------Round number:  789  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9553990610328639\n",
      "Average Global Trainning Loss:  0.1548491120123183\n",
      "Average Personal Accurancy:  0.9338552915766739\n",
      "Average Personal Trainning Accurancy:  0.9650595882990249\n",
      "Average Personal Trainning Loss:  0.13135818145300085\n",
      "-------------Round number:  790  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9540447815095703\n",
      "Average Global Trainning Loss:  0.15803842486005779\n",
      "Average Personal Accurancy:  0.9306155507559395\n",
      "Average Personal Trainning Accurancy:  0.962983026363308\n",
      "Average Personal Trainning Loss:  0.13524694088005598\n",
      "-------------Round number:  791  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9227861771058316\n",
      "Average Global Trainning Accurancy:  0.9521487901769592\n",
      "Average Global Trainning Loss:  0.163225884125869\n",
      "Average Personal Accurancy:  0.9311555075593952\n",
      "Average Personal Trainning Accurancy:  0.9609967497291441\n",
      "Average Personal Trainning Loss:  0.14010059140399286\n",
      "-------------Round number:  792  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9271058315334774\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.1568713396540098\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.13364264645616084\n",
      "-------------Round number:  793  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9246760259179265\n",
      "Average Global Trainning Accurancy:  0.9527807872878296\n",
      "Average Global Trainning Loss:  0.16148618379195445\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9626218851570965\n",
      "Average Personal Trainning Loss:  0.1364869861320366\n",
      "-------------Round number:  794  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9556699169375226\n",
      "Average Global Trainning Loss:  0.15477092793892763\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9638858793788371\n",
      "Average Personal Trainning Loss:  0.13189308218854393\n",
      "-------------Round number:  795  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9260259179265659\n",
      "Average Global Trainning Accurancy:  0.9557602022390754\n",
      "Average Global Trainning Loss:  0.15498167446435424\n",
      "Average Personal Accurancy:  0.9322354211663066\n",
      "Average Personal Trainning Accurancy:  0.9643373058866017\n",
      "Average Personal Trainning Loss:  0.13116351479268237\n",
      "-------------Round number:  796  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.923866090712743\n",
      "Average Global Trainning Accurancy:  0.9562116287468401\n",
      "Average Global Trainning Loss:  0.15277525025957026\n",
      "Average Personal Accurancy:  0.9314254859611231\n",
      "Average Personal Trainning Accurancy:  0.9651498736005778\n",
      "Average Personal Trainning Loss:  0.12970176798723027\n",
      "-------------Round number:  797  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9273758099352052\n",
      "Average Global Trainning Accurancy:  0.9582881906825569\n",
      "Average Global Trainning Loss:  0.14894089125347035\n",
      "Average Personal Accurancy:  0.9325053995680346\n",
      "Average Personal Trainning Accurancy:  0.9668652943300831\n",
      "Average Personal Trainning Loss:  0.1295394373956076\n",
      "-------------Round number:  798  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9265658747300216\n",
      "Average Global Trainning Accurancy:  0.9580173347778982\n",
      "Average Global Trainning Loss:  0.148874764323622\n",
      "Average Personal Accurancy:  0.931695464362851\n",
      "Average Personal Trainning Accurancy:  0.9655110148067895\n",
      "Average Personal Trainning Loss:  0.12779787448650234\n",
      "-------------Round number:  799  -------------\n",
      "Evaluate global model\n",
      "\n",
      "Average Global Accurancy:  0.9254859611231101\n",
      "Average Global Trainning Accurancy:  0.9573853376670278\n",
      "Average Global Trainning Loss:  0.1499789848616942\n",
      "Average Personal Accurancy:  0.9330453563714903\n",
      "Average Personal Trainning Accurancy:  0.9658721560130011\n",
      "Average Personal Trainning Loss:  0.12765909610306067\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() and gpu != -1 else \"cpu\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"---------------Running time:------------\",i)\n",
    "    # Generate model\n",
    "    model = 'mclr'\n",
    "    dataset = 'Mnist'\n",
    "\n",
    "    model = Mclr_Logistic().to(device), model\n",
    "    algorithm = \"pFedMe\"\n",
    "    # select algorithm\n",
    "    batch_size = 20\n",
    "    learning_rate = 0.01\n",
    "    personal_learning_rate = 0.01\n",
    "    beta = 2\n",
    "    lamda = 15\n",
    "    num_glob_iters = 800\n",
    "    local_epochs = 20\n",
    "    optimizer = \"SGD\"\n",
    "    numusers = 5\n",
    "    K = 5\n",
    "    if(algorithm == \"FedAvg\"):\n",
    "        server = FedAvg(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, i)\n",
    "        \n",
    "    if(algorithm == \"pFedMe\"):\n",
    "        server = pFedMe(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, K, personal_learning_rate, i)\n",
    "\n",
    "    if(algorithm == \"PerAvg\"):\n",
    "        server = PerAvg(device, dataset, algorithm, model, batch_size, learning_rate, beta, lamda, num_glob_iters, local_epochs, optimizer, numusers, i)\n",
    "\n",
    "    server.train()\n",
    "    server.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_pFedMe_p_0.01_2_15_5u_20b_20_5_0.01_0\n",
      "Mnist_pFedMe_p_0.01_2_15_5u_20b_20_5_0.01_1\n",
      "Mnist_pFedMe_p_0.01_2_15_5u_20b_20_5_0.01_2\n",
      "Mnist_pFedMe_p_0.01_2_15_5u_20b_20_5_0.01_3\n",
      "Mnist_pFedMe_p_0.01_2_15_5u_20b_20_5_0.01_4\n",
      "std: 0.0010301719237763953\n",
      "Mean: 0.9359611231101512\n",
      "Mnist_pFedMe_0.01_2_15_5u_20b_20_5_0.01_0\n",
      "Mnist_pFedMe_0.01_2_15_5u_20b_20_5_0.01_1\n",
      "Mnist_pFedMe_0.01_2_15_5u_20b_20_5_0.01_2\n",
      "Mnist_pFedMe_0.01_2_15_5u_20b_20_5_0.01_3\n",
      "Mnist_pFedMe_0.01_2_15_5u_20b_20_5_0.01_4\n",
      "std: 0.0008806428958045365\n",
      "Mean: 0.9288876889848812\n"
     ]
    }
   ],
   "source": [
    "times = 5\n",
    "\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=\"pFedMe_p\", batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=algorithm, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.0220,  0.0258,  0.0260,  ..., -0.0261, -0.0202, -0.0071],\n",
      "        [ 0.0161, -0.0038,  0.0174,  ...,  0.0015, -0.0201, -0.0062],\n",
      "        [ 0.0062, -0.0231, -0.0167,  ..., -0.0208, -0.0004,  0.0089],\n",
      "        ...,\n",
      "        [ 0.0246, -0.0131,  0.0192,  ..., -0.0052, -0.0147, -0.0170],\n",
      "        [-0.0128,  0.0103,  0.0034,  ..., -0.0183, -0.0017,  0.0105],\n",
      "        [-0.0036,  0.0170,  0.0172,  ..., -0.0166, -0.0072,  0.0227]],\n",
      "       device='cuda:0'), tensor([-0.3637, -0.4881,  0.8164,  0.3730, -0.1836,  0.4527, -0.2537, -0.2432,\n",
      "         0.0302, -0.1637], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user = server.users[0]\n",
    "model = user.model\n",
    "net_values = [*model.state_dict().values()]\n",
    "print(net_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(server.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x, y in server.users[0].testloaderfull:\n",
    "    x = x.to(user.device)\n",
    "    print(x.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Average data \n",
    "if(algorithm == \"PerAvg\"):\n",
    "    algorithm == \"PerAvg_p\"\n",
    "if(algorithm == \"pFedMe\"):\n",
    "    average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=\"pFedMe_p\", batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "average_data(num_users=numusers, loc_ep1=local_epochs, Numb_Glob_Iters=num_glob_iters, lamb=lamda,learning_rate=learning_rate, beta = beta, algorithms=algorithm, batch_size=batch_size, dataset=dataset, k = K, personal_learning_rate = personal_learning_rate,times = times)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "293539041be06dcdbc1dd82d46367ecf96c14410c0014bf8043197a4a2571a26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
